---
title             : "FAIR Theory: Applying Open Science Principles to the Construction and Iterative Improvement of Scientific Theories"
shorttitle        : "FAIR THEORY"

author:
  - name: "Caspar J. Van Lissa"
    affiliation: "1"
    corresponding: yes
    address: "Professor Cobbenhagenlaan 125, 5037 DB Tilburg, The Netherlands"
    email: "c.j.vanlissa@tilburguniversity.edu"
    role:         # Contributorship roles (e.g., CRediT, https://casrai.org/credit/)
      - Conceptualization
      - Formal Analysis
      - Funding acquisition
      - Methodology
      - Project administration
      - Software
      - Supervision
      - Writing – original draft
      - Writing – review & editing
  - name: "Aaron Peikert"
    affiliation: "2,3"
    role:
      - Formal Analysis
      - Writing – original draft
      - Writing – review & editing
  - name: "Andreas M. Brandmaier"
    affiliation: "2,3,4"
    role:
      - Formal Analysis
      - Writing – original draft
      - Writing – review & editing
  - name: "Felix Schönbrodt"
    affiliation: "5"
    role:
      - Conceptualization
      - Writing – review & editing
affiliation:
  - id            : "1"
    institution   : "Tilburg University, dept. Methodology & Statistics"
  - id            : "2"
    institution   : "Center for Lifespan Psychology, Max Planck Institute for Human Development, Berlin, Germany"
  - id            : "3"
    institution   : "Max Planck UCL Centre for Computational Psychiatry and Ageing Research, Berlin, Germany"
  - id            : "4"
    institution   : "Department of Psychology, MSB Medical School Berlin, Berlin, Germany"
  - id            : "5"
    institution   : "Other affiliations"
authornote: |
  This is a preprint paper, generated from Git Commit # `r substr(gert::git_commit_id(),1,8)`.

abstract: |
  Test test.
keywords          : "meta theory, theory formation, cumulative science, formal models"
wordcount         : "`r tryCatch(wordcountaddin::word_count(here::here('manuscript.Rmd')))`"
bibliography      : "theory-specification.bib"
floatsintext      : yes
linenumbers       : yes
draft             : no
mask              : no
figurelist        : no
tablelist         : no
footnotelist      : no
classoption       : "man"
output            : papaja::apa6_pdf
---

```{r setup, include = FALSE}
library("papaja")
r_refs("r-references.bib")
```

```{r analysis-preferences}
# Seed for random number generation
set.seed(42)
knitr::opts_chunk$set(cache.extra = knitr::rand_seed)
```


The FAIR Guiding Principles (hereafter: FAIR principles) were established to make research data more Findable, Accessible, Interoperable and Reusable [REF].
Since their inception, scholars have demonstrated their relevance for making other information artefacts more open.
This paper argues that the FAIR principles can advance effective and transparent scholarly communication about theory.
To this end, we introduce "FAIR theory":
a digital representation of theory, compliant with the FAIR principles.
By improving the efficiency of scholarly communication, FAIR Theory has the potential to accelerate cumulative knowledge acquisition and advance social scientific research.

<!-- QUOTES 

Kurt Lewin: Nothing is as practical as a good theory

"Call Leon": When finding unexpected results in cognitive dissonance research, students were told to call Leon Festinger. He could explain why the study did not work, e.g. because you used the wrong font for the questionnaire.

END QUOTES -->

## The Need for FAIR Theory

The so-called "replication crisis" has prompted extensive reforms in social science [@lavelleWhenCrisisBecomes2021; @scheelWhyMostPsychological2022].
Concern that undisclosed flexibility in analyses was to blame for the abundance of non-replicable findings led to widespread adoption of open science practices like preregistration and replication [@nosekPromotingOpenResearch2015a].
These various practices ensure transparent and repeated testing of hypotheses.
However, recent reviews show that most preregistered hypothesis tests are not supported [@scheelExcessPositiveResults2021].
Increased rigor in testing has revealed that the root cause of the replication crisis is more fundamental:
psychological theories rarely produce hypotheses that are found to be true,
and are often sufficiently vague to explain contradictory findings.

Scholars have raised concerns about the state of theory in social science for nearly 50 years [@robinaughInvisibleHandsFine2021; @meehlTheoreticalRisksTabular1978].
Two main concerns are that, first, social scientific theories lack precision and clarity compared to theories in the physical sciences [@szollosiArrestedTheoryDevelopment2021].
In other words, social scientific theories lack *formalization* .
A second concern is the lack of transparent and democratic scholarly communication about psychological theory.

Given these concerns, it is unfortunate that scientific reform initiated by the open science movement has focused primarily on improving deductive methods.
The equally critical inductive processes of theory construction and -improvement have been largely overlooked.
The present paper restores balance by applying, for the first time,
open science principles to psychological theory.
We apply the FAIR principles to scientific theories,
introducing the concept of *FAIR Theory* to 
facilitate transparent scholarly communication and accelerate cumulative knowledge acquisition.

## Theory and Scientific Progress

According to the *empirical cycle* [@degrootMethodologieGrondslagenVan1961],
a philosophical model of cumulative knowledge acquisition,
research ideally follows a cyclical process with two phases (Figure \@ref(fig:figec)).
In the deductive phase, hypotheses derived from theory are tested on data. In the inductive phase, patterns observed in data are generalized to theoretical principles.
In this model, theories are the vehicle of scientists' understanding of phenomena.
Ideally, they are iteratively updated based on deductive testing and inductive theory construction.

```{r}
library(tidySEM)
library(ggplot2)
y_spacing <- .5
lo <- get_layout("", "A", "",
                 "D", "", "B",
                 "", "C", "", rows = 3)

edg <- data.frame(from = c("A", "B", "C", "D"),
                  to = c("B", "C", "D", "A")
)

p <- prepare_graph(layout = lo, edges = edg)
p$edges[] <- lapply(p$edges, unlist)
p$edges$connect_from <- list("right", "bottom", "left", "top")
p$edges$connect_to <- list("top", "right", "bottom", "left")
p$edges$curvature <- c(rep(60, 4))
p$edges$label <- c("deduction", "testing", "induction", "generalization")
p$edges$label_colour <- "gray50"
p$edges$colour <- "gray50"

p$nodes$label <- c("Theory", "Hypothesis", "Data", "Observed\npatterns")

p_old <- p
g <- plot(p)

topofplot <- max(p$nodes$node_ymax)

headers <- data.frame(
  x = c(3, 5),
  y = topofplot + 2*y_spacing,
  lab = c("Inductive phase", "Deductive phase")
)

letters <- p$nodes[, c("name", "x", "y")]
letters$y <- letters$y+.26
letters$x <- letters$x+.5
g <- g + geom_hline(yintercept = topofplot+y_spacing) +
  geom_vline(xintercept = median(p$nodes$x), linetype = 5) +
  geom_text(data = headers, aes(x = x, y = y, label = lab), vjust = 1) +
  #geom_label(data = letters, aes(x = x, y = y, label = name), fill = "lightblue") +
  scale_x_continuous(expand = c(0,0))+
  scale_y_continuous(expand = c(0,0))
g$layers <- g$layers[c(9, 1:8, 10:length(g$layers))]
ggsave("empirical_cycle.pdf", g, device = "pdf", width = 200, height = 200, units = "mm")
```

```{r figec, fig.cap="A take on the empirical cycle by De Groot"}
knitr::include_graphics("empirical_cycle.pdf")
```

In a progressive research program [@lakatosHistoryScienceIts1971],
this cycle is regularly completed to iteratively advance our understanding of the studied phenomena.
There are, however, indications that contemporary psychology falls short of this ideal.
Firstly, because deductive research is over-represented in the literature: 
According to one estimate, 89.6% of paper published in psychology tests hypotheses [@kuhbergerPublicationBiasPsychology2014].
Closer examination of deductive research reveals, however, that the link between theory and hypothesis is often tenuous [@scheelWhyHypothesisTesters2021; @oberauerAddressingTheoryCrisis2019].
Only 15% of deductive studies referenced any theory, and theory was often not cited in connection to the hypothesis [@mcphetresDecadeTheoryReflected2021].
The remaining 85% of deductive studies lacked an explicit derivation chain from theory to hypothesis.
Perhaps such ungrounded hypotheses are rooted in researchers' implicit theories, in which case it is important to make these explicit [REF Rasoul].
Or, perhaps the hypotheses are of no substantive interest [REF Hoijtink], and researchers are simply testing them as part of a cultural ritual [REF Gigerenzer].
No matter what the explanation - testing ad-hoc hypotheses not grounded in theory does not advance our principled understanding of psychological phenomena.

According to the aforementioned statistics, theory has an uncomfortable and paradoxical role in contemporary psychology:
The majority of papers ostensibly test hypotheses,
but these are rarely derived from theory,
and test results do not routinely contribute to the improvement of existing theories.
The paradoxical role of theory in psychology is perhaps best described by Meehl's observation that theories in psychology "lack the cumulative character of scientific knowledge. They tend neither to be refuted nor corroborated, but instead merely fade away as people lose interest" [@meehlTheoreticalRisksTabular1978].

To date, scientific reform initiated by the open science movement has predominanty focused on improving deductive methods, overlooking the shortcomings of theory.
The present paper applies, for the first time, open science principles to theory.
Applying the FAIR principles to scientific theories facilitates transparent scholarly communication and accelerates cumulative knowledge acquisition.

### Findability

One major obstacle to cumulative knowledge acquisition is the difficulty in finding relevant theories.
One contributing cause of theories' lack of Findability is the lack of standardized metadata or even a keyword to signal the presence of theory within a paper, and - consequently - the absence of a unified search engine for theory.
Making theories more findable through rich metadata would allow them to be systematically indexed, tagged, and made searchable.
This would allow researchers to easily identify relevant theories to inform their hypotheses,
grounding their work in established theoretical foundations.
Making theories findable also increases the impact and reuse potential of theories across scientific contexts.
For example, it becomes possible to conduct meta-research on theories, 
in the same way libraries and search engines have enabled scholars to study the literature via systematic reviews.
Moreover, theories might have transdisciplinary impact, either through direct application or through analogical modeling.
In analog modeling, the structure of a theory from one discipline is applied to a phenomenon in another field.
For example, predator-prey models have inspired theories of XXX, and the Eysenck model of atomic magnetism has inspired a network theory of depression.

Another contributing cause to the lack of Findability is that the primary unit of dissemination and search in psychology is still the academic paper.
A paper may contain multiple resources - such as materials, data, code, and theory - but if these are not merely described in text, and not instantiated as separate informational artefacts, their findability is limited.
This would be achieved by modular publishing of theories as individually citable academic assets, with adequate metadata that is indexed in standardized repositories,
similar to the current practice of publishing empirical data in standardized repositories (e.g., DataVerse).
As with empirical data, these theories could still be connected to a specific paper which might serve as documentation and the canonical reference for the resource.

There have been notable efforts to improve theories' findability through post-hoc curation.
For example, Gray and colleagues introduced a format for representing theories,
and post many examples on their website [REF GRAY].
Similarly, Borsboom and colleagues seek to establish a database of psychological theories [REF BORSBOOM].
Post-hoc curation does not address the root cause of the lack of Findability, however.
Ideally, Findability would be addressed ante-hoc, through modular publishing and documentation with rich metadata.


### Accessibility

Transparent scholarly communication about theory requires that theories are accessible to all researchers and other stakeholders.
If theories are accessible, researchers can reuse and refine them,
thus accelerating cumulative knowledge acquisition.
Making theories accessible also allows stakeholders (e.g., practitioners, policy makers, advocates) to inform themselves of the current scientific understanding of specific phenomena.
While isolated empirical findings can appear fragmented and contradictory [@dumas-malletPoorReplicationValidity2017],
theories offer a top-down, big picture representation of the phenomena studied in a field.

At present, there are several impediments to theories' accessibility.
The first are paywalls erected by commercial publishers.
Open Access publishing increases the accessibility of all academic output, including theory.

A second impediment is therefore the prevalence of (strategic) ambiguity,
which renders theory difficult to understand [REF Frankenhuis].
While open access publishing increases the availability of theories,
accessibility further requires clear and explicit communication.
This property of good theories has been dubbed "discursive survival [...], the ability to be understood" [@guestWhatMakesGood2024].
It is important to acknowledge the *indeterminacy of translation* [@quineReasonsIndeterminacyTranslation1970]:
which holds that every communicative utterance has multiple alternative translations, with no objective means of choosing the correct or best one.
Thus, it is not possible to entirely formalize an idea to the point that it becomes unambiguously interpretable.
This places a theoretical upper bound on theories' ability to be understood.

Successful communication requires shared background knowledge between sender and receiver [@vogtFAIR20Extending2024].
The Kuhnian notion of "normal science", conducted within the context of a shared paradigm, provides shared background knowledge to facilitate mutual understanding [@kuhnStructureScientificRevolutions2009].
From a pragmatic perspective, these considerations indicate that,
when striving to make theory accessible,
it is important to be as explicit as possible (e.g., about assumptions  and ontological definitions),
while acknowledging that accessibility exists on a spectrum,
and that it is impossible to eliminate all ambiguity.
Rather, it may benefit scientific discourse to anticipate misunderstanding,
and use it to drive further explication of theory.
In sum, efforts to communicate theory clearly, with as few dependencies on shared background knowledge as possible, including by formalization, embedding within shared contexts, and explication of assumptions, will advance its Accessibility.

A third impediment arises when theories have a "dependency on the author" (DOA).
DOA occurs when a theory cannot be understood by independent scholars,
thus requiring the original author for interpretation and clarification.
We have heard DOA referred to apocryphally as the "ask Leon" phenomenon,
as graduate students were supposedly told to ask Leon Festinger to explain to them how their misconstrual of cognitive dissonance theory had caused their experiments to yield null results.
DOA relates to the discourse on "Great Man Theorizing" [@guestWhatMakesGood2024] because it enables gatekeeping: an author could insist that work requires their involvement or denounce work conducted outside their purview as illegitimate,
which violates checks and balances of scientific research.
DOA also renders theories immune to refutation,
because the author can claim that the theory was misconstrued when confronted with falsifying evidence, thus making it a moving target  [@szollosiArrestedTheoryDevelopment2021].
DOA is inherently problematic because authors may not understand their own theories well.
This is illustrated by cases where third parties identify logical inconsistencies within a theory [e.g., @kissnerIDENTIFICATIONLOGICALINCONSISTENCY2008].
In short, DOA unduly impedes scientific progress, and authors should make good-faith efforts to make theories as accessible as possible; both in terms of availability and in terms of interpretability.

<!-- The data usually need to be integrated with other data. In addition, the data need to interoperate with applications or workflows for analysis, storage, and processing. -->

### Interoperability

Interoperability pertains to the property of information artefacts to "integrate or work together [...] with minimal effort" [@wilkinsonFAIRGuidingPrinciples2016a].
As the original definition of interoperability was somewhat narrow and abstract,
the concept has recently been further refined in terms of facilitating "successful communication between machines and between humans and machines", where "A and B are considered X-interoperable if a common operation X exists that can be applied to both" [@vogtFAIR20Extending2024].
This definition invites the question: *interoperable for what purpose?*
Suitable answers for FAIR theory may be:
this theory is X-interoperable for deriving testable null-hypotheses,
or for the purpose of selecting relevant control variables,
or for the purpose of indicating the conditions necessary for observing a particular phenomenon.
These definitions suggest that FAIR theory should, ad minimum,
be instantiated in a human- and machine-readable file format, as previously recommended [@vanlissaWORCSWorkflowOpen2021].
Furthermore, theories may have specific properties that incur affordances in terms of X-interoperability;
for example, Table \@ref(tab:tabmeehl) illustrates the affordances of Meehl's nine properties of strong theories.

```{r}
data.frame(
  "Property" = c("1) Ontology", "2) Causal connections", "3-8) Functional Form", "9) Numerical Value"),
  "X-interoperability" = c("Variable selection", "Model specification, covariate selection, causal inference", "Deriving specific hypotheses", "Simulating data"), check.names = FALSE
) |>
papaja::apa_table()
```


<!-- Do we want to say something about this?
Interoperability of psychological theory may be limited when theories are instantiated in natural language without consideration of ontological complexities. -->
<!-- or as visualizations without a straightforward interpretation -->
<!-- What can go wrong? A well-formed sentence may be logically inconsistent (e.g., the theory that conceptualized father involvement simultaneously as mediator and moderator); a picture may seem sensible but there's no straightforward way to translate it to hypotheses, etc. -->
<!-- which are not machine-readable and l -->

Kurt Lewin's adage "there's nothing as practical as a good theory" [@lewinPsychologyProcessGroup1943] seems to imply that theory plays a practical role in the day-to-day work of psychological researchers.
But, as we argued before, there are clear signs that this is not the case.
The examples of X-interoperability offered in Table \@ref(tab:tabmeehl) illustrate that much can be gained by integrating theory directly into analysis workflows, and by making theory X-interoperable within software used for analysis.
For example, interoperable theory could be used
to select control variables for causal inference [@cinelliCrashCourseGood2022],
or to preregister the inferential procedure that would lead to specific modifications of a theory after analyzing empirical data [@peikertReproducibleResearchTutorial2021],
or to derive machine-readable hypotheses [@lakensImprovingTransparencyFalsifiability2021] which could be automatically evaluated through integration testing [@vanlissaUsingEndpointsCheck2023].
Furthermore, theories can be X-interoperable with each other to enable nesting, or using one theory to clarify elements of another theory.
For example, it should be possible to embed a theory about emotion regulation [e.g., @grossEmotionRegulationCurrent2015] within a theory of emotion regulation development [@morrisRoleFamilyContext2007].

### Reusability

Some have argued that there is a norm *against* theory reuse:
*"[Theories are] like toothbrushes — no self-respecting person wants to use anyone else's"* [@mischelToothbrushProblem2008].
Such a norm impedes scientific progress.
Cumulative knowledge acquisition requires reusable theories that are continuously updated based on insights from new data [@degrootMethodologieGrondslagenVan1961].
Theories are made reusable by thorough documentation,
appropriate licensing, 
and detailed provenance (e.g., through version control, cross-referencing, and semantic versioning).

In our workshops on FAIR Theory, we often hear questions such as "who owns theory",
and "who determines how a theory may be reused or changed"?
Licensing theories for reuse provides an unambiguous answer to such questions.
These questions imply a norm against modifying theory without consent from the author reminiscent of the aforementioned problem of dependency on the author.
However, copyright law limits the rights authors can claim over theory based on the *idea-expression dichotomy* [@bently2010copyright],
<!-- o. Ideas, facts, and concepts are not protected by  Although they are not protectable by copyright, the expression of those ideas, facts, and concepts are protectable, such as in a description, explanation, or illustration or as a database of facts. Separating an idea from the expression or manifestation of that idea is known in copyright law as the  -->
which holds that copyright explicitly does not
*"extend to any idea, procedure, process, system, method of operation, concept, principle, or discovery"*.
It may, however, extend to creative works expressing that idea (e.g., writing, visual illustrations).
<!-- Copyright pertaining to recipes offer an interesting perspective: -->
<!-- Whereas the recipes themselves are not protected, *"substantial literary expression in the form of an explanation or directions"* can be protected by copyright. -->
Applying these principles to FAIR theory, it seems that vague, ambiguous verbal explanations of theories - in other words, those that fall short in terms of the Accessibility criterion - are more likely to qualify for copyright protection than formal theories.
If copyright limits Reusability and does not cover ideas in their purest form (like formal theory),
then it might be counterproductive and possibly misleading to adopt a license that assumes copyright protection.
Furthermore, even if copyright would apply, academic research is covered under "fair use" exemptions,
so copyright would pose few restrictions to Reusability in scholarly communication.
Given these considerations, the CC0 (no rights reserved) license seems most appropriate for FAIR Theory;
it explicitly waives all rights and encourages reuse.
In principle, CC0 does not require attribution.
Nevertheless, is essential that scholars do comprehensively cite theory,
including prior work that new theories are based on,
even in absence of legal obligations to do so,
to meet the definition of Reusability (R1.2, Table \@ref(tab:tabfair) and to comply with other definitions of open scholarship [@aalbersbergMakingScienceTransparent2018].

We can take inspiration from the field of computer science for well-established processes for iteratively improving information artefacts,  like computer code.
Using version control systems, like Git, would enhance the reusability of FAIR theory by thoroughly documenting every modification in a traceable and reversible manner.
Git also facilitates diffuse and adversarial collaboration,
as independent researchers can create independent versions of existing theories through "forking", or suggest modifications to existing theories via "pull requests".
In sum, version control using Git enables systematic, collaborative, and transparent theory development,
enables studying the provenance of a theory and investigating how well different iterations of the theory explain empirical evidence [@vanlissaUsingEndpointsCheck2023].

Even if scholars wish to diverge substantially from prior theory,
explicitly referring back to it enables clear comparison of the differences [@ramGitCanFacilitate2013].


From a meta-science perspective, FAIR theory facilitates studying the state of theory in a particular subfield, and comparing theories' substantive and structural properties. 

Making Theories FAIR Accelerates Scientific Progress
Adopting the FAIR principles for theories can address key challenges in the current research landscape, where theories often remain isolated and underutilized. By making theories findable, accessible, interoperable, and reusable, researchers can ensure that their work is grounded in a shared, transparent, and cumulative body of knowledge. This approach enhances scholarly communication, allowing for greater scrutiny, replication, and collaboration across disciplines, ultimately leading to faster, more reliable, and more impactful scientific progress.

## Publication is not Enough

Merely publishing a theory does not make it open;
to be open, theory should adhere to established open science standards.
The FAIR principles, initially introduced as a standard for open research data, have since been applied to other forms of digital scholarly output [e.g., software @lamprechtFAIRPrinciplesResearch2019].
We propose to apply the FAIR principles to digital representations of theory as well,
introducing a FAIR metadata format to represent (formal) theories.
The resulting theories are made *Findable* via a DOI,
Accessible in a machine- and human-readable filetype,
Interoperable within the data analysis environment,
and Reusable in the practical and legal sense, so that they may be improved over time.

## Adapting the FAIR Principles

The FAIR Principles were devised to make scholarly data more findable, accessible, interoperable, and reusable.
From their inception, these principles were developed with "other research resources" in mind.
Scholars have adapted the FAIR principles to, e.g., research software [REF Lamprecht].
Yet there are key distinctions between theory and other FAIR information artefacts.
With this in mind, the present paper further extends the FAIR principles' definition to theory, see Table \@ref(tab:tabfair).
We establish guiding principles for instantiating theory as a FAIR digital research artifact,
and provide applied examples to encourage their adoption.

```{r tabfair}
tab_fair <- read.csv("fair_principles.csv", stringsAsFactors = FALSE)[, c("Criterion", "Original", "Theory", "Our.action")]
names(tab_fair) <- c("Criterion", "Original", "Theory", "Action")
papaja::apa_table(tab_fair, landscape = TRUE, align = "m{.1\\linewidth}m{.35\\linewidth}m{.35\\linewidth}m{.15\\linewidth}")
```

## FAIR Theory and Recognition & Rewards

FAIR theory provides a clear deliverable, and a clear goal, for scholars and institutions seeking to promote contributions to theory.
In the spirit of DORA, this helps researchers obtain credit for their theoretical contributions - obviating the necessity of publishing a purely theoretical paper, which can be challenging.






## The Role of Theory Formalization

Concerns about the state of theory are a recurring theme in the psychological literature,
but previous writing has focused on theory formalization as a solution for ambiguity in psychological theory.
Greater formality increases theories' *empirical content*,
making them easier to falsify,
which necessitates revising them,
thus advancing our principled understanding of the phenomena they describe.
Conceptually, theory formalization is orthogonal to FAIR theory.
FAIR Theory does not require theories to be formal, and formal theory can be represented in a way that is not FAIR.
It is - in principle - possible to represent a collection of verbal statements as a FAIR Theory.
While FAIR Theory is fully consistent with formal theory, it does not require theories to be formal.


# Examples

## Formalizing the Empirical Cycle

In this example, we represent the empirical cycle - a theory of cumulative knowledge production through scientific research - as FAIR theory.
As several authors have taken inspiration from the work by De Groot,
we compare our interpretation of the original theory to the interpretation of others.
Originally, the theory has the following structure:

```

digraph {

  observation;
  induction;
  deduction;
  test;
  evaluation;
  
  observation -> induction;
  induction -> deduction;
  deduction -> test;
  test -> evaluation;
  evaluation -> observation;
  
}
```

Subsequently, Wagenmakers and colleagues modified the theory by *"[adding the] Whewell-Peirce-Reichenbach distinction between the context of discovery and the context of justification"*:

```
digraph {

  subgraph cluster_discovery {
    label="Discovery";
    hypothesis [label="New hypothesis"];
    prediction [label="New prediction"];
  }
  data  [label="Old knowledge and old data"];      
  subgraph cluster_justification {
    label="Justification";
    test [label="Test on new data"];
    evaluation;
  }

  data -> hypothesis [label="Speculate & explore"];
  hypothesis -> prediction  [label="Deduce"];
  prediction -> test  [label="Design new experiment"];
  test -> evaluation  [label="Statistical analysis"];
  evaluation -> data  [label="Knowledge accumulation"];

}
```

Note, however, that there appear to be further changes:
the phases of the cycle have been renamed,
and the annotations suggest a move towards experimental empirical psychology that was absent in the original formulation.
Moreover, the label "knowledge accumulation" invites the question of exactly *how* knowledge accumulates upon evaluation of a prior experiment.
As this lack of cumulative knowledge acquisition appears to be precisely where contemporary research practice falls short, this ambiguity invites further improvement of the theory.

Our work, too is inspired by De Groot, but our take on the empirical cycle is different again:

```
digraph {

  theory;
  prediction;
  test [label="inferential procedure"];
  observation;
  
  theory -> prediction [label="deduction"];
  prediction -> test;
  test -> observation;
  observation -> theory [label="generalization"];

}
```

In our representation,
induction is not a separate phase but a mode of reasoning by which specific observations are generalized into theory.
For example, the refutation of a hypothesized effect,
or the serendipitous observation of some pattern in data,
might be a reason to revise or construct theory.
Induction, incidentally, also occurs within the link from prediction to testing:
in the form of the inductive bias of methods used to perform the test,
and auxiliary assumptions that must be made to address remaining theoretical ambiguities.

<!-- # And then for example: I understand Aaron's work about inductive bias to be about the link "prediction -> test;", because the test is not identified without making auxiliary assumptions; if the auxiliary assumption is made based on the data, inductive bias is introduced. -->
<!-- ``` -->


## Using FAIR Theory to Perform Causal Inference

Some have argued that *causal explanations* are a property of good theory [REF Meehl, etc?].
According to Pearl and colleagues,
explicit assumptions about the direction of causality allow one to perform causal inference even on cross-sectional data.
Any formal theory that is explicit about direction of causality could thus be used to guide causal inference,
and could even be integrated into the analysis environment.

In this example, we illustrate how to use DAGs for causal inference, including the detection of a violation of the initial model and subsequent adaptation of the DAG. We could use that to illustrate updating FAIR theory:

https://currentprotocols.onlinelibrary.wiley.com/doi/full/10.1002/cpz1.45

We can find more examples of causal inference with DAGs in these tutorials:

https://www.r-bloggers.com/2019/08/causal-inference-with-dags-in-r/

https://www.r-bloggers.com/2018/08/applications-of-dags-in-causal-inference/


<!-- NOTES -->

* Theory is the vehicle of cumulative knowledge acquisition
* According to the empirical cycle, ideally, hypotheses are derived from theory, then tested in data, and theory is amended based on the resulting insights. When this cycle is regularly completed, theories become ever more veracious representations of social scientific phenomena.
* At present, there is concern over a theory crisis in the social sciences, which highlights that this system is not functioning as intended, and highlights the need for better theory.
* One source of potential improvements of theory methodology that has not been previously considered is computer science.
* The process of "iteratively improving" digital objects - in this case, computer code - is well understood.
* Recent work like the FAIR software principles has demonstrated that ideals of open science apply to computer science as well.
* This paper argues that, conversely, principles of computer science - particularly version control, algorithmic hypothesis generation (find better word; this is about using the digital theory object to derive implied hypotheses), and integrated testing, can also be used to improve theory methods in the social science.
* We introduce "FAIR theory", a digital research artifact to represent formal social scientific theories
* FAIR theory can be version controlled; any time new insights require modifications of the theory, these modifications can be documented in a traceable and reversable manner. Version control also enables diffuse collaboration in theory development, as other researchers can submit "pull requests" to suggest modifications of a theory, or can "fork" existing theories to create a spin-off from an existing theory.
* FAIR theory allows for algorithmic derivation of hypotheses implied by the theory.
* FAIR theory enables integration testing: researchers can build a "test suite" of evidence that must be explainable by the theory, and any modifications of the theory must also pass the test suite.
* To illustrate FAIR theory's potential to accelerate cumulative knowledge acquisition, we present several tutorial examples, developed in collaboration with applied researchers across fields of social science.

# Discussion

## Future Directions

One remaining issue that intersects with FAIR Theory is the measurement and operationalization of psychological constructs.
Aside from the aforementioned "theory crisis", there has been talk of a "measurement crisis":
it is not always clear how theoretical constructs are operationalized, and many existing instruments have poor psychometric properties [REF].
Additionally, the "jingle-jangle" fallacy is prevalent in the social sciences:
the same term is often used for distinct constructs, and conversely, different terms are used to refer to the same construct.
FAIR Theory can help address the measurement crisis:
since theories can reference other theories and resources, it is possible to extend a structural theory with a theory of 

FAIR Theory incorporates theory into open science workflows,
facilitates scholarly communication about theories,
making it easier to share theories with less opportunity for ambiguity and misunderstanding.
FAIR Theories are easier to find, and facilitate sharing, reusing, and updating open theories.
More efficient and transparent communication about theory democratizes and accelerates cumulative knowledge acquisition,
removes barriers for knowledge exchange with the global scholarly community,
opens theory development to diverse perspectives, and enables (distributed and adversarial) collaboration.



\newpage

# References

::: {#refs custom-style="Bibliography"}
:::
