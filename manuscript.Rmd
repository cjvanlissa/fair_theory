---
title             : "FAIR theory: Applying Open Science Principles to the Construction and Iterative Improvement of Scientific Theories"
shorttitle        : "FAIR THEORY"

author:
  - name: "Caspar J. Van Lissa"
    affiliation: "1"
    corresponding: yes
    address: "Professor Cobbenhagenlaan 125, 5037 DB Tilburg, The Netherlands"
    email: "c.j.vanlissa@tilburguniversity.edu"
    role:         # Contributorship roles (e.g., CRediT, https://casrai.org/credit/)
      - Conceptualization
      - Formal Analysis
      - Funding acquisition
      - Methodology
      - Project administration
      - Software
      - Supervision
      - Writing – original draft
      - Writing – review & editing
  - name: "Aaron Peikert"
    affiliation: "2,3"
    role:
      - Formal Analysis
      - Writing – original draft
      - Writing – review & editing
  - name: "Andreas M. Brandmaier"
    affiliation: "2,3,4"
    role:
      - Formal Analysis
      - Writing – original draft
      - Writing – review & editing
  - name: "Felix D. Schönbrodt"
    affiliation: "5"
    role:
      - Conceptualization
      - Writing – review & editing
affiliation:
  - id            : "1"
    institution   : "Tilburg University, dept. Methodology & Statistics"
  - id            : "2"
    institution   : "Center for Lifespan Psychology, Max Planck Institute for Human Development, Berlin, Germany"
  - id            : "3"
    institution   : "Max Planck UCL Centre for Computational Psychiatry and Ageing Research, Berlin, Germany"
  - id            : "4"
    institution   : "Department of Psychology, MSB Medical School Berlin, Berlin, Germany"
  - id            : "5"
    institution   : "Ludwig-Maximilians-Universität München, Germany"
authornote: |
  This is a preprint paper, generated from Git Commit # `r substr(gert::git_commit_id(),1,8)`.

abstract: |
  Test test.
keywords          : "meta theory, theory formation, cumulative science, formal models"
wordcount         : "`r tryCatch(wordcountaddin::word_count(here::here('manuscript.Rmd')))`"
bibliography      : "theory-specification.bib"
floatsintext      : yes
linenumbers       : yes
draft             : no
mask              : no
figurelist        : no
tablelist         : no
footnotelist      : no
classoption       : "man"
output            :
  papaja::apa6_pdf: default
  md_document: default
---

```{r setup, include = FALSE}
library("papaja")
r_refs("r-references.bib")
```

```{r analysis-preferences}
# Seed for random number generation
set.seed(42)
knitr::opts_chunk$set(cache.extra = knitr::rand_seed)
```


The FAIR Guiding Principles (hereafter: FAIR principles) were established to improve the reusability of research data by making them more findable, accessible, interoperable and reusable [REF] for both humans and computers.
Since their inception in 2014, scholars have demonstrated their relevance for making other information artefacts more open, such as research software [@lamprechtFAIRPrinciplesResearch2019] and computational workflows [@wilkinson2024applying].
This paper argues that the FAIR principles can advance effective and transparent scholarly communication about theory.
To this end, we introduce "FAIR theory":
a digital representation of a scientific theory, compliant with the FAIR principles.
By improving the efficiency of scholarly communication, FAIR theory has the potential to foster and accelerate cumulative knowledge acquisition and ultimately advance social scientific research.

<!-- QUOTES 

Kurt Lewin: Nothing is as practical as a good theory

"Call Leon": When finding unexpected results in cognitive dissonance research, students were told to call Leon Festinger. He could explain why the study did not work, e.g. because you used the wrong font for the questionnaire.

END QUOTES -->

## The Need for FAIR theory

The so-called "replication crisis" has prompted extensive reforms in social science [@lavelleWhenCrisisBecomes2021; @scheelWhyMostPsychological2022].
Concern that undisclosed flexibility in analyses was a major factor for the abundance of non-replicable findings led to widespread adoption of open science practices like preregistration and replication [@nosekPromotingOpenResearch2015a].
These various practices ensure transparent and repeated testing of hypotheses.
However, recent reviews show that most preregistered hypothesis tests are not supported by empirical evidence [@scheelExcessPositiveResults2021].
Thus, increased rigor in testing has revealed that the root cause of the replication crisis is more fundamental:
Psychological theories rarely produce hypotheses that are corroborated by evidence.
Furthermore, theories are often so vague that they can accommodate findings that are mutually inconsistent,
as the theory's central claims evade falsification.<!--CJ: Resolved AB's comment? AB: Your original wording is contradicting itself; if findings contradict a theory <=> the theory does not explain the findings; I am not sure what the best wording is; should we differentiate between a core of a theory and auxiliary parts?-->
<!-- CJ: Maybe we should give an example here. Does anyone know one? -->

Scholars have been raising concerns about the state of theory in social science for nearly 50 years [@robinaughInvisibleHandsFine2021; @meehlTheoreticalRisksTabular1978].
Two main concerns are that, first, social scientific theories lack precision compared to theories in the physical sciences [@szollosiArrestedTheoryDevelopment2021].
 and clarity
In other words, social scientific theories lack *formalization*,
which means that they do not make very accurate predictions,
and are thus hard to falsify and difficult to understand on their own,
without either substantial interpretation or additional background knowledge.
A second concern is the lack of transparent and participative scholarly communication about psychological theory and their development over time.

Given these concerns, it is an imbalance that scientific reform initiated by the open science movement has focused primarily on improving deductive methods.
The equally critical inductive processes of theory construction and theory improvement have been largely overlooked.
The present paper restores balance by applying, for the first time,
open science principles to psychological theory.
We apply the FAIR principles to scientific theories,
introducing the concept of *FAIR theory* to 
facilitate transparent scholarly communication and accelerate cumulative knowledge acquisition.

## Theory and Scientific Progress

According to the *empirical cycle* [@degrootMethodologieGrondslagenVan1961],
a philosophical model of cumulative knowledge acquisition,
research ideally follows a cyclical process with two phases (Figure \@ref(fig:figec)).
In the deductive phase, hypotheses derived from theory are tested on data. In the inductive phase, patterns observed in data are generalized to theoretical principles.
In this model, theories are the vehicle of scientists' understanding of phenomena.
Ideally, they are iteratively updated based on deductive testing and inductive theory construction.

```{r}
library(tidySEM)
library(ggplot2)
y_spacing <- .5
lo <- get_layout("", "A", "",
                 "D", "", "B",
                 "", "C", "", rows = 3)

edg <- data.frame(from = c("A", "B", "C", "D"),
                  to = c("B", "C", "D", "A")
)

p <- prepare_graph(layout = lo, edges = edg)
p$edges[] <- lapply(p$edges, unlist)
p$edges$connect_from <- list("right", "bottom", "left", "top")
p$edges$connect_to <- list("top", "right", "bottom", "left")
p$edges$curvature <- c(rep(60, 4))
p$edges$label <- c("deduction", "testing", "induction", "generalization")
p$edges$label_colour <- "gray50"
p$edges$colour <- "gray50"

p$nodes$label <- c("Theory", "Hypothesis", "Data", "Observed\npatterns")

p_old <- p
g <- plot(p)

topofplot <- max(p$nodes$node_ymax)

headers <- data.frame(
  x = c(3, 5),
  y = topofplot + 2*y_spacing,
  lab = c("Inductive phase", "Deductive phase")
)

letters <- p$nodes[, c("name", "x", "y")]
letters$y <- letters$y+.26
letters$x <- letters$x+.5
g <- g + geom_hline(yintercept = topofplot+y_spacing) +
  geom_vline(xintercept = median(p$nodes$x), linetype = 5) +
  geom_text(data = headers, aes(x = x, y = y, label = lab), vjust = 1) +
  #geom_label(data = letters, aes(x = x, y = y, label = name), fill = "lightblue") +
  scale_x_continuous(expand = c(0,0))+
  scale_y_continuous(expand = c(0,0))
g$layers <- g$layers[c(9, 1:8, 10:length(g$layers))]
ggsave("empirical_cycle.pdf", g, device = "pdf", width = 200, height = 200, units = "mm")
```

```{r figec, fig.cap="A take on the empirical cycle by De Groot"}
knitr::include_graphics("empirical_cycle.pdf")
```

In a progressive research program [@lakatosHistoryScienceIts1971],
this cycle is regularly completed to iteratively advance our understanding of the studied phenomena
<!-- by successively increasing the empirical content of a theory. -->
<!-- In psychology, this is typically achieved by either generalizing to a larger set of people, contexts, situations, or environments. <!--AB would you agree?-->
<!-- CJ: I am not sure if I agree; I think increasing the empirical content rather implies more and more precision, which loses generality but gains specificity. Not sure how to resolve.
This needs more work! -->
.
There are, however, indications that contemporary psychology falls short of this ideal.
Firstly, because hypothesis-testing research is over-represented in the literature: 
According to @kuhbergerPublicationBiasPsychology2014, 89.6% of papers published in psychology report confirmatory hypothesis tests.
Closer examination of reported deductive research reveals, however, that the link between theory and hypothesis is often tenuous [@scheelWhyHypothesisTesters2021; @oberauerAddressingTheoryCrisis2019].
Only 15% of deductive studies referenced any theory, and theory was often not cited in relation to the hypothesis [@mcphetresDecadeTheoryReflected2021].
The remaining 85% of deductive studies lacked an explicit derivation chain from theory to hypothesis.
In the best case, such ungrounded hypotheses are rooted in researchers' implicit theories, in which case it is particularly important to make these explicit [@friedTheoriesModelsWhat2020, @norouziCapturingCausalClaims2024].
Or, perhaps the hypotheses are not of substantive interest, such as null hypotheses that exist purely for the purpose of being rejected [@vanlissaTeacherCornerEvaluating2020], and researchers are simply testing them as part of a cultural ritual [@gigerenzerNullRitualWhat2004].
Testing ad-hoc hypotheses not grounded in theory does not advance our principled understanding of psychological phenomena.
Put differently: collecting significance statements about ad-hoc hypotheses is much like trying to write novels by collecting sentences from randomly generated letter strings [@vanrooijTheoryTestHow2021].

Theory thus has an uncomfortable and paradoxical role in contemporary psychology:
The majority of papers ostensibly test hypotheses,
but these are rarely derived from theory,
and test results do not routinely contribute to the improvement of existing theories.
The paradoxical role of theory in psychology is perhaps best described by Meehl's observation that theories in psychology "lack the cumulative character of scientific knowledge. They tend neither to be refuted nor corroborated, but instead merely fade away as people lose interest" [@meehlTheoreticalRisksTabular1978].


<!-- First, we reflect on the differences between theory and data. <!-- CJ: Should we? --> -->
<!-- Second, we adapt the FAIR principles for theory, respecting these differences. -->
<!-- Third, we discuss the current state and future directions of psychological theory with respect to each criterion. -->
<!-- Fourth, we present worked examples of theory made FAIR. -->
<!-- We conclude with a summary and future directions for FAIR theory. -->

## Making Theory FAIR

The present paper addresses the lack of open science methods for theory development and suggests an improvement of the state of affairs by applying the FAIR principles to scientific theories.
Merely publishing theory -- as in a classic research article -- does not make it open;
to be open, theory should adhere to established open science standards.
<!--AB  I deleted this sentence because it was already in the introduction -->
We apply the FAIR principles to digital representations of theory,
introducing a FAIR metadata format to make theories *Findable* via a DOI,
*Accessible* in a machine- and human-readable filetype,
*Interoperable* within the data analysis environment,
and *Reusable* in the practical and legal sense, so that they may be improved over time -- at best, in a participative process.
Digital representations of theory intentionally is a broad term, particularly including textual representations of a given theory, as well as formal representations, such as mathematical notation, algorithmic pseudo code, or a set of logical clauses. <!-- AB I think some initial word on what is covered is needed here; otherwise readers may wonder what we mean to cover--> 
Following the original proposal of Lamprecht and colleagues,
we adapt the FAIR principles for theory, see Table \@ref(tab:tabfair).
We reflect on the necessary changes (which are minor),
as well as on the current state and future of FAIR theory in the social sciences.
The resulting principles provide guidance for instantiating theory as a FAIR information artifact,
and we provide worked examples to encourage their adoption.

```{r tabfair}
tab_fair <- read.csv("fair_principles.csv", stringsAsFactors = FALSE)[, c("Criterion", "Original", "Theory", "Our.action")]
names(tab_fair) <- c("Criterion", "Original", "Theory", "Action")
papaja::apa_table(tab_fair, landscape = TRUE, align = "m{.1\\linewidth}m{.35\\linewidth}m{.35\\linewidth}m{.15\\linewidth}")
```


There are different definitions of theory,
and many of those definitions are consistent with the FAIR theory principles.
This paper defines theory as an integrated set of statements that explain phenomena consistently evidenced by patterns in data [bogen/woodward].
Meehl [-@meehlAppraisingAmendingTheories1990] provides guidance as to what kinds of "statements" such a theory might contain:
statements about the types of entities postulated (i.e., ontology),
statements about causal connections between those entities,
statements about the functional form of those connections,
and statements about their specific numerical values [cf. @frankenhuisStrategicAmbiguitySocial2023, @guestWhatMakesGood2024].

Some have defined a model as a "specific instantiation of theory narrower in scope and often more concrete, commonly applied to a particular aspect of a given theory" [REF Fried].
This invites the question: if a FAIR theory is a specific instantiation of theory, how does FAIR theory differ from a model?
While there may be philosophical differences,
these differences are largely irrelevant for the purpose of making theories more FAIR.
When organizing knowledge, we think it is helpful to view theories and models derived from them as existing along a continuum of specificity,
from broad to narrow, from general to specific,
where a theory has a relatively broader scope and may contain one or more models as specific instances.
<!-- Paradigms at the broadest level encompass the larger narrative, frameworks gather and organize concepts and terms, but only theories have a degree of specificity that allows us to derive specific testable and falsifiable hypotheses or models with exact mathematical relations between concepts (cf. Partelow, 2023, Table 1, https://link.springer.com/article/10.1007/s13412-023-00833-w#). -->
For example, following Meehl, we could envision a theory that merely specifies how specific constructs are causally connected.
From this theory, we could derive a more specific *statistical model* by assuming functional form (e.g., linear effects) and error families (e.g., normal distributions).
This statistical model makes just enough assumptions to allow estimation of the remaining unknown parameters (e.g., regression slopes) from data.
Or, we could derive an even more specific *generative/computational model*, which is completely parametrized (i.e., specific values of regression slopes are also assumed) such that an interpreter (e.g., the R programming language) can use the model to generate new data.
Note that broadness and narrowness are relative terms,
and one person's theory may be another person's model.
This definition also implies that FAIR models are a special case of FAIR theory.

As an applied example, consider a comprehensive theory of disease spread and pandemics which covers various psychological factors such as adherence to pandemic mitigation methods (e.g., ), pandemic-related social disruption (e.g., panic buying), or pandemic-related distress and related problems (e.g., anxiety) [@taylor2022psychology].
The theory may encompass a particular transmission _model_ for disease spread including precise parameters for the process of infection (e.g., social distance, average duration of encounters, ventilation) and incubation times.

### The Role of Theory Formalization

Concerns about the state of theory in the psychological literature revolve around two issues: theory formalization and theory (re-)use.
Greater formalization increases theories' *empirical content* [REF] as it forces researchers to use precise statements, for example by specifying exact functional forms for relations or forces them to specify processes  that would otherwise get away with their vague formulation in verbal theories.
For example, the phonological loop in Baddeley's verbal description of his working memory model allows at least 144 different implementations, for example, depending on how decay rate, recall success, or rehearsal sequence are precisely implemented [@lewandowsky2010computational].
More precise theories makes them easier to falsify,
which necessitates revising them,
thus advancing our principled understanding of the phenomena they describe.
FAIR theory does not require theories to be formal,
and formal theory can be represented in a way that is not FAIR.
It is therefore important for us to emphasize that FAIR theory imposes no restrictions on researchers regarding the manner in which theories are derived and written down. 
The guidelines introduced by FAIR theory primarily pertain to how theories are documented and shared in digital environments, with the aim of enhancing their reusability and extensibility.
For example, it is possible to represent a collection of verbal propositions (perhaps derived through qualitative research) as a FAIR theory.
Conversely, a directed acyclic graph (DAG) is a type of formal theory (for example, see the empirical cycle in Figure \@ref(fig:figec)),
but if it is embedded within a journal article as a bitmap image without any key words to help search engines index that article as a theory paper,
it is not FAIR.
FAIR theory is thus consistent with, but does not require, formal theory (also see *Accessibility*).

## Findability

Making theories Findable would allow researchers to easily identify relevant theories to inform their hypotheses,
grounding their work in established theoretical foundations.
Making theories Findable also increases the impact and reuse potential of theories across disciplines,
either through direct application (where one discipline stumbles upon a problem that is already well-understood in another discipline),
or through analogical modeling.
In analog modeling, the structure of a theory from one discipline is applied to a phenomenon in another field.
For example, predator-prey models have inspired theories of XXX, and the Eysenck model of atomic magnetism has inspired a network theory of depression.
Findability also enables meta-research on theories, 
in the same way libraries and search engines have enabled scholars to study the literature via systematic reviews.
In a similar way, it would become possible to compare all theories of a specific phenomenon,
or to study structural properties of theories.

The four Findability criteria are applicable to theory with only minor adjustments, see Table \@ref(tab:tabfair).
First, this requires assigning a globally unique and persistent identifier, or DOI, to each theory (F1).
Of the many services that provide DOIs for scientific information artefacts,
Zenodo and the Open Science Framework are commonly used in psychology.
Second, Findable theory is described with rich metadata	(F2).
This includes citation metadata (e.g., referencing a scientific paper that documents the theory, or a psychometric paper that operationalizes specific constructs).
It might further include domain-specific metadata, such as a reference to a taxonomy of psychological constructs [@boscoMetaBUSVehicleFacilitating2017],
ontology [@guyonMeasurementOntologyEpistemology2018],
or catalog of psychological phenomena [REF Noah Denny].
Metadata should also include identifiers for all the versions of the theory it describes	(F3);
Zenodo handles this by default by providing an overarching DOI for an information artifact which subsumes the DOIs of that artifact's versions.
Finally, these metadata should be registered or indexed in a searchable registry (F4).
This final criterion is less straightforward.
Ideally, FAIR theories should be indexed in search engines used by academics, like Google Scholar.
At present, however, these search engines are designed to index traditional print publications.
The *data paper* solves this problem for research data;
the idea is that scholars publish a paper (or even preprint) as documentation for the data resource [REF McGIllivray on data papers].
The data paper is indexed by search engines, and in turn points to the relevant information artifact.
The same solution could be applied to theories - but it seems superfluous to generate papers whose only purpose is to redirect to a specific resource.
Another solution is to manually index FAIR theories,
for example by adding them to one's Google Scholar profile,
or entering them in PURE.
<!-- CJ: Can we guarantee automatically indexing FAIR theory somehow? -->

At present, theories have poor findability, which impedes cumulative knowledge acquisition.
One factor contributing to theories' lack of Findability is the lack of standardized metadata, or even a standardized keyword to signal the presence of theory within a paper - terms like "theory", "model", and "framework" are used interchangeably.
To curb this trend, we suggest using the keyword `"FAIRtheory"` for all resources that constitute or reference a FAIR theory (separating the words `FAIR` and `theory` by a space or hyphen would lead them to be interpreted as separate tokens in many search engines.
This would allow theoretical resources to be systematically indexed, tagged, and made searchable.
Another factor contributing to the present lack of Findability is that the primary unit of dissemination and search in psychology is still the academic paper.
A paper may contain multiple resources - such as materials, data, code, and theory - but if these are not merely described in text, and not instantiated as separate informational artefacts, their findability is limited.
This would be achieved by modular publishing of theories as individually citable academic assets, with adequate metadata that is indexed in standardized repositories,
similar to the current practice of publishing empirical data in standardized repositories (e.g., DataVerse).
As with empirical data, these theories could still be connected to a specific paper which might serve as documentation and the canonical reference for the resource.

There have been notable efforts to improve theories' findability through post-hoc curation.
For example, Gray and colleagues introduced a format for representing theories,
and post many examples on their website [@grayHowMapTheory2017].
Similarly, Borsboom and colleagues seek to establish a database of psychological theories [REF BORSBOOM].
Post-hoc curation is a notable effort but does not address the root cause of the lack of Findability, however.
Ideally, Findability would be addressed ante-hoc, through documentation with rich metadata and modular publishing.

## Accessibility

Transparent scholarly communication about theory requires that theories are accessible to all researchers and other stakeholders.
If theories are accessible, researchers can reuse and refine them,
thus accelerating cumulative knowledge acquisition.
Making theories accessible also allows stakeholders (e.g., practitioners, policy makers, advocates) to inform themselves of the current scientific understanding of specific phenomena.
While isolated empirical findings can appear fragmented and contradictory [@dumas-malletPoorReplicationValidity2017],
theories offer a top-down, big picture representation of the phenomena studied in a field.
In other words, theories are an important instrument in science communication.

The Accessibility criteria serve to *regulate* access, not to maximize it.
These principles apply to theory with minor changes, with the caveat that there might be less of a need to restrict access to theory than there is for (human subjects) data.
Firstly, theory and its associated metadata should be accessible by their identifier using a standardized communications protocol (A1).
This can be achieved, for example, by hosting theory in a version-controlled remote repository (such as git), and archiving that repository on Zenodo for long-term storage.
The resulting resource will then have an identifier (DOI) which allows the theory to be accessed using a standardized communications protocol (download via `https` or `git`).
Secondly (A2), theory metadata should be accessible, even when the theory is no longer available,
which is also achieved via long-term storage (e.g., on Zenodo).
Git remote repositories allow for access control,
and Zenodo allows for access control of individual files/resources.
An unavailable theory typically refers to a theory that was abandoned in favor of a better or more general theory (such as the phlogiston theory, which was superseded by thermodynamics).
In general, it makes sense to keep outdated theories, in order to be able to track the genesis of theories over time, yet, we require the availability of meta data as a minimum requirement.

At present, there are several impediments to theories' accessibility.
To the extent that theories are still contained within papers,
paywalls erected by commercial publishers constitute a barrier.
Open Access publishing thus increases the accessibility of all academic output, including theory.
A second impediment is more indirect:
While open access publishing increases practical access to theories,
accessibility also requires clear and explicit communication.
This property of good theories has been dubbed "discursive survival [...], the ability to be understood" [@guestWhatMakesGood2024].
The current prevalence of strategic ambiguity renders psychological theory difficult to understand [@frankenhuisStrategicAmbiguitySocial2023].
It is important to acknowledge the *indeterminacy of translation* [@quineReasonsIndeterminacyTranslation1970]:
which holds that every communicative utterance has multiple alternative translations, with no *objective* means of choosing the correct one.
It follows that an idea cannot be formalized to the point that it becomes unambiguously interpretable.
This places a theoretical upper bound on theories' ability to be understood.

Successful communication requires shared background knowledge between sender and receiver [@vogtFAIR20Extending2024].
The Kuhnian notion of "normal science", conducted within the context of a shared paradigm, provides shared background knowledge to facilitate mutual understanding [@kuhnStructureScientificRevolutions2009].
From a pragmatic perspective, these considerations indicate that,
when striving to make theory accessible,
it is important to be as explicit as possible (e.g., about assumptions  and ontological definitions),
while acknowledging that accessibility exists on a spectrum,
and that it is impossible to eliminate all ambiguity.
Rather, it may benefit scientific discourse to anticipate misunderstanding,
and use it to drive further explication of theory.
In sum, efforts to communicate theory clearly, with as few dependencies on shared background knowledge as possible, including by formalization, embedding within shared contexts, and explication of assumptions, will advance its Accessibility.

A third impediment arises when theories have a "dependency on the author" (DOA). <!-- AB citation needed?! Who came up with this term? -->
DOA occurs when a theory cannot be understood by independent scholars,
thus requiring the original author for interpretation and clarification.
We have heard DOA referred to apocryphally as the "ask Leon" phenomenon,
as graduate students were supposedly told to ask Leon Festinger to explain to them how their misconstrual of cognitive dissonance theory had caused their experiments to yield null results.
DOA relates to the discourse on "Great Man Theorizing" [@guestWhatMakesGood2024] because it enables gatekeeping: an author could insist that work requires their involvement or denounce work conducted outside their purview as illegitimate,
which violates checks and balances of scientific research.
DOA also renders theories immune to refutation,
because the author can claim that the theory was misconstrued when confronted with falsifying evidence, thus making it a moving target  [@szollosiArrestedTheoryDevelopment2021].
The fact that DOA is inherently problematic is illustrated by cases where third parties identify logical inconsistencies within a theory [e.g., @kissnerIDENTIFICATIONLOGICALINCONSISTENCY2008].
This demonstrates that original authors are not the ultimate authority on their theories.
DOA thus unduly impedes scientific progress, and authors should make good-faith efforts to make theories as accessible as possible; both in terms of availability and in terms of interpretability.

<!-- The data usually need to be integrated with other data. In addition, the data need to interoperate with applications or workflows for analysis, storage, and processing. -->

## Interoperability

Interoperability pertains to the property of information artefacts to "integrate or work together [...] with minimal effort" [@wilkinsonFAIRGuidingPrinciples2016a].
The original interoperability principles can be rephrased somewhat to apply to theory.
Firstly, theory and its associated metadata should use a formal, accessible, shared and broadly applicable language to facilitate (human- and) machine readability and reuse (I1).
The common practice of instantiating theory as lengthy prose or multi-interpretable bitmap image falls short of this ideal.
Instead, FAIR theory should, ad minimum,
be instantiated as 
as a type of data that is human- and machine-readable with as few interpretative steps as possible,
as previously recommended [@vanlissaWORCSWorkflowOpen2021].
Depending on the level of formalization of the theory,
different formats may be appropriate,
such as verbal statements in plain text,
mathematical formulae, <!-- AB: US readers may expect formulas here ? not sure-->
and statements expressed in some axiomatic system.
Examples of the latter include pseudo-code,
interpretable computer code,
and Gray's theory maps [@grayHowMapTheory2017].
While a theory represented as a bitmap image is not very interoperable,
the same image represented in the DOT language <!--AB citation needed; also Aaron has his own Julia package for graph language specs - not sure whether Aaron wants to refer to this?--> for representing graphs does meet this ideal.

Secondly, theory (meta)data should use vocabularies that follow FAIR principles (I2).
This is essentially a call to establish standardized ontologies,
which are themselves a type of theory [@meehlAppraisingAmendingTheories1990]. 
Thirdly, theory (meta)data should include qualified references to other (meta)data, including previous versions of the theory (I3).
The first part of this principle allows for nested theories;
for example, a theory that specifies causal relationships between constructs could refer back to an ontological theory from which those constructs are derived.
This can be achieved by linking the DOI of those nested theories [@ContributingCitationsReferences].
However, "[i]n systems with many dependencies, releasing new [...] versions can quickly become a nightmare."
The tension lies in balancing regular versioned updates with maintaining interconnected theories: changes risk breaking links between theories, but assuming every change does so leads to an overly sparse network.
In software development this problem is colloquially called "dependency hell" and usually addressed via semantic versioning.
Traditional version control only tracks changes but semantic versioning tracks what those changes mean to other users of the theory by using a specific format of version numbers.
We propose the following adaptation of semantic versioning for theories:

```
Given a version number MAJOR.MINOR.PATCH, increment the:

MAJOR version when you make incompatible changes, i.e., change the meaning or derived empierical statements
MINOR version when you expand the set of empierical statements in a backward compatible manner
PATCH version when you make backward compatible bug fixes, or clarifications
```

Semantic versioning and clearly documented interdependencies allow for tracing the provenance of a theory; keeping track of its prior versions and other theories that inspired it.

As the original definition of interoperability was somewhat narrow [@wilkinsonFAIRGuidingPrinciples2016a],
the concept has recently been further refined in terms of facilitating "successful communication between machines and between humans and machines", where "A and B are considered X-interoperable if a common operation X exists that can be applied to both" [@vogtFAIR20Extending2024].
This definition invites the question: *interoperable for what?*
Suitable answers for FAIR theory may be:
this theory is X-interoperable for deriving testable hypotheses,
or for the purpose of selecting relevant control variables,
or for the purpose of indicating the conditions necessary for observing a particular phenomenon.
This revised definition implies that theories have specific properties that incur affordances in terms of X-interoperability;
for example, Table \@ref(tab:tabmeehl) illustrates the affordances of Meehl's nine properties of strong theories (properties 3-8 are grouped because they all refer to functional form).

```{r tabmeehl}
data.frame(
  "Property" = c("1) Ontology", "2) Causal connections", "3-8) Functional Form", "9) Numerical Value"),
  "X-interoperability" = c("Variable selection", "Model specification, covariate selection, causal inference", "Deriving specific hypotheses", "Simulating data"), check.names = FALSE
) |>
papaja::apa_table()
```


<!-- Do we want to say something about this?
Interoperability of psychological theory may be limited when theories are instantiated in natural language without consideration of ontological complexities. -->
<!-- or as visualizations without a straightforward interpretation -->
<!-- What can go wrong? A well-formed sentence may be logically inconsistent (e.g., the theory that conceptualized father involvement simultaneously as mediator and moderator); a picture may seem sensible but there's no straightforward way to translate it to hypotheses, etc. -->
<!-- which are not machine-readable and l -->

With regard to the state of interoperability in contemporary psychology, 
Kurt Lewin's adage "there's nothing as practical as a good theory" [@lewinPsychologyProcessGroup1943] implies that ought to be highly X-interoperable in psychological researchers' day-to-day work.
But, as we argued, this is not the case.
The examples of X-interoperability offered in Table \@ref(tab:tabmeehl) illustrate that much can be gained by integrating theory directly into analysis workflows, and by making theory X-interoperable within software used for analysis.
For example, interoperable theory could be used
to select control variables for causal inference [@cinelliCrashCourseGood2022],
or to preregister the inferential procedure that would lead to specific modifications of a theory after analyzing empirical data [@peikertReproducibleResearchTutorial2021],
or to derive machine-readable hypotheses [@lakensImprovingTransparencyFalsifiability2021] which could be automatically evaluated through integration testing [@vanlissaUsingEndpointsCheck2023].
Furthermore, theories can be X-interoperable with each other to enable nesting, or using one theory to clarify elements of another theory.
For example, it should be possible to embed a theory about emotion regulation [e.g., @grossEmotionRegulationCurrent2015] within a theory of emotion regulation development [@morrisRoleFamilyContext2007].

## Reusability

If take cumulative knowledge acquisition to be a goal of scientific research, then Reusability is the ultimate purpose of making theory FAIR.
Applied to FAIR theory, reusability requires that  theory and its associated metadata are richly described with a plurality of accurate and relevant attributes (R1) with a clear and accessible license for reuse (R1.1), detailed provenance (R1.2), and (meta)data which meets domain-relevant community standards (R1.3).
As we will argue below, the most appropriate license for theory reuse is likely to be CC0 (no rights reserved), <!-- AB : maybe add a caveat that there may be country-specific legislation, company property rights, etc. and that this is of course no legal advice-->
although this should be combined with a culture of comprehensive (theory) citation to meet other open science requirements [REF TOP guidelines].
Criterion R1.2 is met by version control with Git and archival on Zenodo.
Domain-relevant community standards, to a large extent, remain to be established - and this paper is the first step towards further work in that area.

If we consider the current state of Reusability in psychological theory, there appears to be a norm *against* theory reuse:
*"[Theories are] like toothbrushes — no self-respecting person wants to use anyone else's"* [@mischelToothbrushProblem2008].
This norm impedes scientific progress.
Cumulative knowledge acquisition requires reusable theories that are continuously updated based on insights from new data [@degrootMethodologieGrondslagenVan1961].
In our workshops on FAIR theory, we similarly notice reluctance to the notion of reusing and adapting theories,
reflected in questions such as "who owns theory",
and "who determines how a theory may be reused or changed"?
These questions imply a norm against modifying theory without consent from the author reminiscent of the aforementioned problem of dependency on the author.

Licensing theories for reuse provides an unambiguous answer to such questions.
In determining what license is appropriate for theory,
it is important to consider that copyright law limits authors' rights based on the *idea-expression dichotomy* [@bently2010copyright],
which holds that copyright explicitly does not
*"extend to any idea, procedure, process, system, method of operation, concept, principle, or discovery"*.
Copyright may, however, extend to creative works expressing that idea (e.g., writing, visual illustrations).
It thus seems that vague, ambiguous verbal explanations of theories - in other words, those that fall short of the Accessibility criterion - are more likely to qualify for copyright protection than formal theories.
If copyright limits Reusability and does not cover ideas in their purest form (like formal theories),
then it might be counterproductive and possibly misleading to adopt a license that assumes copyright protection.
Furthermore, even if copyright would apply, academic research is covered under "fair use" exemptions,
so copyright would pose few restrictions to Reusability in scholarly communication.
Given these considerations, the CC0 (no rights reserved) license seems most appropriate for FAIR theory;
it explicitly waives all rights and encourages reuse.
In principle, CC0 does not require attribution.
Nevertheless, is essential that scholars do comprehensively cite theory,
including prior work that new theories are based on,
even in absence of legal obligations to do so,
to meet the definition of Reusability (R1.2, Table \@ref(tab:tabfair) and to comply with other definitions of open scholarship [@aalbersbergMakingScienceTransparent2018].


## Additional considerations

We can take inspiration from the field of computer science for well-established processes for iteratively improving information artefacts,  like computer code (which we also have successfully applied in the domain of reproducible research findings, see XXX). <!--AB cite WORCS and Aarons tutorial on how to do the same thing again..-->
Using version control systems, like git, would enhance the reusability of FAIR theory by thoroughly documenting every modification in a traceable and reversible manner.
Git also facilitates diffuse and adversarial collaboration,
as independent researchers can create independent versions of existing theories through "forking", or suggest modifications to existing theories via "pull requests".
In sum, version control using Git enables systematic, collaborative, and transparent theory development,
enables studying the provenance of a theory and investigating how well different iterations of the theory explain empirical evidence [@vanlissaUsingEndpointsCheck2023].

Even if scholars wish to diverge substantially from prior theory,
explicitly referring back to it enables clear comparison of the differences [@ramGitCanFacilitate2013].


From a meta-science perspective, FAIR theory facilitates studying the state of theory in a particular subfield, and comparing theories' substantive and structural properties. 

### Making Theories FAIR Accelerates Scientific Progress
Adopting the FAIR principles for theories can address key challenges in the current research landscape, where theories often remain isolated and underutilized. By making theories findable, accessible, interoperable, and reusable, researchers can ensure that their work is grounded in a shared, transparent, and cumulative body of knowledge. This approach enhances scholarly communication, allowing for greater scrutiny, replication, and collaboration across disciplines, ultimately leading to faster, more reliable, and more impactful scientific progress.



<!-- ## FAIR theory and Recognition & Rewards -->

<!-- FAIR theory provides a clear deliverable, and a clear goal, for scholars and institutions seeking to promote contributions to theory. -->
<!-- In the spirit of DORA, this helps researchers obtain credit for their theoretical contributions - obviating the necessity of publishing a purely theoretical paper, which can be challenging. -->



# Making a Theory FAIR

Open science infrastructure is an area of active development, and as such,
the approach proposed here should not be considered definitive,
but rather, as one proposal for a FAIR-compliant implementation of theory.
At the time of writing (2024), the integration of GitHub and Zenodo makes for a particularly user-friendly approach.
Nevertheless, it is important to stress that alternatives to GitHub  (Gitlab, Bitbucket, etc.) and Zenodo (e.g., institutional repositories) exist.
The principles described here
(using version control and archiving major versions) could be implemented in a different workflow.

The process described here can be largely automated in R using the `theorytools` package; see the package vignette on FAIR theory, `vignette("fairtheory", package = "theorytools")`.

## 1. Implementing the Theory 

Given that we structured our argument around the importance of FAIR theory for cumulative knowledge production through scientific research around the *empirical cycle*,
we decided to use it as an example for this tutorial.
Note that, while the empirical cycle is not explicitly referred to as a "theory" by De Groot, he derives it from "a theory of thinking" by Selz (REF).
We can thus consider it a meta-theory of the process of theory construction.
<!-- The first step in making a theory FAIR is constructing a specific *implementation* [@guestHowComputationalModeling2021]. -->
The empirical cycle is described on page 28 of @degrootMethodologyFoundationsInference1969:

> *Phase 1:* 'Observation': collection and grouping of empirical materials; (tentative) formation of hypotheses.  
*Phase 2:* 'Induction': formulation of hypotheses.  
*Phase 3:* 'Deduction': derivation of specific consequences from the hypotheses, in the form of testable predictions.  
*Phase 4:* 'Testing': of the hypotheses against new empirical materials, by way of checking whether or not the predictions are fulfilled.  
*Phase 5:* 'Evaluation': of the outcome of the testing procedure with respect to the hypotheses or theories stated, as well as with a view to subsequent, continued or related, investigations.

If we compare it to the levels of theory formalization [@guestHowComputationalModeling2021],
De Groot's theory is either at the "theory" or "specification" level.
It consists of a series of natural language statements.
We can increase the level of formalization, and present an "implementation" in the human- and machine-readable DOT language:

```
digraph {

  observation;
  induction;
  deduction;
  test;
  evaluation;
  
  observation -> induction;
  induction -> deduction;
  deduction -> test;
  test -> evaluation;
  evaluation -> observation;
  
}
```

```{r include = FALSE}
library(DiagrammeR)
library(DiagrammeRsvg)
library(rsvg)
ec_groot <- grViz(diagram = 
'digraph neato { node [fontsize = 6]; 
    edge [fontsize = 6];
    overlap = false; fontsize = 7;
  graph [layout = neato]
  
  observation [pos = "2,3!"];
  induction [pos = "3,2!"];
  deduction [pos = "3,1!"];
  test [pos = "1,1!"];
  evaluation [pos = "1,2!"];
  
  observation -> induction;
  induction -> deduction;
  deduction -> test;
  test -> evaluation;
  evaluation -> observation;
  
}')
ec_wagenmakers <- grViz(diagram = 
'digraph neato { node [fontsize = 6]; 
    edge [fontsize = 6];
    overlap = false; fontsize = 7;
  graph [layout = neato]
  
  subgraph cluster_discovery {
    label="Discovery";
    induction [label="New hypothesis" pos = "3,2!"];
    deduction [label="New prediction" pos = "3,1!"];
  }
  observation  [label="Old knowledge and old data" pos = "2,3!"];
  subgraph cluster_justification {
    label="Justification";
    test [label="Test on new data" pos = "1,1!"];
    evaluation [pos = "1,2!"];
  }

  observation -> induction [label="Speculate & explore" labeljust=r];
  induction -> deduction  [label="Deduce"];
  deduction -> test  [label="Design new experiment"];
  test -> evaluation  [label="Statistical analysis"];
  evaluation -> observation  [label="Knowledge accumulation"];

}')
ec_lissa <- grViz(diagram = 
'digraph neato { node [fontsize = 6]; 
    edge [fontsize = 6];
    overlap = false; fontsize = 7;
  graph [layout = neato]

  theory [pos = "2,3!"];
  prediction [pos = "3,2!"];
  data [pos = "1,1!"];
  test [pos = "2,1!"];
  results [pos = "1,2!"];
  
  theory -> prediction [label="deduction"];
  prediction -> test [label = "implement inferential procedure"];
  data -> results;
  test -> results;
  results -> theory [label="interpretation and generalization"];

}')
rsvg_svg(charToRaw(export_svg(ec_groot)), "ec_groot.svg")
rsvg_svg(charToRaw(export_svg(ec_wagenmakers)), "ec_wagenmakers.svg")
rsvg_svg(charToRaw(export_svg(ec_lissa)), "ec_lissa.svg")
```

This language describes the model as a directed graph.
Note that the code has been organized so that the first half describes an ontology of the entities the theory postulates,
and the second half describes their proposed interrelations.
This follows the first two properties of good theory according to Meehl [@meehlAppraisingAmendingTheories1990].

We can now write this implementation of the empirical cycle to a text file, say `empirical_cycle.dot`.

## 2. Creating a Project Folder

Create a new folder and copy the theory file from the previous step into it.
To help meet the Interoperability and Reusability criteria,
add two more files:
A README.md file with instructions for future users of your theory,
and a LICENSE file with the legal conditions for reuse.
We recommend the `CC0` license, but other options are available, see [https://choosealicense.com](https://choosealicense.com/non-software/).

### What's in a README?

The readme should contain information to help people get started with using your FAIR theory.
We suggest the following elements:

* Title, prefaced with `# FAIR theory: The Theory's Name`
* Description: A plain-text description of the theory and its scope
* Interoperability: Most README files contain a section labeled "Getting Started", "Instructions", or "How to Use". From a FAIR perspective, such a section might be better labeled "Interoperability", or "How to Use (Interoperability)". We propose explicitly addressing the theory's X-interoperability, telling users exactly what they can use the theory for, and how. For example, our example is implemented in the DOT language for describing graphs, so we would could provide instructions here on how to plot a DOT graph.
* Contributing: Pertaining to the Reusability criterion, this section should tell users the *social expectations regarding reuse and contributions*.
* License: The legal complement to the preceding section, this section should refer readers to the LICENSE file to learn about the *legal conditions of reuse*.
* Citing this work: Tell users how to cite the theory. Note that this section is redundant with the Zenodo archive, which has a preferred citation field. The disadvantage of redundant information is that you may have to maintain this section of the README going forward. The advantage is that documenting related works in the README makes it more readily accessible to users. We suggest a compromise: to retain this section, but refer the reader to the Zenodo page.
* Related works: This section should refer to the work that the FAIR theory is derived from, or documented in. Again, this is redundant with metadata entered in Zenodo (step 5). We nevertheless recommend using this section to refer to Zenodo, and/or to document one canonical reference for the theory that is unlikely to change going forward. For example, we referenced the original empirical cycle paper here:

```
This repository contains an implementation of the "empirical cycle",
a model proposed by De Groot and Spiekerman (1969, p. 28). See Zenodo for other related works.

> De Groot, A. D., & Spiekerman, J. A. A. (1969). Methodology:
Foundations of inference and research in the behavioral sciences.
De Gruyter Mouton. https://doi.org/10.1515/9783112313121
```

## 3. Version Control the Repository

The field of computer science provides well-established processes for creating information artefacts that can be iteratively improved.
In particular, the practice of version control offers extensive benefits for scientific work [@ramGitCanFacilitate2013, @vanlissaWORCSWorkflowOpen2021].
To version control our project, we initiate a Git repository in the project folder.
<!-- This can be done by [installing Git](https://git-scm.com/book/en/v2/Getting-Started-Installing-Git) locally, -->
<!-- opening a terminal in the project folder, -->
<!-- and running the command `git init`. -->
We subsequently create a remote repository to host a copy of this local Git repository on GitHub, which will in turn be archived.
<!-- To [do this on GitHub](https://github.blog/developer-skills/github/beginners-guide-to-github-repositories-how-to-create-your-first-repo/), create an account and press the button labeled `Create new repository`. -->
<!-- The default settings for the repository are fine; -->
<!-- for the next steps of the tutorial it  -->
Note that the repository
must be set to "Public" to take advantage of GitHub's Zenodo integration.
<!-- Copy the repository's URL, which usually has the form `https://github.com/username/repository.git`. -->
<!-- Next, in the terminal window, run the following lines of code sequentially: -->

<!-- ``` -->
<!-- git add . -->
<!-- git commit -m "First commit" -->
<!-- git remote add origin *[the repository URL you copied]* -->
<!-- git branch -M main -->
<!-- git push -u origin main -->
<!-- ``` -->
Push the local files to the Git remote repository, and keep them synchronized going forward.

## 4. Archive the Theory on Zenodo 

The process of archiving a GitHub repository on Zenodo is documented in a vignette in the `theorytools` R-package, so that it can be kept up-to-date.
We present a brief summary of the instructions at the time of writing here.
First, create a Zenodo account with your existing GitHub account.
Then in Zenodo, go to the GitHub section under your account.
Following the instructions on the page, activate Zenodo for your theory repository.
Then, create a new release of the GitHub repository.
Choose a tag and release title using our adapted semantic versioning, starting with version 1.0.0, if you intend to share your theory with the broader scientific community.
After publishing the release,
you should be able to see the archived version in your Zenodo account,
along with a DOI.

## 5. Entering Meta-Data

By default, Zenodo assumes that GitHub repositories contain software and documents them as such.
To document our archive as a FAIR theory requires adding some extra information on Zenodo.
Supplying the following information helps improve the Findability of a theory:

- Set the *resource type* to `Model`
- Verify that the *title* is prefaced with `FAIR theory:`
- Add the *keyword* `fairtheory`
- Optionally, submit the theory to the ["FAIR Theory Community"](https://zenodo.org/communities/fairtheory) to increase its findability
- List the DOIs/identifiers of *related works*. Use the `Relation` field as appropriate. For example:
    + `Is documented by` can be used to reference a theory paper you wrote, in which you introduce this FAIR theory
    + `Is derived from` could be used to reference a paper or book chapter that introduced an existing theory that was not previously made FAIR. We used `Is derived from` to reference De Groot and Spiekerman's empirical cycle.

## Automating these Steps

R-users can use the `theorytools` package to partly automate the preceding steps, for example, using following code (see the package documentation for more information):

```
install.packages("theorytools")
library(theorytools)
# Use worcs to check if GitHub permissions are set:
library(worcs)
check_git()
check_github()
# Create the theory repository:
fair_theory(path = "c:/theoryfolder/empirical_cycle",
            title = "The Empirical Cycle",
            theory_file = "empirical_cycle.dot",
            remote_repo = "empirical_cycle",
            add_license = "cc0")
```

Note that this function also automatically provides basic FAIR theory metadata to Zenodo.

## Forking Different Implementations of a Theory

De Groot's empirical cycle has inspired several authors,
but not all of them have interpreted his work the same.
For example, Wagenmakers and colleagues [-@wagenmakersCreativityVerificationCyclePsychological2018] write *"De Groot’s “empirical cycle,” shown here in Figure 6"* - but Figure 6 diverges substantially from De Groot's description, and from our implementation of it.
An important advantage of FAIR theory is that we can implement different versions of a theory, compare them, and document their cross-relationships.
We can take work that has been done before - in this case, the repository created above, and create an independent copy that we can modify as we wish, while retaining cross-references to the original.
This is achieved by ["forking the repository"](https://docs.github.com/en/pull-requests/collaborating-with-pull-requests/working-with-forks/fork-a-repo),
["cloning"](https://docs.github.com/en/pull-requests/collaborating-with-pull-requests/working-with-forks/fork-a-repo) the forked repository to our local computer,
making any changes we want, and then completing steps 4-5 of "Making a Theory FAIR".

We have implemented Wagenmakers and colleagues' version as a DOT graph
to illustrate some clear deviations from the original.
First, the phases of the cycle have been renamed.
While this change was not described in the paper,
we assumed that the labels are meant to illustrate the phases, not substantially change the ontology.
We represent this change by adding labels to the original DOT graph.
Note, however, that the labels suggest a focus on empirical psychology that was absent in the original formulation, which was more general.
Furthermore, the label "knowledge accumulation" invites the question of exactly *how* knowledge accumulates upon evaluation of a prior experiment.
As this lack of cumulative knowledge acquisition appears to be precisely where contemporary research practice falls short, this ambiguity invites further improvement of the theory.
Second, the authors mention an explicit change: *"We added the Whewell-Peirce-Reichenbach distinction between the context of discovery and the context of justification"*.
The DOT graph below shows our implementation of this version of the empirical cycle, by adding subgraphs.

```
digraph {

  subgraph cluster_discovery {
    label="Discovery";
    induction [label="New hypothesis"];
    deduction [label="New prediction"];
  }
  observation  [label="Old knowledge and old data"];
  subgraph cluster_justification {
    label="Justification";
    test [label="Test on new data"];
    evaluation;
  }

  observation -> induction [label="Speculate & explore"];
  induction -> deduction  [label="Deduce"];
  deduction -> test  [label="Design new experiment"];
  test -> evaluation  [label="Statistical analysis"];
  evaluation -> observation  [label="Knowledge accumulation"];

}
```

The first author was inspired by De Groot too,
but they conceive of the empirical cycle in yet another way.
First, notice that the nodes in De Groot's formulation mostly refer to processes.
This invites the question of what the deliverables are in each phase, or in other words: what actually changes when going through the cycle, except the scholar's mind.
In our implementation below, we account for this difference by having the nodes refer to specific deliverables; the edges now refer to processes.
Second, De Groot's strict distinction between processes of observation, induction, and deduction is not widely supported by philosophy of science.
<!-- In our representation, -->
<!-- induction is not a separate phase but a mode of reasoning by which specific observations are generalized into theory. -->
<!-- For example, the refutation of a hypothesized effect, -->
<!-- or the serendipitous observation of some pattern in data, -->
<!-- might be a reason to revise or construct theory. -->
<!-- Induction, incidentally, also occurs within the link from prediction to testing: -->
<!-- in the form of the inductive bias of methods used to perform the test, -->
<!-- and auxiliary assumptions that must be made to address remaining theoretical ambiguities. -->
<!-- # And then for example: I understand Aaron's work about inductive bias to be about the link "prediction -> test;", because the test is not identified without making auxiliary assumptions; if the auxiliary assumption is made based on the data, inductive bias is introduced. -->
<!-- ``` -->
For example, many have argued that observation is value-laden, and as such, involves induction.
The derivation of hypotheses from theory is also not purely deductive,
as auxiliary assumptions are often made (which are, again, an inductive process).
Furthermore, if the testing procedure is not explicitly defined before seeing the data, it incurs some inductive bias as well [REF Peikert].
With these alterations, we implement the empirical cycle as follows:

```
digraph {

  theory;
  prediction;
  data;
  test;
  results;
  
  theory -> prediction [label="deduction"];
  prediction -> test [label = "implement inferential procedure"];
  data -> results;
  test -> results [label = "apply to data"];
  results -> theory [label="interpretation and generalization"];

}
```

## Using FAIR theory to Perform Causal Inference

Some have argued that *causal explanations* are a property of good theory [REF Meehl, etc?].
According to Pearl and colleagues,
explicit assumptions about the direction of causality allow one to perform causal inference even on cross-sectional data.
Any formal theory that is explicit about direction of causality could thus be used to guide causal inference,
and could even be integrated into the analysis environment.

In this example, we illustrate how to use DAGs for causal inference, including the detection of a violation of the initial model and subsequent adaptation of the DAG. We could use that to illustrate updating FAIR theory:

https://currentprotocols.onlinelibrary.wiley.com/doi/full/10.1002/cpz1.45

We can find more examples of causal inference with DAGs in these tutorials:

https://www.r-bloggers.com/2019/08/causal-inference-with-dags-in-r/

https://www.r-bloggers.com/2018/08/applications-of-dags-in-causal-inference/


<!-- NOTES -->

<!-- * Theory is the vehicle of cumulative knowledge acquisition -->
<!-- * According to the empirical cycle, ideally, hypotheses are derived from theory, then tested in data, and theory is amended based on the resulting insights. When this cycle is regularly completed, theories become ever more veracious representations of social scientific phenomena. -->
<!-- * At present, there is concern over a theory crisis in the social sciences, which highlights that this system is not functioning as intended, and highlights the need for better theory. -->
<!-- * One source of potential improvements of theory methodology that has not been previously considered is computer science. -->
<!-- * The process of "iteratively improving" digital objects - in this case, computer code - is well understood. -->
<!-- * Recent work like the FAIR software principles has demonstrated that ideals of open science apply to computer science as well. -->
<!-- * This paper argues that, conversely, principles of computer science - particularly version control, algorithmic hypothesis generation (find better word; this is about using the digital theory object to derive implied hypotheses), and integrated testing, can also be used to improve theory methods in the social science. -->
<!-- * We introduce "FAIR theory", a digital research artifact to represent formal social scientific theories -->
<!-- * FAIR theory can be version controlled; any time new insights require modifications of the theory, these modifications can be documented in a traceable and reversable manner. Version control also enables diffuse collaboration in theory development, as other researchers can submit "pull requests" to suggest modifications of a theory, or can "fork" existing theories to create a spin-off from an existing theory. -->
<!-- * FAIR theory allows for algorithmic derivation of hypotheses implied by the theory. -->
<!-- * FAIR theory enables integration testing: researchers can build a "test suite" of evidence that must be explainable by the theory, and any modifications of the theory must also pass the test suite. -->
<!-- * To illustrate FAIR theory's potential to accelerate cumulative knowledge acquisition, we present several tutorial examples, developed in collaboration with applied researchers across fields of social science. -->

# Discussion

The replication crisis has brought the inadequacies of contemporary theoretical practices in the social sciences into focus.
Psychological theories often fall short of all FAIR principles: they are hard to find and access, have limited interoperability, and are rarely reused.
These limitations impede cumulative knowledge production in our field,
leading to an accumulation of "one-shot" empirical findings, without commensurate advancement in our principled understanding of psychological phenomena.
We argued that applying the FAIR principles to theory offers a structured solution to these shortcomings.
We demonstrated how to create, version-control, and archive theories as digital information artifacts.
We introduced the `theorytools` R-package to partly automate these processes, reducing barrier of entry for researchers,
and creating a FAIR resource for theory construction tools and documentation that can be continuously updated as best practices develop further.

Making theory FAIR allows researchers to more easily find a relevant framework;
access and understand it; interact with it in a very practical manner, for example, by deriving predictions from it, or using it to select control variables; and reuse it, contributing changes to existing theories or splitting of in a new direction.
Whereas the idea of theory can be quite nebulous to empirical social scientists,
FAIR theory makes theoretical work practical and tangible, incorporating theory into scholars' workflows.
Having a concrete object to iterate upon facilitates the systematic improvement and iterative refinement of psychological theories, thus substantially increasing the efficiency of research.
While FAIR theory does not directly resolve the problem of strategic ambiguity, it does provide a framework within which scholars can increase the precision and formalization of theories.
FAIR principles also facilitates new ways of collaboration,
leveraging tools like Git for version control and Zenodo for archiving to document provenance and facilitate contributions from diverse researchers.
<!-- These practices align with the open science ethos, ensuring theories evolve dynamically based on empirical evidence and collaborative input. -->

## Strengths

One important strength of FAIR theory is that it provides much-needed open science methods for the underemphasized inductive phase of the empirical cycle.
Most extant open science methods focus on increased rigor in testing, but provide little guidance as to what to do with the newly collected empirical evidence.
By providing much-needed open science methods for theory construction,
FAIR theory helps restore the balance between inductive and deductive research and contributes to closing the "open empirical cycle" [REF Hoijtink].

Our approach aligns closely with contemporary developments in open science,
such as modular publishing, interdisciplinarity, meta-research, and team science.
The advantage of modular publishing is that authors can be credited for theory development.
Given the current emphasis on empirical papers [REF], theoretical papers can be hard to publish.
FAIR theories, by contrast, can be readily disseminated as citable information artifacts, thus changing the incentive structure to favor theory development.

Interdisciplinarity benefits from FAIR theory's accessibility across different fields; thus, theoretical frameworks can be reused, adapted, or used for analogical modeling [REF Oisin paper].
Meta-research benefit from the fact that FAIR theory enables studying the structure, content, and development of theories over time.
In terms of team science, FAIR theory facilitates collaboration by ensuring that all contributors have access to the same information and
clarifying any remaining areas of contention or misunderstanding. 
Version control provides a framework to resolve parallel developments from multiple collaborators in a non-destructive manner.
This facilitates collaboration across geographical boundaries,
and adversarial collaboration, where others strive to falsify a theory or identify its inconsistencies, and democratizes collaboration with as-of-yet unknown collaborators via platforms like GitHub, where researchers outside one's network can identify issues or suggest improvements to theories.

Finally, FAIR theory plays an important role in science communication, because theory synthesizes contemporary scientific understanding about a phenomenon.
Theory bridges the gap between academic research and practitioners by summarizing actionable insights, relieving practitioners from the need to sift through extensive empirical literature.
By providing a mechanism for iterative improvement based on emerging evidence, FAIR theory also supports effective evidence-based decision making.

## Limitations

One important limitation of the present work is that,
while we build on well-established information architecture like Zenodo,
it is unlikely that the proposed metadata standard is definitive.
Community adoption can reveal areas of further improvement.
Furthermore, at the time of writing, dedicated indexing systems for FAIR theory are non-existent.
Using the Zenodo search function and submitting theories to the "FAIR Theory Community" on Zenodo can help overcome this limitation in the short term.

Another limitation is the learning curve associated with tools like Git and Zenodo.
The `theorytools` R-package mitigates this limitation by automating key steps in the process.
Moreover, the initial investment in time can be offset by long-term productivity gains and increased impact of FAIR theory.
One barrier to adoption of FAIR theory is cultural resistance to sharing and modifying theories, also known as the "toothbrush problem".
Education might help address this limitation; with this in mind,
we are developing open educational materials on theory development.

One limitation of scope is that FAIR theory does not directly resolve problems related to strategic ambiguity [REF] and lack of theory formalization [REF].
However, our work does establish a framework within which theories can be further formalized.
The example of the empirical cycle demonstrates how FAIR principles can guide theory formalization and foster cumulative progress.
Another limitation of scope is that FAIR theory does not resolve other related issues in social sciences, such as the measurement crisis [REF] and lack of standardized ontologies for psychological constructs [REF].
However, our work here provides a template for addressing such challenges,
and any advancements in the areas of measurement and ontology will serve to amplify the value of FAIR theories, particularly when such resources are cross-referenced in the metadata (e.g., on Zenodo).

## Future Directions

One remaining issue that intersects with FAIR theory is the measurement and operationalization of psychological constructs.
Aside from the aforementioned "theory crisis", there has been talk of a "measurement crisis":  <!--AB very important point that I was already missing in the introduction; seems we also need FAIR measurements :) -->
it is not always clear how theoretical constructs are operationalized, and many existing instruments have poor psychometric properties [REF].
Additionally, the "jingle-jangle" fallacy is prevalent in the social sciences:
the same term is often used for distinct constructs, and conversely, different terms are used to refer to the same construct.
FAIR theory can help address the measurement crisis:
since theories can reference other theories and resources, it is possible to extend a structural theory with a theory of 

FAIR theory incorporates theory into open science workflows,
facilitates scholarly communication about theories,
making it easier to share theories with less opportunity for ambiguity and misunderstanding.
FAIR Theories are easier to find, and facilitate sharing, reusing, and updating open theories.
More efficient and transparent communication about theory democratizes and accelerates cumulative knowledge acquisition,
removes barriers for knowledge exchange with the global scholarly community,
opens theory development to diverse perspectives, and enables (distributed and adversarial) collaboration.

## Conclusion

FAIR theory is a major step forwards towards more transparent, collaborative, and efficient theory construction.
It provides much-needed open science methods for the inductive phase of the empirical cycle,
closing a critical gap in the scientific process.
FAIR theory makes theory more tangible, enabling scholars to incorporate it in their day-to-day workflows in order to derive hypotheses, select control variables, and contribute new data-driven insights.
This paves the way for more theory-driven scholarship,
and accelerates cumulative knowledge acquisition in the social sciences and beyond.


\newpage

# References

::: {#refs custom-style="Bibliography"}
:::
