@book{degrootMethodologieGrondslagenVan1961,
  title = {Methodologie: Grondslagen van onderzoek en denken in de gedragswetenschappen},
  shorttitle = {Methodologie},
  author = {family=Groot, given=Adriaan D., prefix=de, useprefix=true},
  date = {1961},
  eprint = {6hiBDwAAQBAJ},
  eprinttype = {googlebooks},
  publisher = {Uitgeverij Mouton},
  location = {'s Gravenhage},
  isbn = {90-279-7721-6},
  langid = {dutch},
  pagetotal = {440},
  keywords = {Language Arts & Disciplines / Linguistics / General}
}

@article{kuhbergerPublicationBiasPsychology2014,
  title = {Publication {{Bias}} in {{Psychology}}: {{A Diagnosis Based}} on the {{Correlation}} between {{Effect Size}} and {{Sample Size}}},
  shorttitle = {Publication {{Bias}} in {{Psychology}}},
  author = {Kühberger, Anton and Fritz, Astrid and Scherndl, Thomas},
  date = {2014-09-05},
  journaltitle = {PLoS ONE},
  shortjournal = {PLoS One},
  volume = {9},
  number = {9},
  eprint = {25192357},
  eprinttype = {pmid},
  pages = {e105825},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0105825},
  url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4156299/},
  urldate = {2024-03-09},
  abstract = {Background The p value obtained from a significance test provides no information about the magnitude or importance of the underlying phenomenon. Therefore, additional reporting of effect size is often recommended. Effect sizes are theoretically independent from sample size. Yet this may not hold true empirically: non-independence could indicate publication bias. Methods We investigate whether effect size is independent from sample size in psychological research. We randomly sampled 1,000 psychological articles from all areas of psychological research. We extracted p values, effect sizes, and sample sizes of all empirical papers, and calculated the correlation between effect size and sample size, and investigated the distribution of p values. Results We found a negative correlation of r{$\mkern1mu$}={$\mkern1mu$}−.45 [95\% CI: −.53; −.35] between effect size and sample size. In addition, we found an inordinately high number of p values just passing the boundary of significance. Additional data showed that neither implicit nor explicit power analysis could account for this pattern of findings. Conclusion The negative correlation between effect size and samples size, and the biased distribution of p values indicate pervasive publication bias in the entire field of psychology.},
  pmcid = {PMC4156299},
  file = {C:\Users\vanlissa\Zotero\storage\JMJ6JSQX\Kühberger et al. - 2014 - Publication Bias in Psychology A Diagnosis Based .pdf}
}

@incollection{lakatosHistoryScienceIts1971,
  title = {History of {{Science}} and Its {{Rational Reconstructions}}},
  booktitle = {{{PSA}} 1970: {{In Memory}} of {{Rudolf Carnap Proceedings}} of the 1970 {{Biennial Meeting Philosophy}} of {{Science Association}}},
  author = {Lakatos, Imre},
  editor = {Buck, Roger C. and Cohen, Robert S.},
  date = {1971},
  series = {Boston {{Studies}} in the {{Philosophy}} of {{Science}}},
  pages = {91--136},
  publisher = {Springer Netherlands},
  location = {Dordrecht},
  doi = {10.1007/978-94-010-3142-4_7},
  url = {https://doi.org/10.1007/978-94-010-3142-4_7},
  urldate = {2024-02-08},
  abstract = {“Philosophy of science without history of science is empty; history of science without philosophy of science is blind”. Taking its cue from this paraphrase of Kant’s famous dictum, this paper intends to explain how the historiography of science should learn from the philosophy of science and vice versa. It will be argued that (a) philosophy of science provides normative methodologies in terms of which the historian reconstructs ‘internal history’ and thereby provides a rational explanation of the growth of objective knowledge; (b) two competing methodologies can be evaluated with the help of (normatively interpreted) history; (c) any rational reconstruction of history needs to be supplemented by an empirical (socio-psychological) ‘external history’.},
  isbn = {978-94-010-3142-4},
  langid = {english},
  keywords = {Actual History,Demarcation Criterion,Inductive Generalisation,Rational Reconstruction,Rationality Theory},
  file = {C:\Users\vanlissa\Zotero\storage\K7SMK27H\Lakatos - HISTORY OF SCIENCE AND ITS RATIONAL RECONSTRUCTION.pdf}
}

@article{lamprechtFAIRPrinciplesResearch2019,
  title = {Towards {{FAIR}} Principles for Research Software},
  author = {Lamprecht, Anna-Lena and Garcia, Leyla and Kuzak, Mateusz and Martinez, Carlos and Arcila, Ricardo and Martin Del Pico, Eva and Dominguez Del Angel, Victoria and family=Sandt, given=Stephanie, prefix=van de, useprefix=true and Ison, Jon and Martinez, Paula Andrea and McQuilton, Peter and Valencia, Alfonso and Harrow, Jennifer and Psomopoulos, Fotis and Gelpi, Josep Ll. and Chue Hong, Neil and Goble, Carole and Capella-Gutierrez, Salvador},
  editor = {Groth, Paul},
  date = {2019-11-13},
  journaltitle = {Data Science},
  shortjournal = {DS},
  pages = {1--23},
  issn = {24518492, 24518484},
  doi = {10.3233/DS-190026},
  url = {https://www.medra.org/servlet/aliasResolver?alias=iospress&doi=10.3233/DS-190026},
  urldate = {2020-05-19},
  file = {C:\Users\vanlissa\Zotero\storage\4YVQJARQ\Lamprecht et al_2019_Towards FAIR principles for research software.pdf}
}

@article{lavelleWhenCrisisBecomes2021,
  title = {When a {{Crisis Becomes}} an {{Opportunity}}: {{The Role}} of {{Replications}} in {{Making Better Theories}}},
  shorttitle = {When a {{Crisis Becomes}} an {{Opportunity}}},
  author = {Lavelle, Jane Suilin},
  date = {2021-04-14},
  journaltitle = {The British Journal for the Philosophy of Science},
  shortjournal = {The British Journal for the Philosophy of Science},
  pages = {714812},
  issn = {0007-0882, 1464-3537},
  doi = {10.1086/714812},
  url = {https://www.journals.uchicago.edu/doi/10.1086/714812},
  urldate = {2022-03-01},
  abstract = {While it is widely acknowledged that psychology is in the throes of a replication ‘crisis’, relatively little attention has been paid to the role theory plays in our evaluation of replications as ‘failed’ or ‘successful’. This paper applies well-known arguments in philosophy of science about the interplay between theory and experiment to a contemporary case study of infants’ understanding of false belief (Onishi and Baillargeon [2005]), and attempts to replicate it. It argues that the lack of consensus about over-arching theories informing both the concepts under study and the methodologies used to track them means that researchers disagree over which experiments constitute replications of the original. The second part of the paper places this specific debate within a broader discussion of the replication crisis as a crisis of ‘theory’, developing work by Muthukrishna and Henrich ([2018]) and Bird ([2018]). Bird argues that the lack of agreed over-arching theories in psychology means that a high rate of replication failure is to be expected; this paper agrees with his diagnosis but challenges his proposal that more replication will resolve the problem.},
  langid = {english},
  file = {C:\Users\vanlissa\Zotero\storage\XDG74HWE\Lavelle - 2021 - When a Crisis Becomes an Opportunity The Role of .pdf}
}

@article{mcphetresDecadeTheoryReflected2021,
  title = {A Decade of Theory as Reflected in {{Psychological Science}} (2009–2019)},
  author = {McPhetres, Jonathon and Albayrak-Aydemir, Nihan and Mendes, Ana Barbosa and Chow, Elvina C. and Gonzalez-Marquez, Patricio and Loukras, Erin and Maus, Annika and O’Mahony, Aoife and Pomareda, Christina and Primbs, Maximilian A. and Sackman, Shalaine L. and Smithson, Conor J. R. and Volodko, Kirill},
  date = {2021-03-05},
  journaltitle = {PLOS ONE},
  shortjournal = {PLOS ONE},
  volume = {16},
  number = {3},
  pages = {e0247986},
  publisher = {Public Library of Science},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0247986},
  url = {https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0247986},
  urldate = {2022-03-09},
  abstract = {The dominant belief is that science progresses by testing theories and moving towards theoretical consensus. While it’s implicitly assumed that psychology operates in this manner, critical discussions claim that the field suffers from a lack of cumulative theory. To examine this paradox, we analysed research published in Psychological Science from 2009–2019 (N = 2,225). We found mention of 359 theories in-text, most were referred to only once. Only 53.66\% of all manuscripts included the word theory, and only 15.33\% explicitly claimed to test predictions derived from theories. We interpret this to suggest that the majority of research published in this flagship journal is not driven by theory, nor can it be contributing to cumulative theory building. These data provide insight into the kinds of research psychologists are conducting and raises questions about the role of theory in the psychological sciences.},
  langid = {english},
  keywords = {Cognitive psychology,Experimental psychology,Psychologists,Psychology,Reaction time,Scientific publishing,Scientists,Semantics},
  file = {C\:\\Users\\vanlissa\\Zotero\\storage\\DZ9FJXZN\\McPhetres et al_2021_A decade of theory as reflected in Psychological Science (2009–2019).pdf;C\:\\Users\\vanlissa\\Zotero\\storage\\ETP3X67C\\article.html}
}

@article{meehlTheoreticalRisksTabular1978,
  title = {Theoretical {{Risks}} and {{Tabular Asterisks}}: {{Sir Karl}}, {{Sir Ronald}}, and the {{Slow Progress}} of {{Soft Psychology}}},
  author = {Meehl, Paul E},
  date = {1978},
  journaltitle = {Journal of Consulting \& Clinical Psychology},
  volume = {46},
  number = {4},
  pages = {806--834},
  langid = {english},
  file = {C:\Users\vanlissa\Zotero\storage\8YNMP9TQ\Meehl - Theoretical Risks and Tabular Asterisks.pdf}
}

@article{mischelToothbrushProblem2008,
  title = {The {{Toothbrush Problem}}},
  author = {Mischel, Walter},
  date = {2008-12-01},
  journaltitle = {APS Observer},
  volume = {21},
  url = {https://www.psychologicalscience.org/observer/the-toothbrush-problem},
  urldate = {2024-05-07},
  abstract = {In these columns, I have been discussing our “urban legends” — the often unspoken but widely shared understandings and misunderstandings about how to build a research-focused academic life in psychology. My goal is to look …},
  langid = {american},
  file = {C:\Users\vanlissa\Zotero\storage\BDLJLLY3\the-toothbrush-problem.html}
}

@article{nosekPromotingOpenResearch2015a,
  title = {Promoting an Open Research Culture},
  author = {Nosek, B. A. and Alter, G. and Banks, G. C. and Borsboom, D. and Bowman, S. D. and Breckler, S. J. and Buck, S. and Chambers, C. D. and Chin, G. and Christensen, G. and Contestabile, M. and Dafoe, A. and Eich, E. and Freese, J. and Glennerster, R. and Goroff, D. and Green, D. P. and Hesse, B. and Humphreys, M. and Ishiyama, J. and Karlan, D. and Kraut, A. and Lupia, A. and Mabry, P. and Madon, T. and Malhotra, N. and Mayo-Wilson, E. and McNutt, M. and Miguel, E. and Paluck, E. Levy and Simonsohn, U. and Soderberg, C. and Spellman, B. A. and Turitto, J. and VandenBos, G. and Vazire, S. and Wagenmakers, E. J. and Wilson, R. and Yarkoni, T.},
  date = {2015-06-26},
  journaltitle = {Science},
  volume = {348},
  number = {6242},
  eprint = {26113702},
  eprinttype = {pmid},
  pages = {1422--1425},
  issn = {0036-8075, 1095-9203},
  doi = {10.1126/science.aab2374},
  url = {http://science.sciencemag.org/content/348/6242/1422},
  urldate = {2019-02-07},
  abstract = {Author guidelines for journals could help to promote transparency, openness, and reproducibility Author guidelines for journals could help to promote transparency, openness, and reproducibility},
  langid = {english},
  file = {C\:\\Users\\vanlissa\\Zotero\\storage\\QMIA9CDD\\Nosek et al. - 2015 - Promoting an open research culture.pdf;C\:\\Users\\vanlissa\\Zotero\\storage\\CHZTCVV2\\1422.html}
}

@article{oberauerAddressingTheoryCrisis2019,
  title = {Addressing the Theory Crisis in Psychology},
  author = {Oberauer, Klaus and Lewandowsky, Stephan},
  date = {2019-10-01},
  journaltitle = {Psychonomic Bulletin \& Review},
  shortjournal = {Psychon Bull Rev},
  volume = {26},
  number = {5},
  pages = {1596--1618},
  issn = {1531-5320},
  doi = {10.3758/s13423-019-01645-2},
  url = {https://doi.org/10.3758/s13423-019-01645-2},
  urldate = {2022-10-20},
  abstract = {A worrying number of psychological findings are not replicable. Diagnoses of the causes of this “replication crisis,” and recommendations to address it, have nearly exclusively focused on methods of data collection, analysis, and reporting. We argue that a further cause of poor replicability is the often weak logical link between theories and their empirical tests. We propose a distinction between discovery-oriented and theory-testing research. In discovery-oriented research, theories do not strongly imply hypotheses by which they can be tested, but rather define a search space for the discovery of effects that would support them. Failures to find these effects do not question the theory. This endeavor necessarily engenders a high risk of Type I errors—that is, publication of findings that will not replicate. Theory-testing research, by contrast, relies on theories that strongly imply hypotheses, such that disconfirmation of the hypothesis provides evidence against the theory. Theory-testing research engenders a smaller risk of Type I errors. A strong link between theories and hypotheses is best achieved by formalizing theories as computational models. We critically revisit recommendations for addressing the “replication crisis,” including the proposal to distinguish exploratory from confirmatory research, and the preregistration of hypotheses and analysis plans.},
  langid = {english},
  keywords = {Computational modeling,Hypothesis testing,Preregistration,Replication,Scientific inference},
  file = {C:\Users\vanlissa\Zotero\storage\WLSKH5PR\Oberauer and Lewandowsky - 2019 - Addressing the theory crisis in psychology.pdf}
}

@article{robinaughInvisibleHandsFine2021,
  title = {Invisible {{Hands}} and {{Fine Calipers}}: {{A Call}} to {{Use Formal Theory}} as a {{Toolkit}} for {{Theory Construction}}},
  shorttitle = {Invisible {{Hands}} and {{Fine Calipers}}},
  author = {Robinaugh, Donald J. and Haslbeck, Jonas M. B. and Ryan, Oisín and Fried, Eiko I. and Waldorp, Lourens J.},
  date = {2021-07-01},
  journaltitle = {Perspectives on Psychological Science},
  shortjournal = {Perspect Psychol Sci},
  volume = {16},
  number = {4},
  pages = {725--743},
  publisher = {SAGE Publications Inc},
  issn = {1745-6916},
  doi = {10.1177/1745691620974697},
  url = {https://doi.org/10.1177/1745691620974697},
  urldate = {2024-02-08},
  abstract = {In recent years, a growing chorus of researchers has argued that psychological theory is in a state of crisis: Theories are rarely developed in a way that indicates an accumulation of knowledge. Paul Meehl raised this very concern more than 40 years ago. Yet in the ensuing decades, little has improved. We aim to chart a better path forward for psychological theory by revisiting Meehl’s criticisms, his proposed solution, and the reasons his solution failed to meaningfully change the status of psychological theory. We argue that Meehl identified serious shortcomings in our evaluation of psychological theories and that his proposed solution would substantially strengthen theory testing. However, we also argue that Meehl failed to provide researchers with the tools necessary to construct the kinds of rigorous theories his approach required. To advance psychological theory, we must equip researchers with tools that allow them to better generate, evaluate, and develop their theories. We argue that formal theories provide this much-needed set of tools, equipping researchers with tools for thinking, evaluating explanation, enhancing measurement, informing theory development, and promoting the collaborative construction of psychological theories.},
  langid = {english},
  file = {C:\Users\vanlissa\Zotero\storage\I3UI652D\Robinaugh et al. - 2021 - Invisible Hands and Fine Calipers A Call to Use F.pdf}
}

@article{scheelExcessPositiveResults2021,
  title = {An {{Excess}} of {{Positive Results}}: {{Comparing}} the {{Standard Psychology Literature With Registered Reports}}},
  shorttitle = {An {{Excess}} of {{Positive Results}}},
  author = {Scheel, Anne M. and Schijen, Mitchell R. M. J. and Lakens, Daniël},
  date = {2021-04-01},
  journaltitle = {Advances in Methods and Practices in Psychological Science},
  shortjournal = {Advances in Methods and Practices in Psychological Science},
  volume = {4},
  number = {2},
  pages = {25152459211007467},
  publisher = {SAGE Publications Inc},
  issn = {2515-2459},
  doi = {10.1177/25152459211007467},
  url = {https://doi.org/10.1177/25152459211007467},
  urldate = {2022-04-15},
  abstract = {Selectively publishing results that support the tested hypotheses (?positive? results) distorts the available evidence for scientific claims. For the past decade, psychological scientists have been increasingly concerned about the degree of such distortion in their literature. A new publication format has been developed to prevent selective reporting: In Registered Reports (RRs), peer review and the decision to publish take place before results are known. We compared the results in published RRs (N = 71 as of November 2018) with a random sample of hypothesis-testing studies from the standard literature (N = 152) in psychology. Analyzing the first hypothesis of each article, we found 96\% positive results in standard reports but only 44\% positive results in RRs. We discuss possible explanations for this large difference and suggest that a plausible factor is the reduction of publication bias and/or Type I error inflation in the RR literature.},
  file = {C:\Users\vanlissa\Zotero\storage\LEW9B5MX\Scheel et al_2021_An Excess of Positive Results.pdf}
}

@article{scheelWhyHypothesisTesters2021,
  title = {Why {{Hypothesis Testers Should Spend Less Time Testing Hypotheses}}},
  author = {Scheel, Anne M. and Tiokhin, Leonid and Isager, Peder M. and Lakens, Daniël},
  date = {2021-07-01},
  journaltitle = {Perspectives on Psychological Science},
  shortjournal = {Perspect Psychol Sci},
  volume = {16},
  number = {4},
  pages = {744--755},
  publisher = {SAGE Publications Inc},
  issn = {1745-6916},
  doi = {10.1177/1745691620966795},
  url = {https://doi.org/10.1177/1745691620966795},
  urldate = {2023-10-12},
  abstract = {For almost half a century, Paul Meehl educated psychologists about how the mindless use of null-hypothesis significance tests made research on theories in the social sciences basically uninterpretable. In response to the replication crisis, reforms in psychology have focused on formalizing procedures for testing hypotheses. These reforms were necessary and influential. However, as an unexpected consequence, psychological scientists have begun to realize that they may not be ready to test hypotheses. Forcing researchers to prematurely test hypotheses before they have established a sound “derivation chain” between test and theory is counterproductive. Instead, various nonconfirmatory research activities should be used to obtain the inputs necessary to make hypothesis tests informative. Before testing hypotheses, researchers should spend more time forming concepts, developing valid measures, establishing the causal relationships between concepts and the functional form of those relationships, and identifying boundary conditions and auxiliary assumptions. Providing these inputs should be recognized and incentivized as a crucial goal in itself. In this article, we discuss how shifting the focus to nonconfirmatory research can tie together many loose ends of psychology’s reform movement and help us to develop strong, testable theories, as Paul Meehl urged.},
  langid = {english},
  file = {C:\Users\vanlissa\Zotero\storage\EIJPIJHY\Scheel et al. - 2021 - Why Hypothesis Testers Should Spend Less Time Test.pdf}
}

@article{scheelWhyMostPsychological2022,
  title = {Why Most Psychological Research Findings Are Not Even Wrong},
  author = {Scheel, Anne M.},
  date = {2022},
  journaltitle = {Infant and Child Development},
  volume = {31},
  number = {1},
  pages = {e2295},
  issn = {1522-7219},
  doi = {10.1002/icd.2295},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/icd.2295},
  urldate = {2022-03-01},
  abstract = {Psychology's replication crisis is typically conceptualized as the insight that the published literature contains a worrying amount of unreplicable, false-positive findings. At the same time, meta-scientific attempts to assess the crisis in more detail have reported substantial difficulties in identifying unambiguous definitions of the scientific claims in published articles and determining how they are connected to the presented evidence. I argue that most claims in the literature are so critically underspecified that attempts to empirically evaluate them are doomed to failure—they are not even wrong. Meta-scientists should beware of the flawed assumption that the psychological literature is a collection of well-defined claims. To move beyond the crisis, psychologists must reconsider and rebuild the conceptual basis of their hypotheses before trying to test them.},
  langid = {english},
  keywords = {falsification,hypothesis testing,replication crisis,reproducibility,scientific inference},
  file = {C\:\\Users\\vanlissa\\Zotero\\storage\\RCSX27VL\\Scheel_2022_Why most psychological research findings are not even wrong.pdf;C\:\\Users\\vanlissa\\Zotero\\storage\\77G7YKYE\\icd.html}
}

@article{szollosiArrestedTheoryDevelopment2021,
  title = {Arrested Theory Development: {{The}} Misguided Distinction between Exploratory and Confirmatory Research},
  author = {Szollosi, Aba and Donkin, Chris},
  date = {2021},
  journaltitle = {Perspectives on Psychological Science},
  volume = {16},
  number = {4},
  pages = {717--724},
  doi = {10.1177/1745691620966796},
  abstract = {Science progresses by finding and correcting problems in theories. Good theories are those that help facilitate this process by being hard-to-vary: they explain what they are supposed to explain, they are consistent with other good theories, and they are not easily adaptable to explain anything. Here we argue that, rather than a lack of distinction between exploratory and confirmatory research, an abundance of flexible theories is a better explanation for current replicability problems of psychology. We also explain why popular methods-oriented solutions fail to address the real problem of flexibility. Instead, we propose that a greater emphasis on theory criticism by argument would improve replicability.},
  langid = {english},
  file = {C:\Users\vanlissa\Zotero\storage\AULQYHPI\Szollosi and Donkin - Arrested theory development The misguided distinc.pdf}
}
