@article{aalbersbergMakingScienceTransparent2018,
  title = {Making {{Science Transparent By Default}}; {{Introducing}} the {{TOP Statement}}},
  author = {family=Aalbersberg, given=IJsbrand Jan, given-i={{IJ}}J and Appleyard, Tom and Brookhart, Sarah and Carpenter, Todd and Clarke, Michael and Curry, Stephen and Dahl, Josh and DeHaven, Alexander Carl and Eich, Eric and Franko, Maryrose and Freedman, Len and Graf, Chris and Grant, Sean and Hanson, Brooks and Joseph, Heather and Kiermer, Veronique and Kramer, Bianca and Kraut, Alan and Karn, Roshan Kumar and Lee, Carole and MacFarlane, Aki and Martone, Maryann and Mayo-Wilson, Evan and McNutt, Marcia and McPhail, Meredith and Mellor, David Thomas and Moher, David and Mudditt, Alison and Nosek, Brian A. and Orland, Belinda and Parker, Timothy H. and Parsons, Mark and Patterson, Mark and Santos, Solange and Shore, Carolyn and Simons, Daniel J. and Spellman, Bobbie and Spies, Jeffrey Robert and Spitzer, Matthew and Stodden, Victoria and Swaminathan, Sowmya and Sweet, Deborah and Tsui, Anne and Vazire, Simine},
  date = {2018-02-15},
  doi = {10.31219/osf.io/sm78t},
  url = {https://osf.io/sm78t},
  urldate = {2020-01-08},
  abstract = {In order to increase the replicability of scientific work, the scientific community has called for practices designed to increase the transparency of research (McNutt, 2014; Nosek et al., 2015). The validity of a scientific claim depends not on the reputation of those making the claim, the venue in which the claim is made, or the novelty of the result, but rather on the empirical evidence provided by the underlying data and methods. Proper evaluation of  the merits of scientific findings requires availability of the methods, materials, and data and the reasoned argument that serve as the basis for the published conclusions (Claerbout and Karrenbach 1992; Donoho et al 2009; Stodden et al 2013; Borwein et al 2013; Munafò et al, 2017). Wide and growing support for these principles (see, for example, signatories to Declaration on Research Assessment, DORA, https://sfdora.org/, and the Transparency and Openness Promotion Guidelines https://cos.io/our-services/top-guidelines/) must be coupled with guidelines to increase open sharing of data and research materials, use of reporting guidelines, preregistration, and replication. We propose that, going forward, authors of all scientific articles disclose the availability and location of all research items, including data, materials, and code, related to their published articles in what we will refer to as a TOP Statement.}
}

@book{bently2010copyright,
  title = {Copyright and {{Piracy}}: {{An}} Interdisciplinary Critique},
  author = {Bently, Lionel and Davis, Jennifer and Ginsburg, Jane C},
  date = {2010},
  volume = {13},
  publisher = {Cambridge University Press}
}

@article{boscoMetaBUSVehicleFacilitating2017,
  title = {{{MetaBUS}} as a Vehicle for Facilitating Meta-Analysis},
  author = {Bosco, Frank A. and Uggerslev, Krista L. and Steel, Piers},
  date = {2017-03-01},
  journaltitle = {Human Resource Management Review},
  shortjournal = {Human Resource Management Review},
  series = {Using {{Meta-analysis}} to {{Enhance}} Our {{Understanding}} of {{Human Resource Management}}},
  volume = {27},
  number = {1},
  pages = {237--254},
  issn = {1053-4822},
  doi = {10.1016/j.hrmr.2016.09.013},
  url = {https://www.sciencedirect.com/science/article/pii/S1053482216300675},
  urldate = {2024-12-05},
  abstract = {To address new research questions and get a clearer picture of research, scientists and practitioners in human resource management have come to rely heavily on meta-analyses. However, meta-analyses may take months or years to produce and are becoming increasingly difficult to produce as the corpus of available research grows exponentially. We describe how the metaBUS platform can assist in tackling two central challenges to conducting meta-analyses. In addition, we provide a detailed description of the platform, with information on all fields included in the database. Next, we provide recommendations for three use cases: generating literature search terms by using the metaBUS taxonomy, conducting metaBUS queries to locate findings and generate first-pass meta-analyses, and identifying relevant findings that might have gone overlooked during traditional literature searches. We demonstrate a new software and a cloud-based interface that allow users to leverage the platform. We conclude with implications, limitations, and future directions.},
  keywords = {Big data,Literature search,Meta-analysis quantitative synthesis},
  file = {C:\Users\vanlissa\Zotero\storage\VPC3KBV4\S1053482216300675.html}
}

@article{brewerTheoryLadennessObservationTheoryLadenness2001,
  title = {The {{Theory-Ladenness}} of {{Observation}} and the {{Theory-Ladenness}} of the {{Rest}} of the {{Scientific Process}}},
  author = {Brewer, William F. and Lambert, Bruce L.},
  date = {2001},
  journaltitle = {Philosophy of Science},
  shortjournal = {Philos. of Sci.},
  volume = {68},
  number = {S3},
  pages = {S176-S186},
  issn = {0031-8248, 1539-767X},
  doi = {10.1086/392907},
  url = {https://www.cambridge.org/core/product/identifier/S0031824800028129/type/journal_article},
  urldate = {2025-01-30},
  abstract = {We use evidence from cognitive psychology and the history of science to examine the issue of the theory-ladenness of perceptual observation. This evidence shows that perception is theory-laden, but that it is only strongly theory-laden when the perceptual evidence is ambiguous or degraded, or when it requires a difficult perceptual judgment. We argue that debates about the theory-ladenness issue have focused too narrowly on the issue of perceptual experience, and that a full account of the scientific process requires an examination of theory-ladenness in attention, perception, data interpretation, data production, memory, and scientific communication. We conclude that the evidence for theory-ladenness does not lead to a relativist account of scientific knowledge.},
  langid = {english}
}

@article{bringmannBackBasicsImportance2022,
  title = {Back to {{Basics}}: {{The Importance}} of {{Conceptual Clarification}} in {{Psychological Science}}},
  shorttitle = {Back to {{Basics}}},
  author = {Bringmann, Laura F. and Elmer, Timon and Eronen, Markus I.},
  date = {2022-06-14},
  journaltitle = {Current Directions in Psychological Science},
  shortjournal = {Curr Dir Psychol Sci},
  pages = {09637214221096485},
  publisher = {SAGE Publications Inc},
  issn = {0963-7214},
  doi = {10.1177/09637214221096485},
  url = {https://doi.org/10.1177/09637214221096485},
  urldate = {2022-06-20},
  abstract = {Although the lack of conceptual clarity has been observed to be a widespread and fundamental problem in psychology, conceptual clarification plays a mostly marginal role in psychological research. In this article, we argue that better conceptualization of psychological phenomena is needed to move psychology forward as a science. We first show how conceptual unclarity seeps through all aspects of psychological research, from everyday concepts to statistical measures. We then turn to recommendations on how to improve conceptual clarity in psychology, emphasizing the importance of seeing research as an iterative process in which it is necessary to revisit the phenomena that are the foundations of theories and models, as well as how they are conceptualized and measured.},
  langid = {english},
  keywords = {concept,measurement,phenomena,philosophy of science,qualitative and quantitative methods},
  file = {C:\Users\vanlissa\Zotero\storage\3Z2B6SFQ\Bringmann et al_2022_Back to Basics.pdf}
}

@article{cinelliCrashCourseGood2022,
  title = {A {{Crash Course}} in {{Good}} and {{Bad Controls}}},
  author = {Cinelli, Carlos and Forney, Andrew and Pearl, Judea},
  date = {2022-05-20},
  journaltitle = {Sociological Methods \& Research},
  pages = {00491241221099552},
  publisher = {SAGE Publications Inc},
  issn = {0049-1241},
  doi = {10.1177/00491241221099552},
  url = {https://journals.sagepub.com/doi/full/10.1177/00491241221099552},
  urldate = {2024-03-12},
  abstract = {Many students of statistics and econometrics express frustration with the way a problem known as “bad control” is treated in the traditional literature. The issue arises when the addition of a variable to a regression equation produces an unintended discrepancy between the regression coefficient and the effect that the coefficient is intended to represent. Avoiding such discrepancies presents a challenge to all analysts in the data intensive sciences. This note describes graphical tools for understanding, visualizing, and resolving the problem through a series of illustrative examples. By making this “crash course” accessible to instructors and practitioners, we hope to avail these tools to a broader community of scientists concerned with the causal interpretation of regression models.},
  keywords = {back-door criterion,bad controls,causal inference,DAG,regression}
}

@online{ContributingCitationsReferences2024,
  title = {Contributing {{Citations}} and {{References}}},
  date = {2024},
  url = {https://support.datacite.org/docs/data-citation},
  urldate = {2024-12-05},
  abstract = {Citations and references can be created by adding relatedIdentifiers to DataCite DOI metadata. Each relatedIdentifier has a required relationType attribute which is used to denote the type of relationship. You can add citations and references to DOI metadata when you create the DOI initially and wit...},
  langid = {english},
  organization = {DataCite Support},
  file = {C:\Users\vanlissa\Zotero\storage\PUMBH9TE\contributing-citations-and-references.html}
}

@article{cramerMajorDepressionComplex2016,
  title = {Major {{Depression}} as a {{Complex Dynamic System}}},
  author = {Cramer, Angélique O. J. and family=Borkulo, given=Claudia D., prefix=van, useprefix=false and Giltay, Erik J. and family=Maas, given=Han L. J., prefix=van der, useprefix=false and Kendler, Kenneth S. and Scheffer, Marten and Borsboom, Denny},
  date = {2016-12-08},
  journaltitle = {PLOS ONE},
  shortjournal = {PLOS ONE},
  volume = {11},
  number = {12},
  pages = {e0167490},
  publisher = {Public Library of Science},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0167490},
  url = {https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0167490},
  urldate = {2022-04-11},
  abstract = {In this paper, we characterize major depression (MD) as a complex dynamic system in which symptoms (e.g., insomnia and fatigue) are directly connected to one another in a network structure. We hypothesize that individuals can be characterized by their own network with unique architecture and resulting dynamics. With respect to architecture, we show that individuals vulnerable to developing MD are those with strong connections between symptoms: e.g., only one night of poor sleep suffices to make a particular person feel tired. Such vulnerable networks, when pushed by forces external to the system such as stress, are more likely to end up in a depressed state; whereas networks with weaker connections tend to remain in or return to a non-depressed state. We show this with a simulation in which we model the probability of a symptom becoming ‘active’ as a logistic function of the activity of its neighboring symptoms. Additionally, we show that this model potentially explains some well-known empirical phenomena such as spontaneous recovery as well as accommodates existing theories about the various subtypes of MD. To our knowledge, we offer the first intra-individual, symptom-based, process model with the potential to explain the pathogenesis and maintenance of major depression.},
  langid = {english},
  keywords = {Autocorrelation,Depression,Dynamical systems,Fatigue,Insomnia,Network analysis,Simulation and modeling,Sleep},
  file = {C\:\\Users\\vanlissa\\Zotero\\storage\\2MV73MIZ\\Cramer et al_2016_Major Depression as a Complex Dynamic System.pdf;C\:\\Users\\vanlissa\\Zotero\\storage\\HJHMQ22W\\article.html}
}

@article{datacitemetadataworkinggroupDataCiteMetadataSchema2024,
  title = {{{DataCite Metadata Schema Documentation}} for the {{Publication}} and {{Citation}} of {{Research Data}} and {{Other Research Outputs}} v4.6},
  author = {{DataCite Metadata Working Group}},
  namea = {Liffers, Matthias and Robertson, Wendy and Ashton, Jan and Bernal, Isabel and Devaraju, Anusuriya and Elger, Kirsten and Gabriel, Vanessa and Habermann, Ted and Medina-Smith, Andrea and Padfield, Joseph and Parland-von Essen, Jessica and Raugh, Anne and Shallcross, Michael and Tarocco, Nicola and Vyčítalová, Hana and Whelan, Alex and Stathis, Kelly and El-Gebali, Sara},
  nameatype = {collaborator},
  date = {2024-12-05},
  publisher = {DataCite},
  doi = {10.14454/MZV1-5B55},
  url = {https://datacite-metadata-schema.readthedocs.io/en/4.6/},
  urldate = {2025-01-09},
  langid = {english},
  version = {4.6}
}

@article{deciEffectsExternallyMediated1971,
  title = {Effects of Externally Mediated Rewards on Intrinsic Motivation},
  author = {Deci, Edward L.},
  date = {1971},
  journaltitle = {Journal of Personality and Social Psychology},
  volume = {18},
  number = {1},
  pages = {105--115},
  publisher = {American Psychological Association},
  location = {US},
  issn = {1939-1315},
  doi = {10.1037/h0030644}
}

@book{degrootMethodologieGrondslagenVan1961,
  title = {Methodologie: Grondslagen van onderzoek en denken in de gedragswetenschappen},
  shorttitle = {Methodologie},
  author = {family=Groot, given=Adriaan D., prefix=de, useprefix=true},
  date = {1961},
  eprint = {6hiBDwAAQBAJ},
  eprinttype = {googlebooks},
  publisher = {Uitgeverij Mouton},
  location = {'s Gravenhage},
  isbn = {90-279-7721-6},
  langid = {dutch},
  pagetotal = {440},
  keywords = {Language Arts & Disciplines / Linguistics / General}
}

@book{degrootMethodologyFoundationsInference1969,
  title = {Methodology: {{Foundations}} of Inference and Research in the Behavioral Sciences},
  shorttitle = {Methodology},
  author = {De Groot, Adriaan D. and Spiekerman, J. A. A.},
  date = {1969-01-01},
  publisher = {De Gruyter Mouton},
  doi = {10.1515/9783112313121},
  url = {https://www.degruyter.com/view/title/571174},
  urldate = {2022-02-06},
  isbn = {978-3-11-230199-9 978-3-11-231312-1},
  file = {C:\Users\vanlissa\Zotero\storage\KCB5FJJR\De Groot and Spiekerman - 1969 - Methodology Foundations of inference and research.pdf}
}

@online{DOTLanguage2024,
  title = {{{DOT Language}}},
  date = {2024},
  url = {https://graphviz.org/doc/info/lang.html},
  urldate = {2024-12-05},
  abstract = {Abstract grammar for defining Graphviz nodes, edges, graphs, [subgraphs, and clusters](/doc/info/lang.html\#subgraphs-and-clusters).},
  langid = {english},
  organization = {Graphviz},
  file = {C:\Users\vanlissa\Zotero\storage\SQ9Y48ML\lang.html}
}

@article{dumas-malletPoorReplicationValidity2017,
  title = {Poor Replication Validity of Biomedical Association Studies Reported by Newspapers},
  author = {Dumas-Mallet, Estelle and Smith, Andy and Boraud, Thomas and Gonon, François},
  date = {2017-02-21},
  journaltitle = {PLOS ONE},
  shortjournal = {PLOS ONE},
  volume = {12},
  number = {2},
  pages = {e0172650},
  publisher = {Public Library of Science},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0172650},
  url = {https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0172650},
  urldate = {2024-02-27},
  abstract = {Objective To investigate the replication validity of biomedical association studies covered by newspapers. Methods We used a database of 4723 primary studies included in 306 meta-analysis articles. These studies associated a risk factor with a disease in three biomedical domains, psychiatry, neurology and four somatic diseases. They were classified into a lifestyle category (e.g. smoking) and a non-lifestyle category (e.g. genetic risk). Using the database Dow Jones Factiva, we investigated the newspaper coverage of each study. Their replication validity was assessed using a comparison with their corresponding meta-analyses. Results Among the 5029 articles of our database, 156 primary studies (of which 63 were lifestyle studies) and 5 meta-analysis articles were reported in 1561 newspaper articles. The percentage of covered studies and the number of newspaper articles per study strongly increased with the impact factor of the journal that published each scientific study. Newspapers almost equally covered initial (5/39 12.8\%) and subsequent (58/600 9.7\%) lifestyle studies. In contrast, initial non-lifestyle studies were covered more often (48/366 13.1\%) than subsequent ones (45/3718 1.2\%). Newspapers never covered initial studies reporting null findings and rarely reported subsequent null observations. Only 48.7\% of the 156 studies reported by newspapers were confirmed by the corresponding meta-analyses. Initial non-lifestyle studies were less often confirmed (16/48) than subsequent ones (29/45) and than lifestyle studies (31/63). Psychiatric studies covered by newspapers were less often confirmed (10/38) than the neurological (26/41) or somatic (40/77) ones. This is correlated to an even larger coverage of initial studies in psychiatry. Whereas 234 newspaper articles covered the 35 initial studies that were later disconfirmed, only four press articles covered a subsequent null finding and mentioned the refutation of an initial claim. Conclusion Journalists preferentially cover initial findings although they are often contradicted by meta-analyses and rarely inform the public when they are disconfirmed.},
  langid = {english},
  keywords = {ADHD,Bibliometrics,Biomarkers,Cancer risk factors,Medical risk factors,Mental health and psychiatry,Metaanalysis,Scientific publishing},
  file = {C:\Users\vanlissa\Zotero\storage\UWPM7YLC\Dumas-Mallet et al. - 2017 - Poor replication validity of biomedical associatio.pdf}
}

@online{ehmkeContributorCovenantCode2014,
  title = {Contributor {{Covenant}}: {{A Code}} of {{Conduct}} for {{Open Source}} and {{Other Digital Commons Communities}}},
  author = {Ehmke, Coraline},
  date = {2014},
  url = {https://www.contributor-covenant.org/},
  urldate = {2024-04-03},
  file = {C:\Users\vanlissa\Zotero\storage\GP4TPP8T\www.contributor-covenant.org.html}
}

@article{feldEstimatingRelationshipSkill2017,
  title = {Estimating the Relationship between Skill and Overconfidence},
  author = {Feld, Jan and Sauermann, Jan and family=Grip, given=Andries, prefix=de, useprefix=true},
  date = {2017-06-01},
  journaltitle = {Journal of Behavioral and Experimental Economics},
  shortjournal = {Journal of Behavioral and Experimental Economics},
  volume = {68},
  pages = {18--24},
  issn = {2214-8043},
  doi = {10.1016/j.socec.2017.03.002},
  url = {https://www.sciencedirect.com/science/article/pii/S2214804317300344},
  urldate = {2024-12-05},
  abstract = {The Dunning–Kruger effect states that low performers vastly overestimate their performance while high performers more accurately assess their performance. Researchers usually interpret this empirical pattern as evidence that the low skilled are vastly overconfident while the high skilled are more accurate in assessing their skill. However, measurement error alone can lead to a negative relationship between performance and overestimation, even if skill and overconfidence are unrelated. To clarify the role of measurement error, we restate the Dunning–Kruger effect in terms of skill and overconfidence. We show that we can correct for bias caused by measurement error with an instrumental variable approach that uses a second performance as instrument. We then estimate the Dunning–Kruger effect in the context of the exam grade predictions of economics students, using their grade point average as an instrument for their exam grade. Our results show that the unskilled are more overconfident than the skilled. However, as we predict in our methodological discussion, this relationship is significantly weaker than ordinary least squares estimates suggest.},
  keywords = {Dunning–Kruger effect,Instrumental variable,Judgment error,Measurement error,Overconfidence},
  file = {C:\Users\vanlissa\Zotero\storage\GWF4DBVT\S2214804317300344.html}
}

@article{frankenhuisStrategicAmbiguitySocial2023,
  title = {Strategic {{Ambiguity}} in the {{Social Sciences}}},
  author = {Frankenhuis, Willem E. and Panchanathan, Karthik and Smaldino, Paul E.},
  date = {2023-11-17},
  journaltitle = {Social Psychological Bulletin},
  volume = {18},
  pages = {1--25},
  issn = {2569-653X},
  doi = {10.32872/spb.9923},
  url = {https://spb.psychopen.eu/index.php/spb/article/view/9923},
  urldate = {2024-03-11},
  abstract = {In the wake of the replication crisis, there have been calls to increase the clarity and precision of theory in the social sciences. Here, we argue that the effects of these calls may be limited due to incentives favoring ambiguous theory. Intentionally or not, scientists can exploit theoretical ambiguities to make support for a claim appear stronger than it is. Practices include theory stretching, interpreting an ambiguous claim more expansively to absorb data outside of the scope of the original claim, and post-hoc precision, interpreting an ambiguous claim more narrowly so it appears more precisely aligned with the data. These practices lead to the overestimation of evidence for the original claim and create the appearance of consistent support and progressive research programs, which may in turn be rewarded by journals, funding agencies, and hiring committees. Selection for ambiguous research can occur even when scientists act in good faith. Although ambiguity might be inevitable or even useful in the early stages of theory construction, scientists should aim for increased clarity as knowledge advances. Science benefits from transparently communicating about known ambiguities. To attain transparency about ambiguity, we provide a set of recommendations for authors, reviewers, and journals. We conclude with suggestions for research on how scientists use strategic ambiguity to advance their careers and the ways in which norms, incentives, and practices favor strategic ambiguity. Our paper ends with a simple mathematical model exploring the conditions in which high-ambiguity theories are favored over low-ambiguity theories, providing a basis for future analyses.},
  langid = {english},
  keywords = {formal modeling,incentive structures,post-hoc precision,RAPPing,strategic ambiguity,theory development,theory stretching},
  file = {C:\Users\vanlissa\Zotero\storage\PE7K42NU\Frankenhuis et al. - 2023 - Strategic Ambiguity in the Social Sciences.pdf}
}

@article{friedTheoriesModelsWhat2020,
  title = {Theories and {{Models}}: {{What They Are}}, {{What They Are}} for, and {{What They Are About}}},
  author = {Fried, Eiko I.},
  date = {2020-10-01},
  journaltitle = {Psychological Inquiry},
  volume = {31},
  number = {4},
  pages = {336--344},
  publisher = {Routledge},
  issn = {1047-840X},
  doi = {10.1080/1047840X.2020.1854011},
  file = {C:\Users\vanlissa\Zotero\storage\JTLH8EGQ\Fried - 2020 - .pdf}
}

@incollection{gigerenzerNullRitualWhat2004,
  title = {The Null Ritual : {{What}} You Always Wanted to Know about Significance Testing but Were Afraid to Ask},
  shorttitle = {The Null Ritual},
  booktitle = {The {{Sage}} Handbook of Quantitative Methodology for the Social Sciences},
  author = {Gigerenzer, Gerd and Krauss, Stefan and Vitouch, Oliver},
  editor = {Kaplan, David},
  date = {2004},
  pages = {391--408},
  publisher = {Sage},
  location = {Thousand Oaks},
  isbn = {978-0-7619-2359-6},
  langid = {english},
  file = {C:\Users\vanlissa\Zotero\storage\AW4645E4\GG_Null_2004.pdf}
}

@article{grayHowMapTheory2017,
  title = {How to {{Map Theory}}: {{Reliable Methods Are Fruitless Without Rigorous Theory}}},
  shorttitle = {How to {{Map Theory}}},
  author = {Gray, Kurt},
  date = {2017-09},
  journaltitle = {Perspectives on Psychological Science},
  volume = {12},
  number = {5},
  pages = {731--741},
  issn = {1745-6916, 1745-6924},
  doi = {10.1177/1745691617691949},
  url = {http://journals.sagepub.com/doi/10.1177/1745691617691949},
  urldate = {2019-01-06},
  langid = {english},
  file = {C:\Users\vanlissa\Zotero\storage\ZFYUID8A\Gray_2017_How to Map Theory.pdf}
}

@article{grossEmotionRegulationCurrent2015,
  title = {Emotion Regulation: {{Current}} Status and Future Prospects},
  shorttitle = {Emotion {{Regulation}}},
  author = {Gross, James J.},
  date = {2015-01-02},
  journaltitle = {Psychological Inquiry},
  volume = {26},
  number = {1},
  pages = {1--26},
  issn = {1047-840X, 1532-7965},
  doi = {10.1080/1047840X.2014.940781},
  url = {http://www.tandfonline.com/doi/abs/10.1080/1047840X.2014.940781},
  urldate = {2017-10-30},
  langid = {english},
  file = {C:\Users\vanlissa\Zotero\storage\QAQAU4DD\gross2015.pdf}
}

@article{guestHowComputationalModeling2021,
  title = {How {{Computational Modeling Can Force Theory Building}} in {{Psychological Science}}},
  author = {Guest, Olivia and Martin, Andrea E.},
  date = {2021-07-01},
  journaltitle = {Perspectives on Psychological Science},
  shortjournal = {Perspect Psychol Sci},
  volume = {16},
  number = {4},
  pages = {789--802},
  publisher = {SAGE Publications Inc},
  issn = {1745-6916},
  doi = {10.1177/1745691620970585},
  url = {https://doi.org/10.1177/1745691620970585},
  urldate = {2022-10-18},
  abstract = {Psychology endeavors to develop theories of human capacities and behaviors on the basis of a variety of methodologies and dependent measures. We argue that one of the most divisive factors in psychological science is whether researchers choose to use computational modeling of theories (over and above data) during the scientific-inference process. Modeling is undervalued yet holds promise for advancing psychological science. The inherent demands of computational modeling guide us toward better science by forcing us to conceptually analyze, specify, and formalize intuitions that otherwise remain unexamined?what we dub open theory. Constraining our inference process through modeling enables us to build explanatory and predictive theories. Here, we present scientific inference in psychology as a path function in which each step shapes the next. Computational modeling can constrain these steps, thus advancing scientific inference over and above the stewardship of experimental practice (e.g., preregistration). If psychology continues to eschew computational modeling, we predict more replicability crises and persistent failure at coherent theory building. This is because without formal modeling we lack open and transparent theorizing. We also explain how to formalize, specify, and implement a computational model, emphasizing that the advantages of modeling can be achieved by anyone with benefit to all.},
  file = {C:\Users\vanlissa\Zotero\storage\YZQCD2RP\Guest and Martin - 2021 - How Computational Modeling Can Force Theory Buildi.pdf}
}

@article{guestWhatMakesGood2024,
  title = {What {{Makes}} a {{Good Theory}}, and {{How Do We Make}} a {{Theory Good}}?},
  author = {Guest, Olivia},
  date = {2024-01-24},
  journaltitle = {Computational Brain \& Behavior},
  shortjournal = {Comput Brain Behav},
  issn = {2522-087X},
  doi = {10.1007/s42113-023-00193-2},
  url = {https://doi.org/10.1007/s42113-023-00193-2},
  urldate = {2024-05-08},
  abstract = {I present an ontology of criteria for evaluating theory to answer the titular question from the perspective of a scientist practitioner. Set inside a formal account of our adjudication over theories, a metatheoretical calculus, this ontology comprises the following: (a) metaphysical commitment, the need to highlight what parts of theory are not under investigation, but are assumed, asserted, or essential; (b) discursive survival, the ability to be understood by interested non-bad actors, to withstand scrutiny within the intended (sub)field(s), and to negotiate the dialectical landscape thereof; (c) empirical interface, the potential to explicate the relationship between theory and observation, i.e., how observations relate to, and affect, theory and vice versa; (d) minimising harm, the reckoning with how theory is forged in a fire of historical, if not ongoing, abuses—from past crimes against humanity, to current exploitation, turbocharged or hyped by machine learning, to historical and present internal academic marginalisation. This work hopes to serve as a possible beginning for scientists who want to examine the properties and characteristics of theories, to propose additional virtues and vices, and to engage in further dialogue. Finally, I appeal to practitioners to iterate frequently over such criteria, by building and sharing the metatheoretical calculi used to adjudicate over theories.},
  langid = {english},
  keywords = {Metascience,Metatheoretical calculcus,Metatheory,Theoretical virtue,Theory},
  file = {C:\Users\vanlissa\Zotero\storage\6I8JTYDS\Guest - 2024 - What Makes a Good Theory, and How Do We Make a The.pdf}
}

@article{guyonMeasurementOntologyEpistemology2018,
  title = {Measurement, Ontology, and Epistemology: {{Psychology}} Needs Pragmatism-Realism},
  shorttitle = {Measurement, Ontology, and Epistemology},
  author = {Guyon, Hervé and Kop, Jean-Luc and Juhel, Jacques and Falissard, Bruno},
  date = {2018-04-01},
  journaltitle = {Theory \& Psychology},
  volume = {28},
  number = {2},
  pages = {149--171},
  publisher = {SAGE Publications Ltd},
  issn = {0959-3543},
  doi = {10.1177/0959354318761606},
  url = {https://doi.org/10.1177/0959354318761606},
  urldate = {2024-12-05},
  abstract = {Measurement in psychology is at the heart of a major debate in the academic literature. We aim to contribute to a critical discussion of this issue. We propose to reposition the object of this type of measure, namely a mental attribute as measured by mental tests. Mental attributes should be considered not as a true object independent of the knower, but as an emergent property of a person dependent on the social context. On the basis of this clarified ontology, we consider that an empirical approach to measuring a mental attribute is possible. This approach must be resolutely pragmatist and realist. In practical terms, this means that a test needs to be renegotiated relative to the context. The validation of quantitative measures requires verification of a certain number of criteria. Consequently, our work critically explores measures as they are usually implemented in the area of psychometrics.},
  langid = {english},
  file = {C:\Users\vanlissa\Zotero\storage\RTRDGCGE\Guyon et al. - 2018 - Measurement, ontology, and epistemology Psycholog.pdf}
}

@article{haslbeckModelingPsychopathologyData2021,
  title = {Modeling Psychopathology: {{From}} Data Models to Formal Theories.},
  shorttitle = {Modeling Psychopathology},
  author = {Haslbeck, Jonas M. B. and Ryan, Oisín and Robinaugh, Donald J. and Waldorp, Lourens J. and Borsboom, Denny},
  date = {2021-11-04},
  journaltitle = {Psychological Methods},
  shortjournal = {Psychological Methods},
  issn = {1939-1463, 1082-989X},
  doi = {10.1037/met0000303},
  url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/met0000303},
  urldate = {2022-04-16},
  abstract = {Over the past decade, there has been a surge of empirical research investigating mental disorders as complex systems. In this article, we investigate how to best make use of this growing body of empirical research and move the field toward its fundamental aims of explaining, predicting, and controlling psychopathology. We first review the contemporary philosophy of science literature on scientific theories and argue that fully achieving the aims of explanation, prediction, and control requires that we construct formal theories of mental disorders: theories expressed in the language of mathematics or a computational programming language. We then investigate three routes by which one can use empirical findings (i.e., data models) to construct formal theories: (a) using data models themselves as formal theories, (b) using data models to infer formal theories, and (c) comparing empirical data models to theory-implied data models in order to evaluate and refine an existing formal theory. We argue that the third approach is the most promising path forward. We conclude by introducing the abductive formal theory construction (AFTC) framework, informed by both our review of philosophy of science and our methodological investigation. We argue that this approach provides a clear and promising way forward for using empirical research to inform the generation, development, and testing of formal theories both in the domain of psychopathology and in the broader field of psychological science.},
  langid = {english},
  file = {C:\Users\vanlissa\Zotero\storage\HVSRHJZL\Haslbeck et al. - 2021 - Modeling psychopathology From data models to form.pdf}
}

@article{hoijtinkOpenEmpiricalCycle2023,
  title = {The {{Open Empirical Cycle}} for {{Hypothesis Evaluation}} in {{Psychology}}},
  author = {Hoijtink, Herbert and family=Bruin, given=Jonathan, prefix=de, useprefix=false and Duken, Sascha Béla and Flores, Jacques and Frankenhuis, Willem and family=Lissa, given=Caspar J., prefix=van, useprefix=false},
  date = {2023-06-02},
  publisher = {OSF},
  doi = {10.31234/osf.io/wsxbh},
  url = {https://osf.io/wsxbh},
  urldate = {2024-03-18},
  abstract = {In the last decade it has become clear that replicability of empirical psychological research should be better. Open science practices aim to enhance the transparency of research thereby both enabling others to reproduce the results presented in a paper and increasing the replicability of these results using new data. Examples of these practices include preregistration, publication of data and analyses, open access publications, and replication research. Although open science practices are gaining traction, they have rarely been placed in a broader epistemological context. To address this shortcoming, this paper introduces the open empirical cycle. It draws upon De Groot’s empirical cycle, a model of cumulative knowledge generation via scientific research. The open empirical cycle is a pragmatic guide for researchers that includes and links to open science practices. Adhering to the open empirical cycle, if only partly, will structure the scientific workflow and create awareness of the adverse consequences of deviations. Following the open empirical cycle increases the transparency, quality, trustworthiness, and replicability of research. The open empirical cycle presented in this paper focusses on hypothesis evaluation using quantitative data in psychology. However, it can straightforwardly be applied to hypothesis evaluation in other social and behavioral sciences and biomedical sciences. It brings together ideas from de Groot’s empirical cycle, traditional, and open research steps, key references, and open science tools, thereby providing a pragmatic, contemporary, and structured approach to hypothesis evaluation.},
  langid = {american},
  file = {C\:\\Users\\vanlissa\\Zotero\\storage\\7JB6VRT2\\Hoijtink et al. - 2023 - The Open Empirical Cycle for Hypothesis Evaluation.pdf;C\:\\Users\\vanlissa\\Zotero\\storage\\8IHHXNTM\\wsxbh.html}
}

@article{katzSpecialIssueSoftware2024,
  title = {Special Issue on Software Citation, Indexing, and Discoverability},
  author = {Katz, Daniel S. and Chue Hong, Neil P.},
  date = {2024-03-26},
  journaltitle = {PeerJ Computer Science},
  volume = {10},
  pages = {e1951},
  issn = {2376-5992},
  doi = {10.7717/peerj-cs.1951},
  url = {https://peerj.com/articles/cs-1951},
  urldate = {2025-01-09},
  abstract = {Software plays a fundamental role in research as a tool, an output, or even as an object of study. This special issue on software citation, indexing, and discoverability brings together five papers examining different aspects of how the use of software is recorded and made available to others. It describes new work on datasets that enable large-scale analysis of the evolution of software usage and citation, that presents evidence of increased citation rates when software artifacts are released, that provides guidance for registries and repositories to support software citation and findability, and that shows there are still barriers to improving and formalising software citation and publication practice. As the use of software increases further, driven by modern research methods, addressing the barriers to software citation and discoverability will encourage greater sharing and reuse of software, in turn enabling research progress.},
  langid = {english},
  file = {C:\Users\vanlissa\Zotero\storage\L8EWGVYX\Katz and Chue Hong - 2024 - Special issue on software citation, indexing, and .pdf}
}

@article{kirczModularityNextForm1998,
  title = {Modularity: The next Form of Scientific Information Presentation?},
  shorttitle = {Modularity},
  author = {Kircz, Joost G.},
  date = {1998},
  journaltitle = {Journal of Documentation},
  volume = {54},
  number = {2},
  pages = {210--235},
  publisher = {MCB UP Ltd},
  issn = {0022-0418},
  doi = {10.1108/EUM0000000007185},
  url = {https://www.emerald.com/insight/content/doi/10.1108/eum0000000007185/full/html},
  urldate = {2025-01-09},
  abstract = {The development of electronic publishing heralds a new period in scientific communications. Besides the obvious advantages of an almost endless storage and transport capacity, many new features come to the fore. As each technology finds its own expressions in the ways scientific communications take form, we analyse print on paper scientific articles in order to obtain the necessary ingredients for shaping a new model for electronic communications. A short historical overview shows that the typical form of the present‐day linear (essay‐type) scientific article is the result of a technological development over the centuries. The various characteristics of print on paper are discussed and the foreseeable changes to a more modular form of communication in an electronic environment are postulated. Subsequently we take the functions of the present‐day scientific article vis‐à‐vis the author and the reader as starting points. We then focus on the process of scientific information transfer and deal essentially with the information consumption by the reader. Different types of information, at present intermingled in the linear article, can be separated and stored in well‐defined, cognitive, textual modules. To serve the scientists better in finding their way through the information overload of today, we conclude that the electronic information transfer of the future will be, in essence, a transfer of well‐defined, cognitive information modules. In the last part of this article we outline the first steps towards a new heuristic model for such scientific information transfer.},
  langid = {english},
  file = {C\:\\Users\\vanlissa\\Zotero\\storage\\HE8DT9WE\\Kircz - 1998 - Modularity the next form of scientific informatio.pdf;C\:\\Users\\vanlissa\\Zotero\\storage\\ERMGTCRM\\html.html}
}

@article{kissnerIDENTIFICATIONLOGICALINCONSISTENCY2008,
  title = {{{ON THE IDENTIFICATION OF A LOGICAL INCONSISTENCY IN THE GENERAL THEORY OF CRIME}}},
  author = {Kissner, Jason},
  date = {2008-01-01},
  journaltitle = {Journal of Crime and Justice},
  publisher = {Taylor \& Francis Group},
  issn = {0735-648X},
  url = {https://www.tandfonline.com/doi/abs/10.1080/0735648X.2008.9721251},
  urldate = {2024-11-21},
  abstract = {Gottfredson and Hirschi's general theory of crime is widely tested and commented upon and just as widely misapprehended. Criminologists have paid insufficient attention to the implications of the...},
  langid = {english},
  file = {C:\Users\vanlissa\Zotero\storage\QJRVQXLW\0735648X.2008.html}
}

@article{kuhbergerPublicationBiasPsychology2014,
  title = {Publication {{Bias}} in {{Psychology}}: {{A Diagnosis Based}} on the {{Correlation}} between {{Effect Size}} and {{Sample Size}}},
  shorttitle = {Publication {{Bias}} in {{Psychology}}},
  author = {Kühberger, Anton and Fritz, Astrid and Scherndl, Thomas},
  date = {2014-09-05},
  journaltitle = {PLoS ONE},
  shortjournal = {PLoS One},
  volume = {9},
  number = {9},
  eprint = {25192357},
  eprinttype = {pmid},
  pages = {e105825},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0105825},
  url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4156299/},
  urldate = {2024-03-09},
  abstract = {Background The p value obtained from a significance test provides no information about the magnitude or importance of the underlying phenomenon. Therefore, additional reporting of effect size is often recommended. Effect sizes are theoretically independent from sample size. Yet this may not hold true empirically: non-independence could indicate publication bias. Methods We investigate whether effect size is independent from sample size in psychological research. We randomly sampled 1,000 psychological articles from all areas of psychological research. We extracted p values, effect sizes, and sample sizes of all empirical papers, and calculated the correlation between effect size and sample size, and investigated the distribution of p values. Results We found a negative correlation of r{$\mkern1mu$}={$\mkern1mu$}−.45 [95\% CI: −.53; −.35] between effect size and sample size. In addition, we found an inordinately high number of p values just passing the boundary of significance. Additional data showed that neither implicit nor explicit power analysis could account for this pattern of findings. Conclusion The negative correlation between effect size and samples size, and the biased distribution of p values indicate pervasive publication bias in the entire field of psychology.},
  pmcid = {PMC4156299},
  file = {C:\Users\vanlissa\Zotero\storage\JMJ6JSQX\Kühberger et al. - 2014 - Publication Bias in Psychology A Diagnosis Based .pdf}
}

@book{kuhnStructureScientificRevolutions2009,
  title = {The Structure of Scientific Revolutions},
  author = {Kuhn, Thomas S.},
  date = {2009},
  edition = {3. ed., [Nachdr.]},
  publisher = {Univ. of Chicago Press},
  location = {Chicago},
  isbn = {978-0-226-45807-6 978-0-226-45808-3},
  langid = {english},
  pagetotal = {212},
  file = {C:\Users\vanlissa\Zotero\storage\2AJXKFEE\Kuhn - 2009 - The structure of scientific revolutions.pdf}
}

@incollection{lakatosHistoryScienceIts1971,
  title = {History of {{Science}} and Its {{Rational Reconstructions}}},
  booktitle = {{{PSA}} 1970: {{In Memory}} of {{Rudolf Carnap Proceedings}} of the 1970 {{Biennial Meeting Philosophy}} of {{Science Association}}},
  author = {Lakatos, Imre},
  editor = {Buck, Roger C. and Cohen, Robert S.},
  date = {1971},
  series = {Boston {{Studies}} in the {{Philosophy}} of {{Science}}},
  pages = {91--136},
  publisher = {Springer Netherlands},
  location = {Dordrecht},
  doi = {10.1007/978-94-010-3142-4_7},
  url = {https://doi.org/10.1007/978-94-010-3142-4_7},
  urldate = {2024-02-08},
  abstract = {“Philosophy of science without history of science is empty; history of science without philosophy of science is blind”. Taking its cue from this paraphrase of Kant’s famous dictum, this paper intends to explain how the historiography of science should learn from the philosophy of science and vice versa. It will be argued that (a) philosophy of science provides normative methodologies in terms of which the historian reconstructs ‘internal history’ and thereby provides a rational explanation of the growth of objective knowledge; (b) two competing methodologies can be evaluated with the help of (normatively interpreted) history; (c) any rational reconstruction of history needs to be supplemented by an empirical (socio-psychological) ‘external history’.},
  isbn = {978-94-010-3142-4},
  langid = {english},
  keywords = {Actual History,Demarcation Criterion,Inductive Generalisation,Rational Reconstruction,Rationality Theory},
  file = {C:\Users\vanlissa\Zotero\storage\K7SMK27H\Lakatos - HISTORY OF SCIENCE AND ITS RATIONAL RECONSTRUCTION.pdf}
}

@article{lakensImprovingTransparencyFalsifiability2021,
  title = {Improving {{Transparency}}, {{Falsifiability}}, and {{Rigor}} by {{Making Hypothesis Tests Machine-Readable}}},
  author = {Lakens, Daniël and DeBruine, Lisa M.},
  date = {2021-04-01},
  journaltitle = {Advances in Methods and Practices in Psychological Science},
  volume = {4},
  number = {2},
  pages = {2515245920970949},
  publisher = {SAGE Publications Inc},
  issn = {2515-2459},
  doi = {10.1177/2515245920970949},
  url = {https://doi.org/10.1177/2515245920970949},
  urldate = {2022-09-20},
  abstract = {Making scientific information machine-readable greatly facilitates its reuse. Many scientific articles have the goal to test a hypothesis, so making the tests of statistical predictions easier to find and access could be very beneficial. We propose an approach that can be used to make hypothesis tests machine-readable. We believe there are two benefits to specifying a hypothesis test in such a way that a computer can evaluate whether the statistical prediction is corroborated or not. First, hypothesis tests become more transparent, falsifiable, and rigorous. Second, scientists benefit if information related to hypothesis tests in scientific articles is easily findable and reusable, for example, to perform meta-analyses, conduct peer review, and examine metascientific research questions. We examine what a machine-readable hypothesis test should look like and demonstrate the feasibility of machine-readable hypothesis tests in a real-life example using the fully operational prototype R package scienceverse.},
  file = {C:\Users\vanlissa\Zotero\storage\PDQXJKL2\Lakens and DeBruine - 2021 - Improving Transparency, Falsifiability, and Rigor .pdf}
}

@article{lamprechtFAIRPrinciplesResearch2019,
  title = {Towards {{FAIR}} Principles for Research Software},
  author = {Lamprecht, Anna-Lena and Garcia, Leyla and Kuzak, Mateusz and Martinez, Carlos and Arcila, Ricardo and Martin Del Pico, Eva and Dominguez Del Angel, Victoria and family=Sandt, given=Stephanie, prefix=van de, useprefix=true and Ison, Jon and Martinez, Paula Andrea and McQuilton, Peter and Valencia, Alfonso and Harrow, Jennifer and Psomopoulos, Fotis and Gelpi, Josep Ll. and Chue Hong, Neil and Goble, Carole and Capella-Gutierrez, Salvador},
  editor = {Groth, Paul},
  date = {2019-11-13},
  journaltitle = {Data Science},
  shortjournal = {DS},
  pages = {1--23},
  issn = {24518492, 24518484},
  doi = {10.3233/DS-190026},
  url = {https://www.medra.org/servlet/aliasResolver?alias=iospress&doi=10.3233/DS-190026},
  urldate = {2020-05-19},
  file = {C:\Users\vanlissa\Zotero\storage\4YVQJARQ\Lamprecht et al_2019_Towards FAIR principles for research software.pdf}
}

@article{landiFAIROpenPossible2020,
  title = {The “{{A}}” of {{FAIR}} – {{As Open}} as {{Possible}}, as {{Closed}} as {{Necessary}}},
  author = {Landi, Annalisa and Thompson, Mark and Giannuzzi, Viviana and Bonifazi, Fedele and Labastida, Ignasi and family=Silva Santos, given=Luiz Olavo Bonino, prefix=da, useprefix=true and Roos, Marco},
  date = {2020-01-01},
  journaltitle = {Data Intelligence},
  shortjournal = {Data Intelligence},
  volume = {2},
  number = {1--2},
  pages = {47--55},
  issn = {2641-435X},
  doi = {10.1162/dint_a_00027},
  url = {https://doi.org/10.1162/dint_a_00027},
  urldate = {2025-03-05},
  abstract = {In order to provide responsible access to health data by reconciling benefits of data sharing with privacy rights and ethical and regulatory requirements, Findable, Accessible, Interoperable and Reusable (FAIR) metadata should be developed. According to the H2020 Program Guidelines on FAIR Data, data should be “as open as possible and as closed as necessary”, “open” in order to foster the reusability and to accelerate research, but at the same time they should be “closed” to safeguard the privacy of the subjects. Additional provisions on the protection of natural persons with regard to the processing of personal data have been endorsed by the European General Data Protection Regulation (GDPR), Reg (EU) 2016/679, that came into force in May 2018. This work aims to solve accessibility problems related to the protection of personal data in the digital era and to achieve a responsible access to and responsible use of health data. We strongly suggest associating each data set with FAIR metadata describing both the type of data collected and the accessibility conditions by considering data protection obligations and ethical and regulatory requirements. Finally, an existing FAIR infrastructure component has been used as an example to explain how FAIR metadata could facilitate data sharing while ensuring protection of individuals.},
  file = {C\:\\Users\\vanlissa\\Zotero\\storage\\E54LUU7F\\Landi et al. - 2020 - The “A” of FAIR – As Open as Possible, as Closed a.pdf;C\:\\Users\\vanlissa\\Zotero\\storage\\MJNTFFRP\\The-A-of-FAIR-As-Open-as-Possible-as-Closed-as.html}
}

@online{langeChecklistIncentivizingFacilitating2025a,
  title = {A Checklist for Incentivizing and Facilitating Good Theory Building},
  author = {Lange, Jens and Freyer, Nele and Musfeld, Philipp and Schönbrodt, Felix and Leising, Daniel},
  date = {2025-01-10},
  eprinttype = {OSF},
  doi = {10.31219/osf.io/7qvfz},
  url = {https://osf.io/7qvfz_v1},
  urldate = {2025-03-02},
  abstract = {Psychology is facing a theory crisis characterized by ambiguous theories that lead to inconclusive empirical tests. To address this problem, we propose a checklist designed to establish hygiene standards for precise theory development and testing. This checklist contains operationalized criteria applicable to the development of both narrative and formal theories as well as empirical tests of these theories. Developing and testing precise theories in psychology is more challenging than is typically acknowledged. Given this challenge, we advocate for the (re-)creation of a dedicated field of theoretical psychology, specialized journals that support the publication of well-developed theories, even without empirical tests, integrating the checklist into evaluation processes such as peer-review, using the checklist in the process of  developing a theory, and as a tool for teaching theory development to students.},
  langid = {american},
  pubstate = {prepublished},
  file = {C:\Users\vanlissa\Zotero\storage\S3DRYWXU\Lange et al. - 2025 - A checklist for incentivizing and facilitating goo.pdf}
}

@incollection{langeSelfDeterminationTheory2012,
  title = {Self-{{Determination Theory}}},
  booktitle = {Handbook of {{Theories}} of {{Social Psychology}}: {{Volume}} 1},
  author = {Lange, Paul A. M. Van and W.Kruglanski, Arie and ToryHiggins, E. and Deci, Edward L. and Ryan, Richard M.},
  date = {2012},
  pages = {416--437},
  publisher = {SAGE Publications Ltd},
  doi = {10.4135/9781446249215},
  url = {https://sk.sagepub.com/hnbk/edvol/hdbk_socialpsychtheories1/chpt/selfdetermination-theory},
  urldate = {2025-01-31},
  abstract = {{$<$}p{$>$}The Handbook of Theories of Social Psychology is an essential resource for researchers and students of social psychology and related disciplines.{$<$}/p{$>$}},
  isbn = {978-1-4462-4921-5},
  langid = {english},
  file = {C:\Users\vanlissa\Zotero\storage\IG58GQ64\Lange et al. - 2012 - Self-Determination Theory.pdf}
}

@article{lavelleWhenCrisisBecomes2021,
  title = {When a {{Crisis Becomes}} an {{Opportunity}}: {{The Role}} of {{Replications}} in {{Making Better Theories}}},
  shorttitle = {When a {{Crisis Becomes}} an {{Opportunity}}},
  author = {Lavelle, Jane Suilin},
  date = {2021-04-14},
  journaltitle = {The British Journal for the Philosophy of Science},
  shortjournal = {The British Journal for the Philosophy of Science},
  pages = {714812},
  issn = {0007-0882, 1464-3537},
  doi = {10.1086/714812},
  url = {https://www.journals.uchicago.edu/doi/10.1086/714812},
  urldate = {2022-03-01},
  abstract = {While it is widely acknowledged that psychology is in the throes of a replication ‘crisis’, relatively little attention has been paid to the role theory plays in our evaluation of replications as ‘failed’ or ‘successful’. This paper applies well-known arguments in philosophy of science about the interplay between theory and experiment to a contemporary case study of infants’ understanding of false belief (Onishi and Baillargeon [2005]), and attempts to replicate it. It argues that the lack of consensus about over-arching theories informing both the concepts under study and the methodologies used to track them means that researchers disagree over which experiments constitute replications of the original. The second part of the paper places this specific debate within a broader discussion of the replication crisis as a crisis of ‘theory’, developing work by Muthukrishna and Henrich ([2018]) and Bird ([2018]). Bird argues that the lack of agreed over-arching theories in psychology means that a high rate of replication failure is to be expected; this paper agrees with his diagnosis but challenges his proposal that more replication will resolve the problem.},
  langid = {english},
  file = {C:\Users\vanlissa\Zotero\storage\XDG74HWE\Lavelle - 2021 - When a Crisis Becomes an Opportunity The Role of .pdf}
}

@book{lewandowsky2010computational,
  title = {Computational Modeling in Cognition: {{Principles}} and Practice},
  author = {Lewandowsky, Stephan and Farrell, Simon},
  date = {2010},
  publisher = {Sage}
}

@article{lewinPsychologyProcessGroup1943,
  title = {Psychology and the {{Process}} of {{Group Living}}},
  author = {Lewin, Kurt},
  date = {1943-02},
  journaltitle = {The Journal of Social Psychology},
  shortjournal = {The Journal of Social Psychology},
  volume = {17},
  number = {1},
  pages = {113--131},
  issn = {0022-4545, 1940-1183},
  doi = {10.1080/00224545.1943.9712269},
  url = {http://www.tandfonline.com/doi/abs/10.1080/00224545.1943.9712269},
  urldate = {2024-11-20},
  langid = {english}
}

@article{mcgillivrayDeepImpactStudy2022,
  title = {Deep {{Impact}}: {{A Study}} on the {{Impact}} of {{Data Papers}} and {{Datasets}} in the {{Humanities}} and {{Social Sciences}}},
  shorttitle = {Deep {{Impact}}},
  author = {McGillivray, Barbara and Marongiu, Paola and Pedrazzini, Nilo and Ribary, Marton and Wigdorowitz, Mandy and Zordan, Eleonora},
  date = {2022-12},
  journaltitle = {Publications},
  volume = {10},
  number = {4},
  pages = {39},
  publisher = {Multidisciplinary Digital Publishing Institute},
  issn = {2304-6775},
  doi = {10.3390/publications10040039},
  url = {https://www.mdpi.com/2304-6775/10/4/39},
  urldate = {2025-01-09},
  abstract = {The humanities and social sciences (HSS) have recently witnessed an exponential growth in data-driven research. In response, attention has been afforded to datasets and accompanying data papers as outputs of the research and dissemination ecosystem. In 2015, two data journals dedicated to HSS disciplines appeared in this landscape: Journal of Open Humanities Data (JOHD) and Research Data Journal for the Humanities and Social Sciences (RDJ). In this paper, we analyse the state of the art in the landscape of data journals in HSS using JOHD and RDJ as exemplars by measuring performance and the deep impact of data-driven projects, including metrics (citation count; Altmetrics, views, downloads, tweets) of data papers in relation to associated research papers and the reuse of associated datasets. Our findings indicate: that data papers are published following the deposit of datasets in a repository and usually following research articles; that data papers have a positive impact on both the metrics of research papers associated with them and on data reuse; and that Twitter hashtags targeted at specific research campaigns can lead to increases in data papers’ views and downloads. HSS data papers improve the visibility of datasets they describe, support accompanying research articles, and add to transparency and the open research agenda.},
  issue = {4},
  langid = {english},
  keywords = {data journals,data papers,data reuse,humanities,impact,open data,open humanities,open research,social sciences},
  file = {C:\Users\vanlissa\Zotero\storage\242AL26C\McGillivray et al. - 2022 - Deep Impact A Study on the Impact of Data Papers .pdf}
}

@article{mcphetresDecadeTheoryReflected2021,
  title = {A Decade of Theory as Reflected in {{Psychological Science}} (2009–2019)},
  author = {McPhetres, Jonathon and Albayrak-Aydemir, Nihan and Mendes, Ana Barbosa and Chow, Elvina C. and Gonzalez-Marquez, Patricio and Loukras, Erin and Maus, Annika and O’Mahony, Aoife and Pomareda, Christina and Primbs, Maximilian A. and Sackman, Shalaine L. and Smithson, Conor J. R. and Volodko, Kirill},
  date = {2021-03-05},
  journaltitle = {PLOS ONE},
  shortjournal = {PLOS ONE},
  volume = {16},
  number = {3},
  pages = {e0247986},
  publisher = {Public Library of Science},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0247986},
  url = {https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0247986},
  urldate = {2022-03-09},
  abstract = {The dominant belief is that science progresses by testing theories and moving towards theoretical consensus. While it’s implicitly assumed that psychology operates in this manner, critical discussions claim that the field suffers from a lack of cumulative theory. To examine this paradox, we analysed research published in Psychological Science from 2009–2019 (N = 2,225). We found mention of 359 theories in-text, most were referred to only once. Only 53.66\% of all manuscripts included the word theory, and only 15.33\% explicitly claimed to test predictions derived from theories. We interpret this to suggest that the majority of research published in this flagship journal is not driven by theory, nor can it be contributing to cumulative theory building. These data provide insight into the kinds of research psychologists are conducting and raises questions about the role of theory in the psychological sciences.},
  langid = {english},
  keywords = {Cognitive psychology,Experimental psychology,Psychologists,Psychology,Reaction time,Scientific publishing,Scientists,Semantics},
  file = {C\:\\Users\\vanlissa\\Zotero\\storage\\DZ9FJXZN\\McPhetres et al_2021_A decade of theory as reflected in Psychological Science (2009–2019).pdf;C\:\\Users\\vanlissa\\Zotero\\storage\\ETP3X67C\\article.html}
}

@article{meehlAppraisingAmendingTheories1990,
  title = {Appraising and {{Amending Theories}}: {{The Strategy}} of {{Lakatosian Defense}} and {{Two Principles}} That {{Warrant It}}},
  shorttitle = {Appraising and {{Amending Theories}}},
  author = {Meehl, Paul E.},
  date = {1990-04},
  journaltitle = {Psychological Inquiry},
  shortjournal = {Psychological Inquiry},
  volume = {1},
  number = {2},
  pages = {108--141},
  issn = {1047-840X, 1532-7965},
  doi = {10.1207/s15327965pli0102_1},
  url = {http://www.tandfonline.com/doi/abs/10.1207/s15327965pli0102_1},
  urldate = {2022-05-02},
  langid = {english},
  file = {C:\Users\vanlissa\Zotero\storage\5CMGPZTH\Meehl - 1990 - Appraising and Amending Theories The Strategy of .pdf}
}

@article{meehlTheoreticalRisksTabular1978,
  title = {Theoretical {{Risks}} and {{Tabular Asterisks}}: {{Sir Karl}}, {{Sir Ronald}}, and the {{Slow Progress}} of {{Soft Psychology}}},
  author = {Meehl, Paul E.},
  date = {1978},
  journaltitle = {Journal of Consulting \& Clinical Psychology},
  volume = {46},
  number = {4},
  pages = {806--834},
  langid = {english},
  file = {C:\Users\vanlissa\Zotero\storage\8YNMP9TQ\Meehl - Theoretical Risks and Tabular Asterisks.pdf}
}

@article{mischelToothbrushProblem2008,
  title = {The {{Toothbrush Problem}}},
  author = {Mischel, Walter},
  date = {2008-12-01},
  journaltitle = {APS Observer},
  volume = {21},
  url = {https://www.psychologicalscience.org/observer/the-toothbrush-problem},
  urldate = {2024-05-07},
  abstract = {In these columns, I have been discussing our “urban legends” — the often unspoken but widely shared understandings and misunderstandings about how to build a research-focused academic life in psychology. My goal is to look …},
  langid = {american},
  file = {C:\Users\vanlissa\Zotero\storage\BDLJLLY3\the-toothbrush-problem.html}
}

@article{morrisRoleFamilyContext2007,
  title = {The Role of the Family Context in the Development of Emotion Regulation},
  author = {Morris, Amanda Sheffield and Silk, Jennifer S. and Steinberg, Laurence and Myers, Sonya S. and Robinson, Lara Rachel},
  date = {2007},
  journaltitle = {Social development},
  volume = {16},
  number = {2},
  pages = {361--388},
  doi = {10.1111/j.1467-9507.2007.00389.x},
  file = {C:\Users\vanlissa\Zotero\storage\8IZJANJI\Morris et al_2007_The role of the family context in the development of emotion regulation.pdf}
}

@article{norouziCapturingCausalClaims2024,
  title = {Capturing {{Causal Claims}}: {{A Fine Tuned Text Mining Model}} for {{Extracting Causal Sentences}} from {{Social Science Papers}}},
  shorttitle = {Capturing {{Causal Claims}}},
  author = {Norouzi, Rasoul and Kleinberg, Bennett and Vermunt, Jeroen and Van Lissa, Caspar J.},
  date = {2024},
  publisher = {OSF},
  url = {https://osf.io/kwtpm/download},
  urldate = {2024-12-05},
  file = {C:\Users\vanlissa\Zotero\storage\E46IRUWL\Norouzi et al. - 2024 - Capturing Causal Claims A Fine Tuned Text Mining .pdf}
}

@article{nosekPromotingOpenResearch2015a,
  title = {Promoting an Open Research Culture},
  author = {Nosek, B. A. and Alter, G. and Banks, G. C. and Borsboom, D. and Bowman, S. D. and Breckler, S. J. and Buck, S. and Chambers, C. D. and Chin, G. and Christensen, G. and Contestabile, M. and Dafoe, A. and Eich, E. and Freese, J. and Glennerster, R. and Goroff, D. and Green, D. P. and Hesse, B. and Humphreys, M. and Ishiyama, J. and Karlan, D. and Kraut, A. and Lupia, A. and Mabry, P. and Madon, T. and Malhotra, N. and Mayo-Wilson, E. and McNutt, M. and Miguel, E. and Paluck, E. Levy and Simonsohn, U. and Soderberg, C. and Spellman, B. A. and Turitto, J. and VandenBos, G. and Vazire, S. and Wagenmakers, E. J. and Wilson, R. and Yarkoni, T.},
  date = {2015-06-26},
  journaltitle = {Science},
  volume = {348},
  number = {6242},
  eprint = {26113702},
  eprinttype = {pmid},
  pages = {1422--1425},
  issn = {0036-8075, 1095-9203},
  doi = {10.1126/science.aab2374},
  url = {http://science.sciencemag.org/content/348/6242/1422},
  urldate = {2019-02-07},
  abstract = {Author guidelines for journals could help to promote transparency, openness, and reproducibility Author guidelines for journals could help to promote transparency, openness, and reproducibility},
  langid = {english},
  file = {C\:\\Users\\vanlissa\\Zotero\\storage\\QMIA9CDD\\Nosek et al. - 2015 - Promoting an open research culture.pdf;C\:\\Users\\vanlissa\\Zotero\\storage\\CHZTCVV2\\1422.html}
}

@article{oberauerAddressingTheoryCrisis2019,
  title = {Addressing the Theory Crisis in Psychology},
  author = {Oberauer, Klaus and Lewandowsky, Stephan},
  date = {2019-10-01},
  journaltitle = {Psychonomic Bulletin \& Review},
  shortjournal = {Psychon Bull Rev},
  volume = {26},
  number = {5},
  pages = {1596--1618},
  issn = {1531-5320},
  doi = {10.3758/s13423-019-01645-2},
  url = {https://doi.org/10.3758/s13423-019-01645-2},
  urldate = {2022-10-20},
  abstract = {A worrying number of psychological findings are not replicable. Diagnoses of the causes of this “replication crisis,” and recommendations to address it, have nearly exclusively focused on methods of data collection, analysis, and reporting. We argue that a further cause of poor replicability is the often weak logical link between theories and their empirical tests. We propose a distinction between discovery-oriented and theory-testing research. In discovery-oriented research, theories do not strongly imply hypotheses by which they can be tested, but rather define a search space for the discovery of effects that would support them. Failures to find these effects do not question the theory. This endeavor necessarily engenders a high risk of Type I errors—that is, publication of findings that will not replicate. Theory-testing research, by contrast, relies on theories that strongly imply hypotheses, such that disconfirmation of the hypothesis provides evidence against the theory. Theory-testing research engenders a smaller risk of Type I errors. A strong link between theories and hypotheses is best achieved by formalizing theories as computational models. We critically revisit recommendations for addressing the “replication crisis,” including the proposal to distinguish exploratory from confirmatory research, and the preregistration of hypotheses and analysis plans.},
  langid = {english},
  keywords = {Computational modeling,Hypothesis testing,Preregistration,Replication,Scientific inference},
  file = {C:\Users\vanlissa\Zotero\storage\WLSKH5PR\Oberauer and Lewandowsky - 2019 - Addressing the theory crisis in psychology.pdf}
}

@article{pearlCausalDiagramsEmpirical1995,
  title = {Causal {{Diagrams}} for {{Empirical Research}}},
  author = {Pearl, Judea},
  date = {1995},
  journaltitle = {Biometrika},
  volume = {82},
  number = {4},
  eprint = {2337329},
  eprinttype = {jstor},
  pages = {669--688},
  publisher = {[Oxford University Press, Biometrika Trust]},
  issn = {0006-3444},
  doi = {10.2307/2337329},
  url = {https://www.jstor.org/stable/2337329},
  urldate = {2022-05-01},
  abstract = {The primary aim of this paper is to show how graphical models can be used as a mathematical language for integrating statistical and subject-matter information. In particular, the paper develops a principled, nonparametric framework for causal inference, in which diagrams are queried to determine if the assumptions available are sufficient for identifying causal effects from nonexperimental data. If so the diagrams can be queried to produce mathematical expressions for causal effects in terms of observed distributions; otherwise, the diagrams can be queried to suggest additional observations or auxiliary experiments from which the desired inferences can be obtained.}
}

@article{peikertReproducibleResearchTutorial2021,
  title = {Reproducible {{Research}} in {{R}}: {{A Tutorial}} on {{How}} to {{Do}} the {{Same Thing More Than Once}}},
  shorttitle = {Reproducible {{Research}} in {{R}}},
  author = {Peikert, Aaron and Van Lissa, Caspar J. and Brandmaier, Andreas M.},
  date = {2021-12-09},
  journaltitle = {Psych},
  shortjournal = {Psych},
  volume = {3},
  number = {4},
  pages = {836--867},
  issn = {2624-8611},
  doi = {10.3390/psych3040053},
  url = {https://www.mdpi.com/2624-8611/3/4/53},
  urldate = {2022-04-28},
  abstract = {Computational reproducibility is the ability to obtain identical results from the same data with the same computer code. It is a building block for transparent and cumulative science because it enables the originator and other researchers, on other computers and later in time, to reproduce and thus understand how results came about, while avoiding a variety of errors that may lead to erroneous reporting of statistical and computational results. In this tutorial, we demonstrate how the R package repro supports researchers in creating fully computationally reproducible research projects with tools from the software engineering community. Building upon this notion of fully automated reproducibility, we present several applications including the preregistration of research plans with code (Preregistration as Code, PAC). PAC eschews all ambiguity of traditional preregistration and offers several more advantages. Making technical advancements that serve reproducibility more widely accessible for researchers holds the potential to innovate the research process and to help it become more productive, credible, and reliable.},
  langid = {english},
  file = {C:\Users\vanlissa\Zotero\storage\9QBMR6G7\Peikert et al. - 2021 - Reproducible Research in R A Tutorial on How to D.pdf}
}

@online{peikertWhyDoesPreregistration2023,
  type = {preprint},
  title = {Why Does Preregistration Increase the Persuasiveness of Evidence? {{A Bayesian}} Rationalization},
  shorttitle = {Why Does Preregistration Increase the Persuasiveness of Evidence?},
  author = {Peikert, Aaron and Ernst, Maximilian Stefan and Brandmaier, Andreas Markus},
  date = {2023-02-17},
  doi = {10.31234/osf.io/cs8wb},
  url = {https://osf.io/cs8wb},
  urldate = {2023-02-20},
  abstract = {The replication crisis has led many researchers to preregister their hypotheses and data analysis plans before collecting data.A widely held view is that preregistration is supposed to limit the extent to which data may influence the hypotheses to be tested.Only if data have no influence an analysis is considered confirmatory. Consequently, many researchers believe that preregistration is only applicable in confirmatory paradigms.In practice, researchers may struggle to preregister their hypotheses because of vague theories that necessitate data-dependent decisions (aka exploration).We argue that preregistration benefits any study on the continuum between confirmatory and exploratory research.To that end, we formalize a general objective of preregistration and demonstrate that exploratory studies also benefit from preregistration.Drawing on Bayesian philosophy of science, we argue that preregistration should primarily aim to reduce uncertainty about the inferential procedure used to derive results.This approach provides a principled justification of preregistration, separating the procedure from the goal of ensuring strictly confirmatory research.We acknowledge that knowing the extent to which a study is exploratory is central, but certainty about the inferential procedure is a prerequisite for persuasive evidence.Finally, we discuss the implications of these insights for the practice of preregistration.},
  pubstate = {prepublished}
}


@thesis{peikertTransparencyOpenScience2023,
  type = {doctoralThesis},
  title = {Towards {{Transparency}} and {{Open Science}}},
  author = {Peikert, Aaron},
  date = {2023-10-17},
  institution = {Humboldt-Universität zu Berlin},
  doi = {10.18452/27056},
  url = {https://edoc.hu-berlin.de/handle/18452/28171},
  urldate = {2024-02-23},
  abstract = {Die Psychologie und andere empirische Wissenschaften befinden sich in einer Krise, da vielen Forschenden bewusst geworden ist, dass viele Erkenntnisse nicht so stark empirisch gestützt sind, wie sie einst glaubten.  Es wurden mehrere Ursachen dieser Krise vorgeschlagen: Missbrauch statistischer Methoden, soziologische Verzerrungen und schwache Theorien.  In dieser Dissertation gehe ich davon aus, dass ungenaue Theorien unvermeidlich sind, diese aber mithilfe von Induktion einer empirischen Prüfung unterzogen werden können.  Anhand von Daten können Theorien ergänzt werden, sodass präzise Vorhersagen möglich sind, die sich mit der Realität vergleichen lassen.  Eine solche Strategie ist jedoch mit Kosten verbunden.  Induktion ist daher zwar notwendig, aber führt zu einem übermäßigen Vertrauen in empirische Befunde.  Um empirische Ergebnisse adäquat zu bewerten, muss diese Verzerrung berücksichtigt werden.  Das Ausmaß der Verzerrung hängt von den Eigenschaften des induktiven Prozesses ab.  Einige induktive Prozesse können vollständig transparent gemacht werden, sodass ihre Verzerrung angemessen berücksichtigt werden kann.  Ich zeige, dass dies bei Induktion der Fall ist, die beliebig mit anderen Daten wiederholt werden kann, was die Bedeutung von computergestützter Reproduzierbarkeit unterstreicht.  Induktion, die die Forschenden und ihr kognitives Modell einbezieht, kann nicht beliebig wiederholt werden; daher kann die Verzerrung durch Induktion nur mit Unsicherheit beurteilt werden.  Ich schlage vor, dass die Verringerung dieser Unsicherheit das Ziel von Präregistrierung sein sollte.  Nachdem ich die Ziele von Reproduzierbarkeit und Präregistrierung unter dem Gesichtspunkt der Transparenz über Induktion präzisiert habe, gebe ich in den wissenschaftlichen Artikeln, die als Teil der Dissertation veröffentlicht wurden, Empfehlungen für die praktische Umsetzung beider Verfahren.},
  langid = {english},
  annotation = {Accepted: 2023-10-17T11:10:35Z},
  file = {C:\Users\vanlissa\Zotero\storage\3XTQNMV5\Peikert - 2023 - Towards Transparency and Open Science.pdf}
}

@book{peirceCollectedPapersCharles1960,
  title = {Collected {{Papers Of Charles Peirce}}},
  author = {Peirce, Charles},
  date = {1960},
  url = {http://archive.org/details/collected-papers-of-charles-peirce},
  urldate = {2025-01-29},
  abstract = {Charles Sanders Peirce plays a unique rôle in the history of Americanphilosophy. During his own lifetime he published no book on philosophy, and exceptfor a relatively short period he held no university chair from which to impress hisinfluence upon students; yet he has come to be recognized as the founder of the onedistinctive movement which this country has produced.Peirce: CP 1 Introduction p iiiPragmatism, as it developed, followed the pattern of William James' thoughtand that of John Dewey rather than the conceptions of Peirce; but it was Peirce, asJames and Dewey magnanimously insisted, who defined the principle of themovement and gave it the first impetus. Never indeed a leader of movements, Peircewas an originator of ideas. He clearly formulated in his writings many conceptionswhich are only today beginning to find recognition, and there are implications in histhought which have not yet been fully developed.Peirce: CP 1 Introduction p iiiArticles on pragmatism represent only one phase of his work. Some of his bestthought was devoted to logical problems: to the logic of classes and relations, thetheory of signs, scientific method, to probability and induction, and to the logical},
  langid = {english},
  keywords = {Philosophy},
  file = {C:\Users\vanlissa\Zotero\storage\I6RVV2HX\peirce-collectedpapers.pdf}
}

@book{popperLogicScientificDiscovery2002,
  title = {The Logic of Scientific Discovery},
  author = {Popper, Karl R},
  date = {2002},
  url = {http://public.ebookcentral.proquest.com/choice/publicfullrecord.aspx?p=254228},
  urldate = {2022-08-19},
  abstract = {When first published in 1959, this book revolutionized contemporary thinking about science and knowledge. It remains the one of the most widely read books about science to come out of the twentieth century.},
  isbn = {978-0-203-99462-7 978-1-280-23930-4},
  langid = {english},
  annotation = {OCLC: 475967187},
  file = {C:\Users\vanlissa\Zotero\storage\PRYUKFIS\Popper - 2002 - The logic of scientific discovery.pdf}
}

@article{quineReasonsIndeterminacyTranslation1970,
  title = {On the {{Reasons}} for {{Indeterminacy}} of {{Translation}}},
  author = {Quine, W. V.},
  date = {1970},
  journaltitle = {The Journal of Philosophy},
  volume = {67},
  number = {6},
  eprint = {2023887},
  eprinttype = {jstor},
  pages = {178--183},
  publisher = {Journal of Philosophy, Inc.},
  issn = {0022-362X},
  doi = {10.2307/2023887},
  url = {https://www.jstor.org/stable/2023887},
  urldate = {2024-11-20},
  file = {C:\Users\vanlissa\Zotero\storage\Q6HGZB86\Quine - 1970 - On the Reasons for Indeterminacy of Translation.pdf}
}

@article{ramGitCanFacilitate2013,
  title = {Git Can Facilitate Greater Reproducibility and Increased Transparency in Science},
  author = {Ram, Karthik},
  date = {2013-02-28},
  journaltitle = {Source Code for Biology and Medicine},
  shortjournal = {Source Code for Biology and Medicine},
  volume = {8},
  number = {1},
  pages = {7},
  issn = {1751-0473},
  doi = {10.1186/1751-0473-8-7},
  url = {https://doi.org/10.1186/1751-0473-8-7},
  urldate = {2020-01-08},
  abstract = {Reproducibility is the hallmark of good science. Maintaining a high degree of transparency in scientific reporting is essential not just for gaining trust and credibility within the scientific community but also for facilitating the development of new ideas. Sharing data and computer code associated with publications is becoming increasingly common, motivated partly in response to data deposition requirements from journals and mandates from funders. Despite this increase in transparency, it is still difficult to reproduce or build upon the findings of most scientific publications without access to a more complete workflow.},
  file = {C\:\\Users\\vanlissa\\Zotero\\storage\\RZB63RDE\\Ram_2013_Git can facilitate greater reproducibility and increased transparency in science.pdf;C\:\\Users\\vanlissa\\Zotero\\storage\\H4UH8INM\\1751-0473-8-7.html}
}

@article{robinaughInvisibleHandsFine2021,
  title = {Invisible {{Hands}} and {{Fine Calipers}}: {{A Call}} to {{Use Formal Theory}} as a {{Toolkit}} for {{Theory Construction}}},
  shorttitle = {Invisible {{Hands}} and {{Fine Calipers}}},
  author = {Robinaugh, Donald J. and Haslbeck, Jonas M. B. and Ryan, Oisín and Fried, Eiko I. and Waldorp, Lourens J.},
  date = {2021-07-01},
  journaltitle = {Perspectives on Psychological Science},
  shortjournal = {Perspect Psychol Sci},
  volume = {16},
  number = {4},
  pages = {725--743},
  publisher = {SAGE Publications Inc},
  issn = {1745-6916},
  doi = {10.1177/1745691620974697},
  url = {https://doi.org/10.1177/1745691620974697},
  urldate = {2024-02-08},
  abstract = {In recent years, a growing chorus of researchers has argued that psychological theory is in a state of crisis: Theories are rarely developed in a way that indicates an accumulation of knowledge. Paul Meehl raised this very concern more than 40 years ago. Yet in the ensuing decades, little has improved. We aim to chart a better path forward for psychological theory by revisiting Meehl’s criticisms, his proposed solution, and the reasons his solution failed to meaningfully change the status of psychological theory. We argue that Meehl identified serious shortcomings in our evaluation of psychological theories and that his proposed solution would substantially strengthen theory testing. However, we also argue that Meehl failed to provide researchers with the tools necessary to construct the kinds of rigorous theories his approach required. To advance psychological theory, we must equip researchers with tools that allow them to better generate, evaluate, and develop their theories. We argue that formal theories provide this much-needed set of tools, equipping researchers with tools for thinking, evaluating explanation, enhancing measurement, informing theory development, and promoting the collaborative construction of psychological theories.},
  langid = {english},
  file = {C:\Users\vanlissa\Zotero\storage\I3UI652D\Robinaugh et al. - 2021 - Invisible Hands and Fine Calipers A Call to Use F.pdf}
}

@article{ryanSelfdeterminationTheoryFacilitation2000,
  title = {Self-Determination Theory and the Facilitation of Intrinsic Motivation, Social Development, and Well-Being},
  author = {Ryan, Richard M. and Deci, Edward L.},
  date = {2000},
  journaltitle = {American Psychologist},
  volume = {55},
  number = {1},
  pages = {68--78},
  publisher = {American Psychological Association},
  location = {US},
  issn = {1935-990X},
  doi = {10.1037/0003-066X.55.1.68}
}

@article{scheelExcessPositiveResults2021,
  title = {An {{Excess}} of {{Positive Results}}: {{Comparing}} the {{Standard Psychology Literature With Registered Reports}}},
  shorttitle = {An {{Excess}} of {{Positive Results}}},
  author = {Scheel, Anne M. and Schijen, Mitchell R. M. J. and Lakens, Daniël},
  date = {2021-04-01},
  journaltitle = {Advances in Methods and Practices in Psychological Science},
  shortjournal = {Advances in Methods and Practices in Psychological Science},
  volume = {4},
  number = {2},
  pages = {25152459211007467},
  publisher = {SAGE Publications Inc},
  issn = {2515-2459},
  doi = {10.1177/25152459211007467},
  url = {https://doi.org/10.1177/25152459211007467},
  urldate = {2022-04-15},
  abstract = {Selectively publishing results that support the tested hypotheses (?positive? results) distorts the available evidence for scientific claims. For the past decade, psychological scientists have been increasingly concerned about the degree of such distortion in their literature. A new publication format has been developed to prevent selective reporting: In Registered Reports (RRs), peer review and the decision to publish take place before results are known. We compared the results in published RRs (N = 71 as of November 2018) with a random sample of hypothesis-testing studies from the standard literature (N = 152) in psychology. Analyzing the first hypothesis of each article, we found 96\% positive results in standard reports but only 44\% positive results in RRs. We discuss possible explanations for this large difference and suggest that a plausible factor is the reduction of publication bias and/or Type I error inflation in the RR literature.},
  file = {C:\Users\vanlissa\Zotero\storage\LEW9B5MX\Scheel et al_2021_An Excess of Positive Results.pdf}
}

@article{scheelWhyHypothesisTesters2021,
  title = {Why {{Hypothesis Testers Should Spend Less Time Testing Hypotheses}}},
  author = {Scheel, Anne M. and Tiokhin, Leonid and Isager, Peder M. and Lakens, Daniël},
  date = {2021-07-01},
  journaltitle = {Perspectives on Psychological Science},
  shortjournal = {Perspect Psychol Sci},
  volume = {16},
  number = {4},
  pages = {744--755},
  publisher = {SAGE Publications Inc},
  issn = {1745-6916},
  doi = {10.1177/1745691620966795},
  url = {https://doi.org/10.1177/1745691620966795},
  urldate = {2023-10-12},
  abstract = {For almost half a century, Paul Meehl educated psychologists about how the mindless use of null-hypothesis significance tests made research on theories in the social sciences basically uninterpretable. In response to the replication crisis, reforms in psychology have focused on formalizing procedures for testing hypotheses. These reforms were necessary and influential. However, as an unexpected consequence, psychological scientists have begun to realize that they may not be ready to test hypotheses. Forcing researchers to prematurely test hypotheses before they have established a sound “derivation chain” between test and theory is counterproductive. Instead, various nonconfirmatory research activities should be used to obtain the inputs necessary to make hypothesis tests informative. Before testing hypotheses, researchers should spend more time forming concepts, developing valid measures, establishing the causal relationships between concepts and the functional form of those relationships, and identifying boundary conditions and auxiliary assumptions. Providing these inputs should be recognized and incentivized as a crucial goal in itself. In this article, we discuss how shifting the focus to nonconfirmatory research can tie together many loose ends of psychology’s reform movement and help us to develop strong, testable theories, as Paul Meehl urged.},
  langid = {english},
  file = {C:\Users\vanlissa\Zotero\storage\EIJPIJHY\Scheel et al. - 2021 - Why Hypothesis Testers Should Spend Less Time Test.pdf}
}

@article{scheelWhyMostPsychological2022,
  title = {Why Most Psychological Research Findings Are Not Even Wrong},
  author = {Scheel, Anne M.},
  date = {2022},
  journaltitle = {Infant and Child Development},
  volume = {31},
  number = {1},
  pages = {e2295},
  issn = {1522-7219},
  doi = {10.1002/icd.2295},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/icd.2295},
  urldate = {2022-03-01},
  abstract = {Psychology's replication crisis is typically conceptualized as the insight that the published literature contains a worrying amount of unreplicable, false-positive findings. At the same time, meta-scientific attempts to assess the crisis in more detail have reported substantial difficulties in identifying unambiguous definitions of the scientific claims in published articles and determining how they are connected to the presented evidence. I argue that most claims in the literature are so critically underspecified that attempts to empirically evaluate them are doomed to failure—they are not even wrong. Meta-scientists should beware of the flawed assumption that the psychological literature is a collection of well-defined claims. To move beyond the crisis, psychologists must reconsider and rebuild the conceptual basis of their hypotheses before trying to test them.},
  langid = {english},
  keywords = {falsification,hypothesis testing,replication crisis,reproducibility,scientific inference},
  file = {C\:\\Users\\vanlissa\\Zotero\\storage\\RCSX27VL\\Scheel_2022_Why most psychological research findings are not even wrong.pdf;C\:\\Users\\vanlissa\\Zotero\\storage\\77G7YKYE\\icd.html}
}

@incollection{scientifictheories,
  title = {The Structure of Scientific Theories},
  booktitle = {The {{Stanford}} Encyclopedia of Philosophy},
  author = {Winther, Rasmus Grønfeldt},
  editor = {Zalta, Edward N.},
  date = {2021},
  edition = {Spring 2021},
  publisher = {Metaphysics Research Lab, Stanford University},
  url = {https://plato.stanford.edu/archives/spr2021/entries/structure-scientific-theories/}
}

@article{szollosiArrestedTheoryDevelopment2021,
  title = {Arrested Theory Development: {{The}} Misguided Distinction between Exploratory and Confirmatory Research},
  author = {Szollosi, Aba and Donkin, Chris},
  date = {2021},
  journaltitle = {Perspectives on Psychological Science},
  volume = {16},
  number = {4},
  pages = {717--724},
  doi = {10.1177/1745691620966796},
  abstract = {Science progresses by finding and correcting problems in theories. Good theories are those that help facilitate this process by being hard-to-vary: they explain what they are supposed to explain, they are consistent with other good theories, and they are not easily adaptable to explain anything. Here we argue that, rather than a lack of distinction between exploratory and confirmatory research, an abundance of flexible theories is a better explanation for current replicability problems of psychology. We also explain why popular methods-oriented solutions fail to address the real problem of flexibility. Instead, we propose that a greater emphasis on theory criticism by argument would improve replicability.},
  langid = {english},
  file = {C:\Users\vanlissa\Zotero\storage\AULQYHPI\Szollosi and Donkin - Arrested theory development The misguided distinc.pdf}
}

@article{taylor2022psychology,
  title = {The Psychology of Pandemics},
  author = {Taylor, Steven},
  date = {2022},
  journaltitle = {Annual review of clinical psychology},
  volume = {18},
  number = {1},
  pages = {581--609},
  publisher = {Annual Reviews}
}

@article{vandermaasDynamicalModelGeneral2006,
  title = {A Dynamical Model of General Intelligence: {{The}} Positive Manifold of Intelligence by Mutualism},
  shorttitle = {A Dynamical Model of General Intelligence},
  author = {Van Der Maas, Han L. J. and Dolan, Conor V. and Grasman, Raoul P. P. P. and Wicherts, Jelte M. and Huizenga, Hilde M. and Raijmakers, Maartje E. J.},
  date = {2006},
  journaltitle = {Psychological Review},
  volume = {113},
  number = {4},
  pages = {842--861},
  publisher = {American Psychological Association},
  location = {US},
  issn = {1939-1471},
  doi = {10.1037/0033-295X.113.4.842},
  abstract = {Scores on cognitive tasks used in intelligence tests correlate positively with each other, that is, they display a positive manifold of correlations. The positive manifold is often explained by positing a dominant latent variable, the g factor, associated with a single quantitative cognitive or biological process or capacity. In this article, a new explanation of the positive manifold based on a dynamical model is proposed, in which reciprocal causation or mutualism plays a central role. It is shown that the positive manifold emerges purely by positive beneficial interactions between cognitive processes during development. A single underlying g factor plays no role in the model. The model offers explanations of important findings in intelligence research, such as the hierarchical factor structure of intelligence, the low predictability of intelligence from early childhood performance, the integration/differentiation effect, the increase in heritability of g, and the Jensen effect, and is consistent with current explanations of the Flynn effect. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
  keywords = {Cognitive Processes,Factor Structure,Intelligence,Models},
  file = {C:\Users\vanlissa\Zotero\storage\ECM5N4RQ\doiLanding.html}
}

@article{vandesompelRethinkingScholarlyCommunication2004,
  title = {Rethinking {{Scholarly Communication}}: {{Building}} the {{System}} That {{Scholars Deserve}}},
  shorttitle = {Rethinking {{Scholarly Communication}}},
  author = {Van De Sompel, Herbert and Payette, Sandy and Erickson, John and Lagoze, Carl and Warner, Simeon},
  date = {2004-09},
  journaltitle = {D-Lib Magazine},
  shortjournal = {D-Lib Magazine},
  volume = {10},
  number = {9},
  issn = {1082-9873},
  doi = {10.1045/september2004-vandesompel},
  url = {http://www.dlib.org/dlib/september04/vandesompel/09vandesompel.html},
  urldate = {2025-01-09},
  langid = {english},
  file = {C:\Users\vanlissa\Zotero\storage\UKDRLQTW\Van De Sompel et al. - 2004 - Rethinking Scholarly Communication Building the S.pdf}
}

@online{vandongenPsychoModelsMathematicalComputational2025,
  title = {{{PsychoModels}}: {{The}} Mathematical and Computational Model Repository for Psychological Science.},
  author = {family=Dongen, given=Noah N. N., prefix=van, useprefix=true and Volz, L.},
  date = {2025},
  url = {https://www.psychomodels.org/},
  urldate = {2025-03-05},
  file = {C:\Users\vanlissa\Zotero\storage\97ULYVDE\www.psychomodels.org.html}
}

@article{vanlissaTeacherCornerEvaluating2020,
  title = {Teacher’s {{Corner}}: {{Evaluating Informative Hypotheses Using}} the {{Bayes Factor}} in {{Structural Equation Models}}},
  shorttitle = {Teacher’s {{Corner}}},
  author = {Van Lissa, Caspar J. and Gu, Xin and Mulder, Joris and Rosseel, Yves and Zundert, Camiel Van and Hoijtink, Herbert},
  date = {2020-05-29},
  journaltitle = {Structural Equation Modeling: A Multidisciplinary Journal},
  volume = {0},
  number = {0},
  pages = {1--10},
  publisher = {Routledge},
  issn = {1070-5511},
  doi = {10.1080/10705511.2020.1745644},
  url = {https://doi.org/10.1080/10705511.2020.1745644},
  urldate = {2020-08-18},
  abstract = {This Teacher’s Corner paper introduces Bayesian evaluation of informative hypotheses for structural equation models, using the free open-source R packages bain, for Bayesian informative hypothesis testing, and lavaan, a widely used SEM package. The introduction provides a brief non-technical explanation of informative hypotheses, the statistical underpinnings of Bayesian hypothesis evaluation, and the bain algorithm. Three tutorial examples demonstrate informative hypothesis evaluation in the context of common types of structural equation models: 1) confirmatory factor analysis, 2) latent variable regression, and 3) multiple group analysis. We discuss hypothesis formulation, the interpretation of Bayes factors and posterior model probabilities, and sensitivity analysis.},
  keywords = {Bain,bayes factor,informative hypotheses,structural equation modeling}
}

@online{vanlissaUsingEndpointsCheck2023,
  type = {Package Documentation},
  title = {Using {{Endpoints}} to {{Check Reproducibility}}},
  author = {Van Lissa, Caspar J.},
  date = {2023},
  url = {https://cjvanlissa.github.io/worcs/articles/endpoints.html},
  urldate = {2024-03-21},
  abstract = {worcs},
  langid = {english},
  organization = {worcs 0.1.15.2 package documentation},
  file = {C:\Users\vanlissa\Zotero\storage\QEDWE8TZ\endpoints.html}
}

@article{vanlissaVisionTeamScience2024,
  title = {Towards a {{Vision}} for {{Team Science}} at {{Tilburg University}}},
  author = {Van Lissa, Caspar J. and Keymolen, Esther and family=Hoek, given=Sasha, prefix=van den, useprefix=false and Klingner, Annika and Schurman, Lilly and family=Hunnik, given=Marjan, prefix=van, useprefix=false},
  date = {2024-02-23},
  publisher = {OSF},
  doi = {10.31234/osf.io/jsbuv},
  url = {https://osf.io/jsbuv},
  urldate = {2024-02-23},
  abstract = {Tilburg University has committed to establishing a vision on Team Science in 2023. To meet this mandate, the working group "Team Science" was established within the university-wide program "Use (Y)our Talents". The working group Team Science wrote this policy brief to inform a vision on Team Science, paying attention to the following: 1) Defining team science in the context of Tilburg University (with special attention to the Social Sciences \&amp; Humanities, SSH); 2) Exploring the scientific literature on team science; 3) Developing practical starting points for the implementation of team science; and 4) Charting national and international best practices for team science.},
  langid = {american},
  file = {C\:\\Users\\vanlissa\\Zotero\\storage\\E5DBP5S2\\Lissa et al. - 2024 - Towards a Vision for Team Science at Tilburg Unive.pdf;C\:\\Users\\vanlissa\\Zotero\\storage\\U6IHDK2B\\jsbuv.html}
}

@article{vanlissaWORCSWorkflowOpen2021,
  title = {{{WORCS}}: {{A}} Workflow for Open Reproducible Code in Science},
  author = {Van Lissa, Caspar J. and Brandmaier, Andreas M. and Brinkman, Loek and Lamprecht, Anna-Lena and Peikert, Aaron and Struiksma, Marijn E. and Vreede, Barbara M.I.},
  date = {2021},
  journaltitle = {Data Science},
  volume = {4},
  number = {1},
  pages = {29--49},
  publisher = {IOS Press},
  issn = {2451-8492},
  doi = {10.3233/DS-210031},
  abstract = {Adopting open science principles can be challenging, requiring conceptual education and training in the use of new tools. This paper introduces the Workflow for Open Reproducible Code in Science (WORCS): A step-by-step procedure that researchers can follow to make a research project open and reproducible. This workflow intends to lower the threshold for adoption of open science principles. It is based on established best practices, and can be used either in parallel to, or in absence of, top-down requirements by journals, institutions, and funding bodies. To facilitate widespread adoption, the WORCS principles have been implemented in the R package worcs , which offers an RStudio project template and utility functions for specific workflow steps. This paper introduces the conceptual workflow, discusses how it meets different standards for open science, and addresses the functionality provided by the R implementation, worcs . This paper is primarily targeted towards scholars conducting research projects in R, conducting research that involves academic prose, analysis code, and tabular data. However, the workflow is flexible enough to accommodate other scenarios, and offers a starting point for customized solutions. The source code for the R package and manuscript, and a list of examplesof WORCS projects , are available at https://github.com/cjvanlissa/worcs .},
  keywords = {dynamic document generation,Open science,r,reproducibility,version control}
}

@article{vanrooijTheoryTestHow2021,
  title = {Theory {{Before}} the {{Test}}: {{How}} to {{Build High-Verisimilitude Explanatory Theories}} in {{Psychological Science}}},
  shorttitle = {Theory {{Before}} the {{Test}}},
  author = {family=Rooij, given=Iris, prefix=van, useprefix=true and Baggio, Giosuè},
  date = {2021-07-01},
  journaltitle = {Perspectives on Psychological Science},
  shortjournal = {Perspect Psychol Sci},
  volume = {16},
  number = {4},
  pages = {682--697},
  publisher = {SAGE Publications Inc},
  issn = {1745-6916},
  doi = {10.1177/1745691620970604},
  url = {https://doi.org/10.1177/1745691620970604},
  urldate = {2022-04-30},
  abstract = {Drawing on the philosophy of psychological explanation, we suggest that psychological science, by focusing on effects, may lose sight of its primary explananda: psychological capacities. We revisit Marr?s levels-of-analysis framework, which has been remarkably productive and useful for cognitive psychological explanation. We discuss ways in which Marr?s framework may be extended to other areas of psychology, such as social, developmental, and evolutionary psychology, bringing new benefits to these fields. We then show how theoretical analyses can endow a theory with minimal plausibility even before contact with empirical data: We call this the theoretical cycle. Finally, we explain how our proposal may contribute to addressing critical issues in psychological science, including how to leverage effects to understand capacities better.},
  file = {C:\Users\vanlissa\Zotero\storage\LW2SJ4JX\van Rooij_Baggio_2021_Theory Before the Test.pdf}
}

@online{vogtFAIR20Extending2024,
  title = {{{FAIR}} 2.0: {{Extending}} the {{FAIR Guiding Principles}} to {{Address Semantic Interoperability}}},
  shorttitle = {{{FAIR}} 2.0},
  author = {Vogt, Lars and Strömert, Philip and Matentzoglu, Nicolas and Karam, Naouel and Konrad, Marcel and Prinz, Manuel and Baum, Roman},
  date = {2024-05-06},
  eprint = {2405.03345},
  eprinttype = {arXiv},
  url = {http://arxiv.org/abs/2405.03345},
  urldate = {2024-11-20},
  abstract = {FAIR data presupposes their successful communication between machines and humans while preserving their meaning and reference, requiring all parties involved to share the same background knowledge. Inspired by English as a natural language, we investigate the linguistic structure that ensures reliable communication of information and draw parallels with data structures, understanding both as models of systems of interest. We conceptualize semantic interoperability as comprising terminological and propositional interoperability. The former includes ontological (i.e., same meaning) and referential (i.e., same referent/extension) interoperability and the latter schema (i.e., same data schema) and logical (i.e., same logical framework) interoperability. Since no best ontology and no best data schema exists, establishing semantic interoperability and FAIRness of data and metadata requires the provision of a comprehensive set of relevant ontological and referential entity mappings and schema crosswalks. We therefore propose appropriate additions to the FAIR Guiding Principles, leading to FAIR 2.0. Furthermore, achieving FAIRness of data requires the provision of FAIR services in addition to organizing data into FAIR Digital Objects. FAIR services include a terminology, a schema, and an operations service.},
  pubstate = {prepublished},
  keywords = {Computer Science - Databases},
  file = {C\:\\Users\\vanlissa\\Zotero\\storage\\LXGHVJ34\\Vogt et al. - 2024 - FAIR 2.0 Extending the FAIR Guiding Principles to.pdf;C\:\\Users\\vanlissa\\Zotero\\storage\\HMWZVVD9\\2405.html}
}

@article{wagenmakersCreativityVerificationCyclePsychological2018,
  title = {The {{Creativity-Verification Cycle}} in {{Psychological Science}}: {{New Methods}} to {{Combat Old Idols}}},
  shorttitle = {The {{Creativity-Verification Cycle}} in {{Psychological Science}}},
  author = {Wagenmakers, Eric-Jan and Dutilh, Gilles and Sarafoglou, Alexandra},
  date = {2018-07},
  journaltitle = {Perspectives on Psychological Science},
  shortjournal = {Perspect Psychol Sci},
  volume = {13},
  number = {4},
  eprint = {29961413},
  eprinttype = {pmid},
  pages = {418--427},
  issn = {1745-6916},
  doi = {10.1177/1745691618771357},
  url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6041759/},
  urldate = {2021-02-09},
  abstract = {Over the years, researchers in psychological science have documented and investigated a host of powerful cognitive fallacies, including hindsight bias and confirmation bias. Researchers themselves may not be immune to these fallacies and may unwittingly adjust their statistical analysis to produce an outcome that is more pleasant or better in line with prior expectations. To shield researchers from the impact of cognitive fallacies, several methodologists are now advocating preregistration—that is, the creation of a detailed analysis plan before data collection or data analysis. One may argue, however, that preregistration is out of touch with academic reality, hampering creativity and impeding scientific progress. We provide a historical overview to show that the interplay between creativity and verification has shaped theories of scientific inquiry throughout the centuries; in the currently dominant theory, creativity and verification operate in succession and enhance one another’s effectiveness. From this perspective, the use of preregistration to safeguard the verification stage will help rather than hinder the generation of fruitful new ideas.},
  pmcid = {PMC6041759},
  file = {C:\Users\vanlissa\Zotero\storage\8BHSVEHH\Wagenmakers et al_2018_The Creativity-Verification Cycle in Psychological Science.pdf}
}

@unpublished{wilkinson2024applying,
  title = {Applying the {{FAIR}} Principles to Computational Workflows},
  author = {Wilkinson, Sean R and Aloqalaa, Meznah and Belhajjame, Khalid and Crusoe, Michael R and Kinoshita, Bruno de Paula and Gadelha, Luiz and Garijo, Daniel and Gustafsson, Ove Johan Ragnar and Juty, Nick and Kanwal, Sehrish and others},
  date = {2024},
  eprint = {2410.03490},
  eprinttype = {arXiv}
}

@article{wilkinsonFAIRGuidingPrinciples2016,
  title = {The {{FAIR Guiding Principles}} for Scientific Data Management and Stewardship},
  author = {Wilkinson, Mark D. and Dumontier, Michel and family=Aalbersberg, given=IJsbrand Jan, given-i={{IJ}}J and Appleton, Gabrielle and Axton, Myles and Baak, Arie and Blomberg, Niklas and Boiten, Jan-Willem and family=Silva Santos, given=Luiz Bonino, prefix=da, useprefix=true and Bourne, Philip E. and Bouwman, Jildau and Brookes, Anthony J. and Clark, Tim and Crosas, Mercè and Dillo, Ingrid and Dumon, Olivier and Edmunds, Scott and Evelo, Chris T. and Finkers, Richard and Gonzalez-Beltran, Alejandra and Gray, Alasdair J. G. and Groth, Paul and Goble, Carole and Grethe, Jeffrey S. and Heringa, Jaap and family=Hoen, given=Peter A. C., prefix=’t, useprefix=true and Hooft, Rob and Kuhn, Tobias and Kok, Ruben and Kok, Joost and Lusher, Scott J. and Martone, Maryann E. and Mons, Albert and Packer, Abel L. and Persson, Bengt and Rocca-Serra, Philippe and Roos, Marco and family=Schaik, given=Rene, prefix=van, useprefix=true and Sansone, Susanna-Assunta and Schultes, Erik and Sengstag, Thierry and Slater, Ted and Strawn, George and Swertz, Morris A. and Thompson, Mark and family=Lei, given=Johan, prefix=van der, useprefix=true and family=Mulligen, given=Erik, prefix=van, useprefix=true and Velterop, Jan and Waagmeester, Andra and Wittenburg, Peter and Wolstencroft, Katherine and Zhao, Jun and Mons, Barend},
  date = {2016-03-15},
  journaltitle = {Scientific Data},
  volume = {3},
  number = {1},
  pages = {1--9},
  publisher = {Nature Publishing Group},
  issn = {2052-4463},
  doi = {10.1038/sdata.2016.18},
  url = {https://www.nature.com/articles/sdata201618},
  urldate = {2020-04-23},
  abstract = {There is an urgent need to improve the infrastructure supporting the reuse of scholarly data. A diverse set of stakeholders—representing academia, industry, funding agencies, and scholarly publishers—have come together to design and jointly endorse a concise and measureable set of principles that we refer to as the FAIR Data Principles. The intent is that these may act as a guideline for those wishing to enhance the reusability of their data holdings. Distinct from peer initiatives that focus on the human scholar, the FAIR Principles put specific emphasis on enhancing the ability of machines to automatically find and use the data, in addition to supporting its reuse by individuals. This Comment is the first formal publication of the FAIR Principles, and includes the rationale behind them, and some exemplar implementations in the community.},
  issue = {1},
  langid = {english},
  file = {C\:\\Users\\vanlissa\\Zotero\\storage\\GIZ9EY4X\\Wilkinson et al_2016_The FAIR Guiding Principles for scientific data management and stewardship.pdf;C\:\\Users\\vanlissa\\Zotero\\storage\\L9FSJNYX\\sdata201618.html}
}

@misc{zenodo,
  title = {Zenodo},
  author = {{European Organization For Nuclear Research} and {OpenAIRE}},
  date = {2013},
  doi = {10.25495/7GXK-RD71},
  url = {https://doi.org/10.25495/7gxk-rd71},
  langid = {english},
  organization = {CERN},
  keywords = {Dataset,FOS: Physical sciences,Publication}
}
